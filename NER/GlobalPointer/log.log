Some weights of the model checkpoint at ./roberta_pretrain were not used when initializing BertModel: ['sop.cls.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'sop.cls.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
epoch:0, step:0, loss:  6.548341, precision:  0.000331, f1:  0.000662
epoch:0, step:1, loss:  6.470067, precision:  0.000290, f1:  0.000579
epoch:0, step:2, loss:  6.606449, precision:  0.000400, f1:  0.000800
epoch:0, step:3, loss:  6.532515, precision:  0.000366, f1:  0.000731
epoch:0, step:4, loss:  6.582807, precision:  0.000293, f1:  0.000586
epoch:0, step:5, loss:  6.631693, precision:  0.000286, f1:  0.000571
epoch:0, step:6, loss:  6.596733, precision:  0.000311, f1:  0.000621
epoch:0, step:7, loss:  6.519698, precision:  0.000299, f1:  0.000598
epoch:0, step:8, loss:  6.731627, precision:  0.000289, f1:  0.000579
epoch:0, step:9, loss:  6.621593, precision:  0.000385, f1:  0.000770
epoch:0, step:10, loss:  6.462303, precision:  0.000332, f1:  0.000664
epoch:0, step:11, loss:  6.678435, precision:  0.000297, f1:  0.000595
epoch:0, step:12, loss:  6.537369, precision:  0.000285, f1:  0.000570
epoch:0, step:13, loss:  6.747875, precision:  0.000285, f1:  0.000569
epoch:0, step:14, loss:  6.676843, precision:  0.000332, f1:  0.000664
epoch:0, step:15, loss:  6.559584, precision:  0.000322, f1:  0.000643
epoch:0, step:16, loss:  6.327432, precision:  0.000326, f1:  0.000652
epoch:0, step:17, loss:  6.617188, precision:  0.000278, f1:  0.000556
epoch:0, step:18, loss:  6.605929, precision:  0.000387, f1:  0.000773
epoch:0, step:19, loss:  6.480997, precision:  0.000283, f1:  0.000565
epoch:0, step:20, loss:  6.640571, precision:  0.000311, f1:  0.000622
epoch:0, step:21, loss:  6.573224, precision:  0.000307, f1:  0.000613
epoch:0, step:22, loss:  6.669422, precision:  0.000351, f1:  0.000701
epoch:0, step:23, loss:  6.392236, precision:  0.000352, f1:  0.000702
epoch:0, step:24, loss:  6.449355, precision:  0.000402, f1:  0.000803
epoch:0, step:25, loss:  6.532485, precision:  0.000357, f1:  0.000713
epoch:0, step:26, loss:  6.429956, precision:  0.000417, f1:  0.000833
epoch:0, step:27, loss:  6.504415, precision:  0.000420, f1:  0.000840
epoch:0, step:28, loss:  6.656799, precision:  0.000273, f1:  0.000545
epoch:0, step:29, loss:  6.580606, precision:  0.000361, f1:  0.000721
epoch:0, step:30, loss:  6.597016, precision:  0.000445, f1:  0.000889
epoch:0, step:31, loss:  6.566470, precision:  0.000323, f1:  0.000646
epoch:0, step:32, loss:  6.534785, precision:  0.000418, f1:  0.000835
epoch:0, step:33, loss:  6.462034, precision:  0.000568, f1:  0.001134
epoch:0, step:34, loss:  6.512437, precision:  0.000478, f1:  0.000955
epoch:0, step:35, loss:  6.632349, precision:  0.000401, f1:  0.000800
epoch:0, step:36, loss:  6.483651, precision:  0.000344, f1:  0.000687
epoch:0, step:37, loss:  6.660484, precision:  0.000356, f1:  0.000711
epoch:0, step:38, loss:  6.511162, precision:  0.000477, f1:  0.000953
epoch:0, step:39, loss:  6.518121, precision:  0.000324, f1:  0.000647
epoch:0, step:40, loss:  6.555938, precision:  0.000517, f1:  0.001032
epoch:0, step:41, loss:  6.324038, precision:  0.000490, f1:  0.000977
epoch:0, step:42, loss:  6.478692, precision:  0.000343, f1:  0.000684
epoch:0, step:43, loss:  6.432854, precision:  0.000394, f1:  0.000785
epoch:0, step:44, loss:  6.389423, precision:  0.000539, f1:  0.001074
epoch:0, step:45, loss:  6.267609, precision:  0.000614, f1:  0.001222
epoch:0, step:46, loss:  6.359307, precision:  0.000567, f1:  0.001128
epoch:0, step:47, loss:  6.297969, precision:  0.000596, f1:  0.001185
epoch:0, step:48, loss:  6.248147, precision:  0.000949, f1:  0.001878
epoch:0, step:49, loss:  6.285938, precision:  0.000407, f1:  0.000805
epoch:0, step:50, loss:  6.228914, precision:  0.000627, f1:  0.001233
epoch:0, step:51, loss:  6.209852, precision:  0.000339, f1:  0.000663
epoch:0, step:52, loss:  6.405406, precision:  0.000204, f1:  0.000397
epoch:0, step:53, loss:  6.159626, precision:  0.000000, f1:  0.000000
epoch:0, step:54, loss:  6.222527, precision:  0.000000, f1:  0.000000
epoch:0, step:55, loss:  6.175382, precision:  0.000699, f1:  0.001268
epoch:0, step:56, loss:  6.228126, precision:  0.000000, f1:  0.000000
epoch:0, step:57, loss:  6.169201, precision:  0.000000, f1:  0.000000
epoch:0, step:58, loss:  6.060857, precision:  0.000000, f1:  0.000000
epoch:0, step:59, loss:  6.025949, precision:  0.000000, f1:  0.000000
epoch:0, step:60, loss:  5.949521, precision:  0.000000, f1:  0.000000
epoch:0, step:61, loss:  5.729534, precision:  0.000000, f1:  0.000000
epoch:0, step:62, loss:  5.670177, precision:  0.000000, f1:  0.000000
epoch:0, step:63, loss:  5.690024, precision:  0.000000, f1:  0.000000
epoch:0, step:64, loss:  5.888541, precision:  0.000000, f1:  0.000000
epoch:0, step:65, loss:  5.752892, precision:  0.000000, f1:  0.000000
epoch:0, step:66, loss:  5.744580, precision:  0.000000, f1:  0.000000
epoch:0, step:67, loss:  5.706936, precision:  0.000000, f1:  0.000000
epoch:0, step:68, loss:  5.647584, precision:  0.000000, f1:  0.000000
epoch:0, step:69, loss:  5.590257, precision:  0.000000, f1:  0.000000
epoch:0, step:70, loss:  5.405451, precision:  0.000000, f1:  0.000000
epoch:0, step:71, loss:  5.453876, precision:  0.000000, f1:  0.000000
epoch:0, step:72, loss:  5.278489, precision:  0.000000, f1:  0.000000
epoch:0, step:73, loss:  5.319711, precision:  0.000000, f1:  0.000000
epoch:0, step:74, loss:  5.033270, precision:  0.000000, f1:  0.000000
epoch:0, step:75, loss:  5.092187, precision:  0.000000, f1:  0.000000
epoch:0, step:76, loss:  5.224072, precision:  0.000000, f1:  0.000000
epoch:0, step:77, loss:  4.865888, precision:  0.000000, f1:  0.000000
epoch:0, step:78, loss:  5.074702, precision:  0.000000, f1:  0.000000
epoch:0, step:79, loss:  5.193439, precision:  0.000000, f1:  0.000000
epoch:0, step:80, loss:  4.763702, precision:  0.000000, f1:  0.000000
epoch:0, step:81, loss:  4.922077, precision:  0.000000, f1:  0.000000
epoch:0, step:82, loss:  4.747108, precision:  0.000000, f1:  0.000000
epoch:0, step:83, loss:  4.693079, precision:  0.000000, f1:  0.000000
epoch:0, step:84, loss:  4.762876, precision:  0.000000, f1:  0.000000
epoch:0, step:85, loss:  4.718176, precision:  0.000000, f1:  0.000000
epoch:0, step:86, loss:  4.651250, precision:  0.000000, f1:  0.000000
epoch:0, step:87, loss:  4.499321, precision:  0.000000, f1:  0.000000
epoch:0, step:88, loss:  4.685320, precision:  0.000000, f1:  0.000000
epoch:0, step:89, loss:  4.312289, precision:  0.000000, f1:  0.000000
epoch:0, step:90, loss:  4.390203, precision:  0.000000, f1:  0.000000
epoch:0, step:91, loss:  4.261087, precision:  0.000000, f1:  0.000000
epoch:0, step:92, loss:  4.209569, precision:  0.000000, f1:  0.000000
epoch:0, step:93, loss:  4.174642, precision:  0.000000, f1:  0.000000
epoch:0, step:94, loss:  4.208436, precision:  0.000000, f1:  0.000000
epoch:0, step:95, loss:  4.095953, precision:  0.000000, f1:  0.000000
epoch:0, step:96, loss:  4.101418, precision:  0.000000, f1:  0.000000
epoch:0, step:97, loss:  3.975712, precision:  0.000000, f1:  0.000000
epoch:0, step:98, loss:  3.930271, precision:  0.000000, f1:  0.000000
epoch:0, step:99, loss:  3.958979, precision:  0.000000, f1:  0.000000
epoch:0, step:100, loss:  3.908295, precision:  0.000000, f1:  0.000000
epoch:0, step:101, loss:  3.947516, precision:  0.000000, f1:  0.000000
epoch:0, step:102, loss:  3.815938, precision:  0.000000, f1:  0.000000
epoch:0, step:103, loss:  3.613317, precision:  0.000000, f1:  0.000000
epoch:0, step:104, loss:  3.796710, precision:  0.000000, f1:  0.000000
epoch:0, step:105, loss:  3.598186, precision:  0.000000, f1:  0.000000
epoch:0, step:106, loss:  3.576941, precision:  0.000000, f1:  0.000000
epoch:0, step:107, loss:  3.497296, precision:  0.000000, f1:  0.000000
epoch:0, step:108, loss:  3.427850, precision:  0.000000, f1:  0.000000
epoch:0, step:109, loss:  3.314996, precision:  0.000000, f1:  0.000000
epoch:0, step:110, loss:  3.214573, precision:  0.000000, f1:  0.000000
epoch:0, step:111, loss:  3.123775, precision:  0.000000, f1:  0.000000
epoch:0, step:112, loss:  3.213077, precision:  0.000000, f1:  0.000000
epoch:0, step:113, loss:  3.051746, precision:  0.000000, f1:  0.000000
epoch:0, step:114, loss:  3.029799, precision:  0.000000, f1:  0.000000
epoch:0, step:115, loss:  2.942445, precision:  0.000000, f1:  0.000000Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:06,  3.16it/s]Validating:  10%|▉         | 2/21 [00:00<00:06,  2.90it/s]Validating:  14%|█▍        | 3/21 [00:01<00:06,  2.69it/s]Validating:  19%|█▉        | 4/21 [00:01<00:06,  2.57it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.53it/s]Validating:  29%|██▊       | 6/21 [00:02<00:05,  2.52it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.47it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.36it/s]Validating:  43%|████▎     | 9/21 [00:03<00:04,  2.50it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.45it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.44it/s]Validating:  57%|█████▋    | 12/21 [00:04<00:03,  2.42it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.42it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:02,  2.57it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.46it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.38it/s]Validating:  81%|████████  | 17/21 [00:06<00:01,  2.37it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.31it/s]Validating:  90%|█████████ | 19/21 [00:07<00:00,  2.42it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.38it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.41it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.43it/s]
epoch:0, step:116, loss:  2.746799, precision:  0.000000, f1:  0.000000
epoch:0, step:117, loss:  2.898849, precision:  0.000000, f1:  0.000000
epoch:0, step:118, loss:  2.741374, precision:  0.000000, f1:  0.000000
epoch:0, step:119, loss:  2.708541, precision:  0.000000, f1:  0.000000
epoch:0, step:120, loss:  2.470073, precision:  0.000000, f1:  0.000000
epoch:0, step:121, loss:  2.653738, precision:  0.000000, f1:  0.000000
epoch:0, step:122, loss:  2.467107, precision:  0.000000, f1:  0.000000
epoch:0, step:123, loss:  2.521699, precision:  0.000000, f1:  0.000000
epoch:0, step:124, loss:  2.411668, precision:  0.000000, f1:  0.000000
epoch:0, step:125, loss:  2.341050, precision:  0.000000, f1:  0.000000
epoch:0, step:126, loss:  2.289155, precision:  0.000000, f1:  0.000000
epoch:0, step:127, loss:  2.205623, precision:  0.000000, f1:  0.000000
epoch:0, step:128, loss:  2.141974, precision:  0.000000, f1:  0.000000
epoch:0, step:129, loss:  1.998444, precision:  0.000000, f1:  0.000000
epoch:0, step:130, loss:  2.021163, precision:  0.000000, f1:  0.000000
epoch:0, step:131, loss:  2.054070, precision:  0.000000, f1:  0.000000
epoch:0, step:132, loss:  1.931726, precision:  0.000000, f1:  0.000000
epoch:0, step:133, loss:  1.785046, precision:  0.000000, f1:  0.000000
epoch:0, step:134, loss:  1.746482, precision:  0.000000, f1:  0.000000
epoch:0, step:135, loss:  1.798827, precision:  0.000000, f1:  0.000000
epoch:0, step:136, loss:  1.865233, precision:  0.000000, f1:  0.000000
epoch:0, step:137, loss:  1.693502, precision:  0.000000, f1:  0.000000
epoch:0, step:138, loss:  1.752541, precision:  0.000000, f1:  0.000000
epoch:0, step:139, loss:  1.740207, precision:  0.000000, f1:  0.000000
epoch:0, step:140, loss:  1.731991, precision:  0.000000, f1:  0.000000
epoch:0, step:141, loss:  1.548773, precision:  0.000000, f1:  0.000000
epoch:0, step:142, loss:  1.537789, precision:  0.000000, f1:  0.000000
epoch:0, step:143, loss:  1.507106, precision:  0.000000, f1:  0.000000
epoch:0, step:144, loss:  1.497405, precision:  0.000000, f1:  0.000000
epoch:0, step:145, loss:  1.663152, precision:  0.000000, f1:  0.000000
epoch:0, step:146, loss:  1.519982, precision:  0.000000, f1:  0.000000
epoch:0, step:147, loss:  1.419341, precision:  0.000000, f1:  0.000000
epoch:0, step:148, loss:  1.508502, precision:  0.000000, f1:  0.000000
epoch:0, step:149, loss:  1.547171, precision:  0.000000, f1:  0.000000
epoch:0, step:150, loss:  1.468994, precision:  0.000000, f1:  0.000000
epoch:0, step:151, loss:  1.489253, precision:  0.000000, f1:  0.000000
epoch:0, step:152, loss:  1.480782, precision:  0.000000, f1:  0.000000
epoch:0, step:153, loss:  1.447109, precision:  0.000000, f1:  0.000000
epoch:0, step:154, loss:  1.512385, precision:  0.000000, f1:  0.000000
epoch:0, step:155, loss:  1.409753, precision:  0.000000, f1:  0.000000
epoch:0, step:156, loss:  1.485212, precision:  0.000000, f1:  0.000000
epoch:0, step:157, loss:  1.444932, precision:  0.000000, f1:  0.000000
epoch:0, step:158, loss:  1.412632, precision:  0.000000, f1:  0.000000
epoch:0, step:159, loss:  1.622760, precision:  0.000000, f1:  0.000000
epoch:0, step:160, loss:  1.393070, precision:  0.000000, f1:  0.000000
epoch:0, step:161, loss:  1.459714, precision:  0.000000, f1:  0.000000
epoch:0, step:162, loss:  1.418700, precision:  0.000000, f1:  0.000000
epoch:0, step:163, loss:  1.302122, precision:  0.000000, f1:  0.000000
epoch:0, step:164, loss:  1.428650, precision:  0.000000, f1:  0.000000
epoch:0, step:165, loss:  1.399339, precision:  0.000000, f1:  0.000000
epoch:0, step:166, loss:  1.372986, precision:  0.000000, f1:  0.000000
epoch:0, step:167, loss:  1.377038, precision:  0.000000, f1:  0.000000
epoch:0, valid_f1:  0.000000, valid_precision:  0.000000, valid_recall:  0.000000
epoch:1, step:0, loss:  1.349277, precision:  0.000000, f1:  0.000000
epoch:1, step:1, loss:  1.376262, precision:  0.000000, f1:  0.000000
epoch:1, step:2, loss:  1.404679, precision:  0.000000, f1:  0.000000
epoch:1, step:3, loss:  1.330198, precision:  0.000000, f1:  0.000000
epoch:1, step:4, loss:  1.304364, precision:  0.000000, f1:  0.000000
epoch:1, step:5, loss:  1.327680, precision:  0.000000, f1:  0.000000
epoch:1, step:6, loss:  1.252484, precision:  0.000000, f1:  0.000000
epoch:1, step:7, loss:  1.319691, precision:  0.000000, f1:  0.000000
epoch:1, step:8, loss:  1.325593, precision:  0.000000, f1:  0.000000
epoch:1, step:9, loss:  1.135763, precision:  0.000000, f1:  0.000000
epoch:1, step:10, loss:  1.052737, precision:  0.000000, f1:  0.000000
epoch:1, step:11, loss:  1.139347, precision:  0.000000, f1:  0.000000
epoch:1, step:12, loss:  1.156203, precision:  0.000000, f1:  0.000000
epoch:1, step:13, loss:  1.067662, precision:  0.000000, f1:  0.000000
epoch:1, step:14, loss:  1.179539, precision:  0.000000, f1:  0.000000
epoch:1, step:15, loss:  1.139393, precision:  0.000000, f1:  0.000000
epoch:1, step:16, loss:  0.986806, precision:  0.000000, f1:  0.000000
epoch:1, step:17, loss:  1.065812, precision:  0.000000, f1:  0.000000
epoch:1, step:18, loss:  1.011713, precision:  0.000000, f1:  0.000000
epoch:1, step:19, loss:  0.905781, precision:  0.000000, f1:  0.000000
epoch:1, step:20, loss:  0.952587, precision:  0.000000, f1:  0.000000
epoch:1, step:21, loss:  0.933404, precision:  0.000000, f1:  0.000000
epoch:1, step:22, loss:  0.908995, precision:  0.000000, f1:  0.000000
epoch:1, step:23, loss:  0.987586, precision:  0.000000, f1:  0.000000
epoch:1, step:24, loss:  0.897657, precision:  0.000000, f1:  0.000000
epoch:1, step:25, loss:  0.885285, precision:  0.500000, f1:  0.014925
epoch:1, step:26, loss:  0.939116, precision:  0.900000, f1:  0.105263
epoch:1, step:27, loss:  0.811934, precision:  0.857143, f1:  0.083333
epoch:1, step:28, loss:  0.844335, precision:  0.000000, f1:  0.000000
epoch:1, step:29, loss:  0.895188, precision:  0.500000, f1:  0.012903
epoch:1, step:30, loss:  0.761407, precision:  0.500000, f1:  0.013986
epoch:1, step:31, loss:  0.902446, precision:  0.833333, f1:  0.065359
epoch:1, step:32, loss:  0.813864, precision:  0.846154, f1:  0.133333
epoch:1, step:33, loss:  0.714908, precision:  0.833333, f1:  0.196078
epoch:1, step:34, loss:  0.745095, precision:  0.750000, f1:  0.037500
epoch:1, step:35, loss:  0.762123, precision:  0.500000, f1:  0.041667
epoch:1, step:36, loss:  0.776322, precision:  0.833333, f1:  0.117647
epoch:1, step:37, loss:  0.784472, precision:  0.750000, f1:  0.148148
epoch:1, step:38, loss:  0.693585, precision:  0.666667, f1:  0.179487
epoch:1, step:39, loss:  0.716259, precision:  0.647059, f1:  0.141935
epoch:1, step:40, loss:  0.694158, precision:  0.846154, f1:  0.141026
epoch:1, step:41, loss:  0.575779, precision:  0.909091, f1:  0.158730
epoch:1, step:42, loss:  0.703247, precision:  0.805556, f1:  0.288557
epoch:1, step:43, loss:  0.710371, precision:  0.829268, f1:  0.345178
epoch:1, step:44, loss:  0.577883, precision:  0.933333, f1:  0.201439
epoch:1, step:45, loss:  0.705160, precision:  0.846154, f1:  0.140127
epoch:1, step:46, loss:  0.603402, precision:  0.777778, f1:  0.185430
epoch:1, step:47, loss:  0.590650, precision:  0.916667, f1:  0.349206
epoch:1, step:48, loss:  0.645655, precision:  0.941176, f1:  0.367816
epoch:1, step:49, loss:  0.616316, precision:  0.880000, f1:  0.255814
epoch:1, step:50, loss:  0.676210, precision:  0.857143, f1:  0.327869
epoch:1, step:51, loss:  0.581609, precision:  0.962963, f1:  0.305882
epoch:1, step:52, loss:  0.625973, precision:  0.812500, f1:  0.166667
epoch:1, step:53, loss:  0.586339, precision:  0.892857, f1:  0.280899
epoch:1, step:54, loss:  0.596332, precision:  0.800000, f1:  0.160000
epoch:1, step:55, loss:  0.536435, precision:  0.846154, f1:  0.161765
epoch:1, step:56, loss:  0.572754, precision:  0.761905, f1:  0.344086
epoch:1, step:57, loss:  0.564087, precision:  0.843750, f1:  0.310345
epoch:1, step:58, loss:  0.548358, precision:  0.888889, f1:  0.214765
epoch:1, step:59, loss:  0.521445, precision:  0.916667, f1:  0.278481
epoch:1, step:60, loss:  0.510665, precision:  0.722222, f1:  0.319018
epoch:1, step:61, loss:  0.558847, precision:  0.740000, f1:  0.375635
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.16it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.32it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.26it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.29it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.32it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.32it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.37it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.32it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.24it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.26it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.28it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.37it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.30it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.23it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.19it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.18it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.19it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.16it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.29it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.21it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.30it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.28it/s]
epoch:1, step:62, loss:  0.535045, precision:  0.791667, f1:  0.242038
epoch:1, step:63, loss:  0.466303, precision:  0.818182, f1:  0.323353
epoch:1, step:64, loss:  0.464125, precision:  0.785714, f1:  0.171875
epoch:1, step:65, loss:  0.491611, precision:  0.852941, f1:  0.337209
epoch:1, step:66, loss:  0.524360, precision:  0.885714, f1:  0.333333
epoch:1, step:67, loss:  0.541755, precision:  0.815789, f1:  0.344444
epoch:1, step:68, loss:  0.432771, precision:  0.800000, f1:  0.453608
epoch:1, step:69, loss:  0.544383, precision:  0.732143, f1:  0.405941
epoch:1, step:70, loss:  0.500433, precision:  0.840000, f1:  0.432990
epoch:1, step:71, loss:  0.502887, precision:  0.790698, f1:  0.357895
epoch:1, step:72, loss:  0.435289, precision:  0.833333, f1:  0.451977
epoch:1, step:73, loss:  0.495064, precision:  0.847458, f1:  0.473934
epoch:1, step:74, loss:  0.411413, precision:  0.909091, f1:  0.529101
epoch:1, step:75, loss:  0.425947, precision:  0.857143, f1:  0.507042
epoch:1, step:76, loss:  0.482752, precision:  0.907692, f1:  0.513043
epoch:1, step:77, loss:  0.498928, precision:  0.769231, f1:  0.346821
epoch:1, step:78, loss:  0.430527, precision:  0.836066, f1:  0.512563
epoch:1, step:79, loss:  0.442860, precision:  0.765957, f1:  0.402235
epoch:1, step:80, loss:  0.495259, precision:  0.811321, f1:  0.427861
epoch:1, step:81, loss:  0.484749, precision:  0.756757, f1:  0.504505
epoch:1, step:82, loss:  0.462016, precision:  0.687500, f1:  0.564103
epoch:1, step:83, loss:  0.488736, precision:  0.717949, f1:  0.520930
epoch:1, step:84, loss:  0.421803, precision:  0.781250, f1:  0.483092
epoch:1, step:85, loss:  0.474775, precision:  0.833333, f1:  0.518868
epoch:1, step:86, loss:  0.373490, precision:  0.915254, f1:  0.556701
epoch:1, step:87, loss:  0.447549, precision:  0.723404, f1:  0.379888
epoch:1, step:88, loss:  0.399838, precision:  0.846154, f1:  0.558376
epoch:1, step:89, loss:  0.415469, precision:  0.767123, f1:  0.546341
epoch:1, step:90, loss:  0.412668, precision:  0.814815, f1:  0.554622
epoch:1, step:91, loss:  0.438842, precision:  0.850000, f1:  0.502463
epoch:1, step:92, loss:  0.395318, precision:  0.794872, f1:  0.571429
epoch:1, step:93, loss:  0.466313, precision:  0.777778, f1:  0.594595
epoch:1, step:94, loss:  0.446309, precision:  0.757282, f1:  0.624000
epoch:1, step:95, loss:  0.400039, precision:  0.778947, f1:  0.632479
epoch:1, step:96, loss:  0.430954, precision:  0.835821, f1:  0.546341
epoch:1, step:97, loss:  0.355456, precision:  0.894737, f1:  0.539683
epoch:1, step:98, loss:  0.396858, precision:  0.873239, f1:  0.546256
epoch:1, step:99, loss:  0.372491, precision:  0.835616, f1:  0.562212
epoch:1, step:100, loss:  0.417133, precision:  0.738318, f1:  0.619608
epoch:1, step:101, loss:  0.413561, precision:  0.754545, f1:  0.636015
epoch:1, step:102, loss:  0.349744, precision:  0.797468, f1:  0.575342
epoch:1, step:103, loss:  0.425218, precision:  0.821429, f1:  0.457711
epoch:1, step:104, loss:  0.363322, precision:  0.826087, f1:  0.540284
epoch:1, step:105, loss:  0.394133, precision:  0.806122, f1:  0.644898
epoch:1, step:106, loss:  0.410329, precision:  0.737288, f1:  0.677043
epoch:1, step:107, loss:  0.326195, precision:  0.731183, f1:  0.607143
epoch:1, step:108, loss:  0.375832, precision:  0.795181, f1:  0.589286
epoch:1, step:109, loss:  0.465839, precision:  0.791045, f1:  0.479638
epoch:1, step:110, loss:  0.410442, precision:  0.854167, f1:  0.645669
epoch:1, step:111, loss:  0.376101, precision:  0.678571, f1:  0.615385
epoch:1, step:112, loss:  0.375730, precision:  0.743243, f1:  0.567010
epoch:1, step:113, loss:  0.358786, precision:  0.727273, f1:  0.663900
epoch:1, step:114, loss:  0.361577, precision:  0.858974, f1:  0.611872
epoch:1, step:115, loss:  0.399169, precision:  0.768421, f1:  0.610879
epoch:1, step:116, loss:  0.373953, precision:  0.814286, f1:  0.578680
epoch:1, step:117, loss:  0.392726, precision:  0.800000, f1:  0.628099
epoch:1, step:118, loss:  0.352315, precision:  0.722772, f1:  0.648889
epoch:1, step:119, loss:  0.400155, precision:  0.770992, f1:  0.671096
epoch:1, step:120, loss:  0.309290, precision:  0.813953, f1:  0.639269
epoch:1, step:121, loss:  0.371746, precision:  0.813953, f1:  0.606061
epoch:1, step:122, loss:  0.310536, precision:  0.892308, f1:  0.610526
epoch:1, step:123, loss:  0.420246, precision:  0.813953, f1:  0.588235
epoch:1, step:124, loss:  0.379110, precision:  0.796296, f1:  0.656489
epoch:1, step:125, loss:  0.377217, precision:  0.735714, f1:  0.710345
epoch:1, step:126, loss:  0.343545, precision:  0.843750, f1:  0.689362
epoch:1, step:127, loss:  0.334236, precision:  0.797872, f1:  0.638298
epoch:1, step:128, loss:  0.352830, precision:  0.806452, f1:  0.510204
epoch:1, step:129, loss:  0.355524, precision:  0.855263, f1:  0.607477
epoch:1, step:130, loss:  0.285158, precision:  0.847059, f1:  0.679245
epoch:1, step:131, loss:  0.425704, precision:  0.737288, f1:  0.656604
epoch:1, step:132, loss:  0.343606, precision:  0.753425, f1:  0.743243
epoch:1, step:133, loss:  0.319913, precision:  0.732673, f1:  0.640693
epoch:1, step:134, loss:  0.308764, precision:  0.862500, f1:  0.660287
epoch:1, step:135, loss:  0.416574, precision:  0.814286, f1:  0.502203
epoch:1, step:136, loss:  0.348195, precision:  0.819149, f1:  0.647059
epoch:1, step:137, loss:  0.319462, precision:  0.826923, f1:  0.725738
epoch:1, step:138, loss:  0.422046, precision:  0.734513, f1:  0.626415
epoch:1, step:139, loss:  0.384757, precision:  0.769231, f1:  0.723684
epoch:1, step:140, loss:  0.361569, precision:  0.767241, f1:  0.674242
epoch:1, step:141, loss:  0.263371, precision:  0.865385, f1:  0.731707
epoch:1, step:142, loss:  0.311746, precision:  0.901235, f1:  0.669725
epoch:1, step:143, loss:  0.349183, precision:  0.872093, f1:  0.657895
epoch:1, step:144, loss:  0.331055, precision:  0.777778, f1:  0.666667
epoch:1, step:145, loss:  0.337780, precision:  0.758333, f1:  0.702703
epoch:1, step:146, loss:  0.321594, precision:  0.725191, f1:  0.685921
epoch:1, step:147, loss:  0.346804, precision:  0.816667, f1:  0.745247
epoch:1, step:148, loss:  0.314927, precision:  0.772277, f1:  0.658228
epoch:1, step:149, loss:  0.328765, precision:  0.855556, f1:  0.675439
epoch:1, step:150, loss:  0.324177, precision:  0.833333, f1:  0.666667
epoch:1, step:151, loss:  0.315804, precision:  0.800000, f1:  0.703297
epoch:1, step:152, loss:  0.334455, precision:  0.684211, f1:  0.626506
epoch:1, step:153, loss:  0.331220, precision:  0.742188, f1:  0.719697
epoch:1, step:154, loss:  0.329559, precision:  0.709091, f1:  0.641975
epoch:1, step:155, loss:  0.317100, precision:  0.835165, f1:  0.697248
epoch:1, step:156, loss:  0.282498, precision:  0.879518, f1:  0.637555
epoch:1, step:157, loss:  0.321131, precision:  0.864078, f1:  0.712000
epoch:1, step:158, loss:  0.364458, precision:  0.764706, f1:  0.631579
epoch:1, step:159, loss:  0.341257, precision:  0.773109, f1:  0.691729
epoch:1, step:160, loss:  0.297092, precision:  0.746032, f1:  0.720307
epoch:1, step:161, loss:  0.336858, precision:  0.770992, f1:  0.729242
epoch:1, step:162, loss:  0.303681, precision:  0.876106, f1:  0.764479
epoch:1, step:163, loss:  0.306719, precision:  0.801980, f1:  0.692308
epoch:1, step:164, loss:  0.267631, precision:  0.830000, f1:  0.744395
epoch:1, step:165, loss:  0.314783, precision:  0.864583, f1:  0.680328
epoch:1, step:166, loss:  0.379418, precision:  0.693548, f1:  0.637037
epoch:1, step:167, loss:  0.336347, precision:  0.728000, f1:  0.689394
epoch:1, valid_f1:  0.753539, valid_precision:  0.757152, valid_recall:  0.750875
epoch:2, step:0, loss:  0.300420, precision:  0.743119, f1:  0.686441
epoch:2, step:1, loss:  0.260647, precision:  0.921348, f1:  0.748858
epoch:2, step:2, loss:  0.290940, precision:  0.871287, f1:  0.715447
epoch:2, step:3, loss:  0.287913, precision:  0.813084, f1:  0.698795
epoch:2, step:4, loss:  0.307649, precision:  0.815789, f1:  0.718147
epoch:2, step:5, loss:  0.290421, precision:  0.813559, f1:  0.752941
epoch:2, step:6, loss:  0.322909, precision:  0.790698, f1:  0.708333
epoch:2, step:7, loss:  0.289018, precision:  0.738318, f1:  0.663866
epoch:2, step:8, loss:  0.324865, precision:  0.763636, f1:  0.646154
epoch:2, step:9, loss:  0.270100, precision:  0.803738, f1:  0.696356
epoch:2, step:10, loss:  0.287647, precision:  0.862385, f1:  0.743083
epoch:2, step:11, loss:  0.319553, precision:  0.804348, f1:  0.765517
epoch:2, step:12, loss:  0.271129, precision:  0.773438, f1:  0.744361
epoch:2, step:13, loss:  0.275161, precision:  0.806202, f1:  0.779026
epoch:2, step:14, loss:  0.283010, precision:  0.846774, f1:  0.769231
epoch:2, step:15, loss:  0.270289, precision:  0.774194, f1:  0.738462
epoch:2, step:16, loss:  0.266151, precision:  0.887755, f1:  0.787330
epoch:2, step:17, loss:  0.328720, precision:  0.841584, f1:  0.705394
epoch:2, step:18, loss:  0.287846, precision:  0.805085, f1:  0.706320
epoch:2, step:19, loss:  0.257433, precision:  0.804878, f1:  0.752852
epoch:2, step:20, loss:  0.268988, precision:  0.789474, f1:  0.786885
epoch:2, step:21, loss:  0.283341, precision:  0.752137, f1:  0.706827
epoch:2, step:22, loss:  0.288144, precision:  0.793893, f1:  0.745520
epoch:2, step:23, loss:  0.217373, precision:  0.858268, f1:  0.816479
epoch:2, step:24, loss:  0.288006, precision:  0.825000, f1:  0.741573
epoch:2, step:25, loss:  0.265931, precision:  0.862903, f1:  0.769784
epoch:2, step:26, loss:  0.224629, precision:  0.864407, f1:  0.803150
epoch:2, step:27, loss:  0.239740, precision:  0.810219, f1:  0.790036
epoch:2, step:28, loss:  0.260902, precision:  0.835821, f1:  0.797153
epoch:2, step:29, loss:  0.297252, precision:  0.816327, f1:  0.692641
epoch:2, step:30, loss:  0.215313, precision:  0.892857, f1:  0.809717
epoch:2, step:31, loss:  0.254767, precision:  0.838462, f1:  0.798535
epoch:2, step:32, loss:  0.301656, precision:  0.759399, f1:  0.734545
epoch:2, step:33, loss:  0.285423, precision:  0.818898, f1:  0.745520
epoch:2, step:34, loss:  0.246362, precision:  0.785714, f1:  0.730290
epoch:2, step:35, loss:  0.281568, precision:  0.854701, f1:  0.760456
epoch:2, step:36, loss:  0.281200, precision:  0.718182, f1:  0.689956
epoch:2, step:37, loss:  0.209156, precision:  0.836207, f1:  0.798354
epoch:2, step:38, loss:  0.290097, precision:  0.837209, f1:  0.782609
epoch:2, step:39, loss:  0.298778, precision:  0.819444, f1:  0.756410
epoch:2, step:40, loss:  0.250610, precision:  0.803279, f1:  0.777778
epoch:2, step:41, loss:  0.248817, precision:  0.812030, f1:  0.774194
epoch:2, step:42, loss:  0.237524, precision:  0.871212, f1:  0.818505
epoch:2, step:43, loss:  0.296427, precision:  0.812500, f1:  0.759740
epoch:2, step:44, loss:  0.224478, precision:  0.755725, f1:  0.761538
epoch:2, step:45, loss:  0.277003, precision:  0.858268, f1:  0.798535
epoch:2, step:46, loss:  0.217528, precision:  0.873134, f1:  0.826855
epoch:2, step:47, loss:  0.292916, precision:  0.768707, f1:  0.750831
epoch:2, step:48, loss:  0.246619, precision:  0.787402, f1:  0.775194
epoch:2, step:49, loss:  0.274658, precision:  0.817518, f1:  0.802867
epoch:2, step:50, loss:  0.226765, precision:  0.835938, f1:  0.789668
epoch:2, step:51, loss:  0.289845, precision:  0.822222, f1:  0.762887
epoch:2, step:52, loss:  0.251112, precision:  0.842105, f1:  0.764940
epoch:2, step:53, loss:  0.290838, precision:  0.822581, f1:  0.741818
epoch:2, step:54, loss:  0.192858, precision:  0.841667, f1:  0.811245
epoch:2, step:55, loss:  0.252038, precision:  0.806452, f1:  0.772201
epoch:2, step:56, loss:  0.302118, precision:  0.789474, f1:  0.752688
epoch:2, step:57, loss:  0.256469, precision:  0.841667, f1:  0.765152
epoch:2, step:58, loss:  0.240270, precision:  0.861386, f1:  0.759825
epoch:2, step:59, loss:  0.269017, precision:  0.847328, f1:  0.760274
epoch:2, step:60, loss:  0.215611, precision:  0.855263, f1:  0.833333
epoch:2, step:61, loss:  0.229750, precision:  0.811475, f1:  0.785714
epoch:2, step:62, loss:  0.304552, precision:  0.831250, f1:  0.798799
epoch:2, step:63, loss:  0.243837, precision:  0.812500, f1:  0.801370
epoch:2, step:64, loss:  0.239507, precision:  0.866667, f1:  0.812500
epoch:2, step:65, loss:  0.333462, precision:  0.803419, f1:  0.723077
epoch:2, step:66, loss:  0.236400, precision:  0.768519, f1:  0.721739
epoch:2, step:67, loss:  0.238815, precision:  0.782609, f1:  0.779783
epoch:2, step:68, loss:  0.237449, precision:  0.763158, f1:  0.794521
epoch:2, step:69, loss:  0.277934, precision:  0.747748, f1:  0.706383
epoch:2, step:70, loss:  0.299993, precision:  0.822034, f1:  0.740458
epoch:2, step:71, loss:  0.259457, precision:  0.838710, f1:  0.748201
epoch:2, step:72, loss:  0.256611, precision:  0.774194, f1:  0.774194
epoch:2, step:73, loss:  0.321826, precision:  0.769231, f1:  0.730897
epoch:2, step:74, loss:  0.288459, precision:  0.741935, f1:  0.749186
epoch:2, step:75, loss:  0.271391, precision:  0.776786, f1:  0.734177
epoch:2, step:76, loss:  0.236907, precision:  0.827273, f1:  0.733871
epoch:2, step:77, loss:  0.239567, precision:  0.798246, f1:  0.733871
epoch:2, step:78, loss:  0.299989, precision:  0.836066, f1:  0.758364
epoch:2, step:79, loss:  0.239686, precision:  0.810606, f1:  0.781022
epoch:2, step:80, loss:  0.282275, precision:  0.766423, f1:  0.766423
epoch:2, step:81, loss:  0.323841, precision:  0.693548, f1:  0.674510
epoch:2, step:82, loss:  0.232521, precision:  0.843537, f1:  0.818482
epoch:2, step:83, loss:  0.301701, precision:  0.829268, f1:  0.752768
epoch:2, step:84, loss:  0.299799, precision:  0.834783, f1:  0.747082
epoch:2, step:85, loss:  0.277086, precision:  0.866667, f1:  0.753623
epoch:2, step:86, loss:  0.205409, precision:  0.822222, f1:  0.801444
epoch:2, step:87, loss:  0.315997, precision:  0.727941, f1:  0.709677
epoch:2, step:88, loss:  0.226906, precision:  0.843750, f1:  0.760563
epoch:2, step:89, loss:  0.273793, precision:  0.839695, f1:  0.788530
epoch:2, step:90, loss:  0.276895, precision:  0.770992, f1:  0.745387
epoch:2, step:91, loss:  0.313594, precision:  0.727941, f1:  0.694737
epoch:2, step:92, loss:  0.287904, precision:  0.727273, f1:  0.712329
epoch:2, step:93, loss:  0.268429, precision:  0.819048, f1:  0.761062
epoch:2, step:94, loss:  0.315439, precision:  0.797101, f1:  0.728477
epoch:2, step:95, loss:  0.269758, precision:  0.837209, f1:  0.800000
epoch:2, step:96, loss:  0.248647, precision:  0.798450, f1:  0.749091
epoch:2, step:97, loss:  0.316953, precision:  0.769841, f1:  0.726592
epoch:2, step:98, loss:  0.253727, precision:  0.880342, f1:  0.786260
epoch:2, step:99, loss:  0.254284, precision:  0.877049, f1:  0.795539
epoch:2, step:100, loss:  0.292405, precision:  0.766423, f1:  0.750000
epoch:2, step:101, loss:  0.205625, precision:  0.801587, f1:  0.789062
epoch:2, step:102, loss:  0.310093, precision:  0.715385, f1:  0.683824
epoch:2, step:103, loss:  0.258207, precision:  0.842520, f1:  0.807547
epoch:2, step:104, loss:  0.230286, precision:  0.891473, f1:  0.845588
epoch:2, step:105, loss:  0.263740, precision:  0.800000, f1:  0.735632
epoch:2, step:106, loss:  0.269560, precision:  0.822581, f1:  0.728571
epoch:2, step:107, loss:  0.265979, precision:  0.801653, f1:  0.754864
epoch:2, step:108, loss:  0.211162, precision:  0.792000, f1:  0.776471
epoch:2, step:109, loss:  0.230760, precision:  0.847458, f1:  0.793651
epoch:2, step:110, loss:  0.253991, precision:  0.816667, f1:  0.745247
epoch:2, step:111, loss:  0.319101, precision:  0.785714, f1:  0.744361
epoch:2, step:112, loss:  0.228645, precision:  0.833333, f1:  0.776256
epoch:2, step:113, loss:  0.235261, precision:  0.897196, f1:  0.777328
epoch:2, step:114, loss:  0.240348, precision:  0.822581, f1:  0.778626
epoch:2, step:115, loss:  0.226238, precision:  0.803150, f1:  0.766917
epoch:2, step:116, loss:  0.218246, precision:  0.803279, f1:  0.777778
epoch:2, step:117, loss:  0.257955, precision:  0.740458, f1:  0.746154
epoch:2, step:118, loss:  0.226364, precision:  0.852941, f1:  0.794521
epoch:2, step:119, loss:  0.252770, precision:  0.827273, f1:  0.728000
epoch:2, step:120, loss:  0.184468, precision:  0.910714, f1:  0.832653
epoch:2, step:121, loss:  0.277030, precision:  0.756098, f1:  0.715385
epoch:2, step:122, loss:  0.274601, precision:  0.780488, f1:  0.744186
epoch:2, step:123, loss:  0.288756, precision:  0.724832, f1:  0.722408
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.15it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.14it/s]Validating:  14%|█▍        | 3/21 [00:01<00:08,  2.14it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.13it/s]Validating:  24%|██▍       | 5/21 [00:02<00:07,  2.16it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.23it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.15it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.34it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.33it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.28it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.30it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.27it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.41it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.33it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.21it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.19it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.17it/s]Validating:  86%|████████▌ | 18/21 [00:08<00:01,  2.19it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.18it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.29it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.21it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.23it/s]
epoch:2, step:124, loss:  0.264625, precision:  0.744828, f1:  0.742268
epoch:2, step:125, loss:  0.288943, precision:  0.791045, f1:  0.759857
epoch:2, step:126, loss:  0.249968, precision:  0.780702, f1:  0.700787
epoch:2, step:127, loss:  0.211915, precision:  0.895652, f1:  0.771536
epoch:2, step:128, loss:  0.246738, precision:  0.855072, f1:  0.805461
epoch:2, step:129, loss:  0.207921, precision:  0.798507, f1:  0.801498
epoch:2, step:130, loss:  0.221346, precision:  0.797203, f1:  0.820144
epoch:2, step:131, loss:  0.258210, precision:  0.794118, f1:  0.771429
epoch:2, step:132, loss:  0.222799, precision:  0.895161, f1:  0.828358
epoch:2, step:133, loss:  0.230478, precision:  0.840909, f1:  0.801444
epoch:2, step:134, loss:  0.153398, precision:  0.807018, f1:  0.814159
epoch:2, step:135, loss:  0.239813, precision:  0.801587, f1:  0.795276
epoch:2, step:136, loss:  0.213973, precision:  0.802632, f1:  0.818792
epoch:2, step:137, loss:  0.272463, precision:  0.816794, f1:  0.767025
epoch:2, step:138, loss:  0.284931, precision:  0.758621, f1:  0.695652
epoch:2, step:139, loss:  0.283189, precision:  0.815126, f1:  0.732075
epoch:2, step:140, loss:  0.275928, precision:  0.823529, f1:  0.794326
epoch:2, step:141, loss:  0.261294, precision:  0.746269, f1:  0.732601
epoch:2, step:142, loss:  0.263388, precision:  0.802817, f1:  0.775510
epoch:2, step:143, loss:  0.267307, precision:  0.776978, f1:  0.750000
epoch:2, step:144, loss:  0.274344, precision:  0.797297, f1:  0.789298
epoch:2, step:145, loss:  0.287770, precision:  0.842520, f1:  0.761566
epoch:2, step:146, loss:  0.294549, precision:  0.678832, f1:  0.686347
epoch:2, step:147, loss:  0.258347, precision:  0.787879, f1:  0.773234
epoch:2, step:148, loss:  0.236806, precision:  0.870690, f1:  0.795276
epoch:2, step:149, loss:  0.274699, precision:  0.768707, f1:  0.768707
epoch:2, step:150, loss:  0.237595, precision:  0.796992, f1:  0.770909
epoch:2, step:151, loss:  0.156514, precision:  0.889764, f1:  0.837037
epoch:2, step:152, loss:  0.229152, precision:  0.846154, f1:  0.785714
epoch:2, step:153, loss:  0.238717, precision:  0.883333, f1:  0.815385
epoch:2, step:154, loss:  0.266429, precision:  0.826772, f1:  0.766423
epoch:2, step:155, loss:  0.282447, precision:  0.760331, f1:  0.730159
epoch:2, step:156, loss:  0.278702, precision:  0.793103, f1:  0.795848
epoch:2, step:157, loss:  0.220253, precision:  0.750000, f1:  0.750000
epoch:2, step:158, loss:  0.282255, precision:  0.827869, f1:  0.756554
epoch:2, step:159, loss:  0.235336, precision:  0.882353, f1:  0.775862
epoch:2, step:160, loss:  0.208969, precision:  0.834862, f1:  0.791304
epoch:2, step:161, loss:  0.248488, precision:  0.746154, f1:  0.760784
epoch:2, step:162, loss:  0.263989, precision:  0.851562, f1:  0.764912
epoch:2, step:163, loss:  0.231324, precision:  0.849206, f1:  0.789668
epoch:2, step:164, loss:  0.291870, precision:  0.813084, f1:  0.731092
epoch:2, step:165, loss:  0.264338, precision:  0.757143, f1:  0.765343
epoch:2, step:166, loss:  0.319909, precision:  0.773050, f1:  0.762238
epoch:2, step:167, loss:  0.224644, precision:  0.785714, f1:  0.778761
epoch:2, valid_f1:  0.787113, valid_precision:  0.798273, valid_recall:  0.777425
epoch:3, step:0, loss:  0.238764, precision:  0.839286, f1:  0.758065
epoch:3, step:1, loss:  0.195635, precision:  0.893130, f1:  0.844765
epoch:3, step:2, loss:  0.188389, precision:  0.837838, f1:  0.781513
epoch:3, step:3, loss:  0.154329, precision:  0.845588, f1:  0.845588
epoch:3, step:4, loss:  0.213454, precision:  0.853659, f1:  0.823529
epoch:3, step:5, loss:  0.154189, precision:  0.859504, f1:  0.825397
epoch:3, step:6, loss:  0.184632, precision:  0.872881, f1:  0.804688
epoch:3, step:7, loss:  0.233689, precision:  0.813793, f1:  0.808219
epoch:3, step:8, loss:  0.224978, precision:  0.803279, f1:  0.787149
epoch:3, step:9, loss:  0.211654, precision:  0.834646, f1:  0.812261
epoch:3, step:10, loss:  0.254265, precision:  0.820312, f1:  0.783582
epoch:3, step:11, loss:  0.169435, precision:  0.921569, f1:  0.813853
epoch:3, step:12, loss:  0.247898, precision:  0.845528, f1:  0.781955
epoch:3, step:13, loss:  0.223833, precision:  0.849315, f1:  0.815789
epoch:3, step:14, loss:  0.186125, precision:  0.805195, f1:  0.829431
epoch:3, step:15, loss:  0.257413, precision:  0.757962, f1:  0.798658
epoch:3, step:16, loss:  0.201197, precision:  0.881890, f1:  0.845283
epoch:3, step:17, loss:  0.187612, precision:  0.847826, f1:  0.829787
epoch:3, step:18, loss:  0.181070, precision:  0.880342, f1:  0.820717
epoch:3, step:19, loss:  0.213237, precision:  0.864407, f1:  0.787645
epoch:3, step:20, loss:  0.175097, precision:  0.845070, f1:  0.851064
epoch:3, step:21, loss:  0.210608, precision:  0.800000, f1:  0.791809
epoch:3, step:22, loss:  0.183680, precision:  0.847826, f1:  0.847826
epoch:3, step:23, loss:  0.222858, precision:  0.805755, f1:  0.785965
epoch:3, step:24, loss:  0.212238, precision:  0.843478, f1:  0.782258
epoch:3, step:25, loss:  0.196630, precision:  0.839416, f1:  0.824373
epoch:3, step:26, loss:  0.241732, precision:  0.826389, f1:  0.806780
epoch:3, step:27, loss:  0.189849, precision:  0.815385, f1:  0.815385
epoch:3, step:28, loss:  0.217274, precision:  0.838710, f1:  0.822134
epoch:3, step:29, loss:  0.190217, precision:  0.792000, f1:  0.779528
epoch:3, step:30, loss:  0.166538, precision:  0.858268, f1:  0.832061
epoch:3, step:31, loss:  0.181152, precision:  0.863014, f1:  0.848485
epoch:3, step:32, loss:  0.172140, precision:  0.823077, f1:  0.819923
epoch:3, step:33, loss:  0.157908, precision:  0.850877, f1:  0.818565
epoch:3, step:34, loss:  0.240819, precision:  0.875000, f1:  0.840841
epoch:3, step:35, loss:  0.265656, precision:  0.811688, f1:  0.798722
epoch:3, step:36, loss:  0.233858, precision:  0.787879, f1:  0.779026
epoch:3, step:37, loss:  0.253712, precision:  0.843137, f1:  0.837662
epoch:3, step:38, loss:  0.205029, precision:  0.814815, f1:  0.830189
epoch:3, step:39, loss:  0.258758, precision:  0.871429, f1:  0.821549
epoch:3, step:40, loss:  0.223450, precision:  0.857143, f1:  0.800000
epoch:3, step:41, loss:  0.181933, precision:  0.861111, f1:  0.840678
epoch:3, step:42, loss:  0.187115, precision:  0.872340, f1:  0.854167
epoch:3, step:43, loss:  0.166767, precision:  0.860294, f1:  0.863469
epoch:3, step:44, loss:  0.236359, precision:  0.776000, f1:  0.740458
epoch:3, step:45, loss:  0.162829, precision:  0.846939, f1:  0.798077
epoch:3, step:46, loss:  0.214942, precision:  0.818898, f1:  0.803089
epoch:3, step:47, loss:  0.191083, precision:  0.885496, f1:  0.822695
epoch:3, step:48, loss:  0.159433, precision:  0.893130, f1:  0.823944
epoch:3, step:49, loss:  0.244412, precision:  0.794118, f1:  0.757895
epoch:3, step:50, loss:  0.202508, precision:  0.859649, f1:  0.800000
epoch:3, step:51, loss:  0.180240, precision:  0.833333, f1:  0.838926
epoch:3, step:52, loss:  0.162027, precision:  0.874074, f1:  0.887218
epoch:3, step:53, loss:  0.211363, precision:  0.754967, f1:  0.794425
epoch:3, step:54, loss:  0.138508, precision:  0.875000, f1:  0.871595
epoch:3, step:55, loss:  0.154057, precision:  0.907563, f1:  0.850394
epoch:3, step:56, loss:  0.203722, precision:  0.823529, f1:  0.777778
epoch:3, step:57, loss:  0.217838, precision:  0.830986, f1:  0.828070
epoch:3, step:58, loss:  0.212011, precision:  0.825175, f1:  0.830986
epoch:3, step:59, loss:  0.227986, precision:  0.811475, f1:  0.785714
epoch:3, step:60, loss:  0.156276, precision:  0.825175, f1:  0.842857
epoch:3, step:61, loss:  0.246794, precision:  0.800000, f1:  0.800000
epoch:3, step:62, loss:  0.214794, precision:  0.808511, f1:  0.780822
epoch:3, step:63, loss:  0.128926, precision:  0.905109, f1:  0.882562
epoch:3, step:64, loss:  0.231707, precision:  0.816176, f1:  0.787234
epoch:3, step:65, loss:  0.229315, precision:  0.806897, f1:  0.793220
epoch:3, step:66, loss:  0.219623, precision:  0.855172, f1:  0.807818
epoch:3, step:67, loss:  0.169757, precision:  0.878049, f1:  0.857143
epoch:3, step:68, loss:  0.128917, precision:  0.932836, f1:  0.905797
epoch:3, step:69, loss:  0.191760, precision:  0.801471, f1:  0.822641
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:08,  2.42it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.48it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.46it/s]Validating:  19%|█▉        | 4/21 [00:01<00:06,  2.44it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.39it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.42it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.50it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.47it/s]Validating:  43%|████▎     | 9/21 [00:03<00:04,  2.48it/s]Validating:  48%|████▊     | 10/21 [00:03<00:04,  2.69it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:03,  2.57it/s]Validating:  57%|█████▋    | 12/21 [00:04<00:03,  2.53it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.59it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:02,  2.53it/s]Validating:  71%|███████▏  | 15/21 [00:05<00:02,  2.53it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:01,  2.53it/s]Validating:  81%|████████  | 17/21 [00:06<00:01,  2.51it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.51it/s]Validating:  90%|█████████ | 19/21 [00:07<00:00,  2.41it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.43it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.59it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.52it/s]
epoch:3, step:70, loss:  0.194568, precision:  0.812030, f1:  0.827586
epoch:3, step:71, loss:  0.191655, precision:  0.872000, f1:  0.822641
epoch:3, step:72, loss:  0.158436, precision:  0.872881, f1:  0.854772
epoch:3, step:73, loss:  0.185242, precision:  0.926829, f1:  0.860377
epoch:3, step:74, loss:  0.194538, precision:  0.857143, f1:  0.790123
epoch:3, step:75, loss:  0.173889, precision:  0.908397, f1:  0.862319
epoch:3, step:76, loss:  0.188757, precision:  0.828767, f1:  0.843206
epoch:3, step:77, loss:  0.173905, precision:  0.855172, f1:  0.840678
epoch:3, step:78, loss:  0.199190, precision:  0.821138, f1:  0.808000
epoch:3, step:79, loss:  0.175258, precision:  0.860294, f1:  0.866667
epoch:3, step:80, loss:  0.213020, precision:  0.853147, f1:  0.835616
epoch:3, step:81, loss:  0.186187, precision:  0.864662, f1:  0.842491
epoch:3, step:82, loss:  0.193732, precision:  0.901408, f1:  0.833876
epoch:3, step:83, loss:  0.179942, precision:  0.870229, f1:  0.820144
epoch:3, step:84, loss:  0.182907, precision:  0.825806, f1:  0.836601
epoch:3, step:85, loss:  0.210740, precision:  0.850000, f1:  0.829268
epoch:3, step:86, loss:  0.211377, precision:  0.786207, f1:  0.802817
epoch:3, step:87, loss:  0.168218, precision:  0.842767, f1:  0.848101
epoch:3, step:88, loss:  0.241623, precision:  0.816327, f1:  0.781759
epoch:3, step:89, loss:  0.198111, precision:  0.800000, f1:  0.815686
epoch:3, step:90, loss:  0.208083, precision:  0.804688, f1:  0.751825
epoch:3, step:91, loss:  0.181637, precision:  0.825397, f1:  0.822134
epoch:3, step:92, loss:  0.208968, precision:  0.835938, f1:  0.792593
epoch:3, step:93, loss:  0.183477, precision:  0.889831, f1:  0.826772
epoch:3, step:94, loss:  0.203447, precision:  0.850394, f1:  0.805970
epoch:3, step:95, loss:  0.188779, precision:  0.822695, f1:  0.834532
epoch:3, step:96, loss:  0.184461, precision:  0.865248, f1:  0.859155
epoch:3, step:97, loss:  0.180687, precision:  0.837662, f1:  0.840391
epoch:3, step:98, loss:  0.219525, precision:  0.840580, f1:  0.808362
epoch:3, step:99, loss:  0.162544, precision:  0.873239, f1:  0.858131
epoch:3, step:100, loss:  0.179315, precision:  0.880000, f1:  0.859375
epoch:3, step:101, loss:  0.234839, precision:  0.792793, f1:  0.724280
epoch:3, step:102, loss:  0.254440, precision:  0.789474, f1:  0.776699
epoch:3, step:103, loss:  0.187512, precision:  0.835938, f1:  0.804511
epoch:3, step:104, loss:  0.162834, precision:  0.900901, f1:  0.833333
epoch:3, step:105, loss:  0.162641, precision:  0.835938, f1:  0.826255
epoch:3, step:106, loss:  0.240817, precision:  0.854167, f1:  0.809211
epoch:3, step:107, loss:  0.144171, precision:  0.902256, f1:  0.888889
epoch:3, step:108, loss:  0.235659, precision:  0.766667, f1:  0.790378
epoch:3, step:109, loss:  0.214042, precision:  0.833333, f1:  0.821429
epoch:3, step:110, loss:  0.207556, precision:  0.829630, f1:  0.826568
epoch:3, step:111, loss:  0.175004, precision:  0.870968, f1:  0.847059
epoch:3, step:112, loss:  0.171533, precision:  0.868852, f1:  0.824903
epoch:3, step:113, loss:  0.219860, precision:  0.876923, f1:  0.791667
epoch:3, step:114, loss:  0.243152, precision:  0.797203, f1:  0.770270
epoch:3, step:115, loss:  0.202529, precision:  0.816901, f1:  0.811189
epoch:3, step:116, loss:  0.214545, precision:  0.834711, f1:  0.792157
epoch:3, step:117, loss:  0.199739, precision:  0.794326, f1:  0.797153
epoch:3, step:118, loss:  0.188795, precision:  0.831169, f1:  0.850498
epoch:3, step:119, loss:  0.211358, precision:  0.833333, f1:  0.833333
epoch:3, step:120, loss:  0.174717, precision:  0.876712, f1:  0.861953
epoch:3, step:121, loss:  0.207685, precision:  0.905983, f1:  0.828125
epoch:3, step:122, loss:  0.200453, precision:  0.794872, f1:  0.768595
epoch:3, step:123, loss:  0.228010, precision:  0.762963, f1:  0.765799
epoch:3, step:124, loss:  0.234480, precision:  0.828358, f1:  0.790036
epoch:3, step:125, loss:  0.202461, precision:  0.847826, f1:  0.801370
epoch:3, step:126, loss:  0.230323, precision:  0.819549, f1:  0.784173
epoch:3, step:127, loss:  0.187577, precision:  0.828125, f1:  0.812261
epoch:3, step:128, loss:  0.198145, precision:  0.841772, f1:  0.841772
epoch:3, step:129, loss:  0.200185, precision:  0.824324, f1:  0.835616
epoch:3, step:130, loss:  0.271473, precision:  0.751825, f1:  0.730496
epoch:3, step:131, loss:  0.172976, precision:  0.899225, f1:  0.852941
epoch:3, step:132, loss:  0.194782, precision:  0.893443, f1:  0.835249
epoch:3, step:133, loss:  0.184876, precision:  0.897436, f1:  0.840000
epoch:3, step:134, loss:  0.217072, precision:  0.866667, f1:  0.790541
epoch:3, step:135, loss:  0.176961, precision:  0.864286, f1:  0.831615
epoch:3, step:136, loss:  0.174273, precision:  0.851852, f1:  0.862500
epoch:3, step:137, loss:  0.188558, precision:  0.835616, f1:  0.862191
epoch:3, step:138, loss:  0.205602, precision:  0.849315, f1:  0.858131
epoch:3, step:139, loss:  0.171481, precision:  0.840278, f1:  0.867384
epoch:3, step:140, loss:  0.194905, precision:  0.883721, f1:  0.860377
epoch:3, step:141, loss:  0.203446, precision:  0.884058, f1:  0.859155
epoch:3, step:142, loss:  0.156389, precision:  0.916667, f1:  0.883534
epoch:3, step:143, loss:  0.159489, precision:  0.900826, f1:  0.868526
epoch:3, step:144, loss:  0.194057, precision:  0.797203, f1:  0.802817
epoch:3, step:145, loss:  0.171741, precision:  0.834532, f1:  0.852941
epoch:3, step:146, loss:  0.186400, precision:  0.832258, f1:  0.837662
epoch:3, step:147, loss:  0.200579, precision:  0.871795, f1:  0.844720
epoch:3, step:148, loss:  0.144978, precision:  0.884298, f1:  0.877049
epoch:3, step:149, loss:  0.279365, precision:  0.821705, f1:  0.770909
epoch:3, step:150, loss:  0.195554, precision:  0.872340, f1:  0.848276
epoch:3, step:151, loss:  0.153348, precision:  0.880000, f1:  0.891892
epoch:3, step:152, loss:  0.183821, precision:  0.829787, f1:  0.835714
epoch:3, step:153, loss:  0.217188, precision:  0.785714, f1:  0.788274
epoch:3, step:154, loss:  0.195715, precision:  0.858065, f1:  0.839117
epoch:3, step:155, loss:  0.162000, precision:  0.883212, f1:  0.855124
epoch:3, step:156, loss:  0.240917, precision:  0.804688, f1:  0.754579
epoch:3, step:157, loss:  0.188157, precision:  0.869565, f1:  0.796813
epoch:3, step:158, loss:  0.203388, precision:  0.871212, f1:  0.848709
epoch:3, step:159, loss:  0.226445, precision:  0.782051, f1:  0.797386
epoch:3, step:160, loss:  0.140790, precision:  0.880282, f1:  0.889680
epoch:3, step:161, loss:  0.279182, precision:  0.786260, f1:  0.760148
epoch:3, step:162, loss:  0.215915, precision:  0.877863, f1:  0.824373
epoch:3, step:163, loss:  0.204438, precision:  0.816794, f1:  0.795539
epoch:3, step:164, loss:  0.171503, precision:  0.938053, f1:  0.831373
epoch:3, step:165, loss:  0.169662, precision:  0.871795, f1:  0.836066
epoch:3, step:166, loss:  0.178226, precision:  0.829630, f1:  0.832714
epoch:3, step:167, loss:  0.197450, precision:  0.832168, f1:  0.838028
epoch:3, valid_f1:  0.788019, valid_precision:  0.756571, valid_recall:  0.822740
epoch:4, step:0, loss:  0.141157, precision:  0.869281, f1:  0.863636
epoch:4, step:1, loss:  0.139222, precision:  0.843537, f1:  0.861111
epoch:4, step:2, loss:  0.161929, precision:  0.853503, f1:  0.872964
epoch:4, step:3, loss:  0.136123, precision:  0.913043, f1:  0.893617
epoch:4, step:4, loss:  0.157608, precision:  0.889831, f1:  0.840000
epoch:4, step:5, loss:  0.119619, precision:  0.918033, f1:  0.858238
epoch:4, step:6, loss:  0.161092, precision:  0.882353, f1:  0.863309
epoch:4, step:7, loss:  0.155416, precision:  0.897810, f1:  0.872340
epoch:4, step:8, loss:  0.120101, precision:  0.865546, f1:  0.876596
epoch:4, step:9, loss:  0.157117, precision:  0.897260, f1:  0.873333
epoch:4, step:10, loss:  0.151675, precision:  0.862319, f1:  0.850000
epoch:4, step:11, loss:  0.138636, precision:  0.840909, f1:  0.863813
epoch:4, step:12, loss:  0.181775, precision:  0.820144, f1:  0.826087
epoch:4, step:13, loss:  0.165591, precision:  0.841727, f1:  0.850909
epoch:4, step:14, loss:  0.171736, precision:  0.878378, f1:  0.858086
epoch:4, step:15, loss:  0.151314, precision:  0.855072, f1:  0.845878
epoch:4, step:16, loss:  0.177418, precision:  0.894309, f1:  0.849421
epoch:4, step:17, loss:  0.100992, precision:  0.905512, f1:  0.901961
epoch:4, step:18, loss:  0.154308, precision:  0.795620, f1:  0.819549
epoch:4, step:19, loss:  0.160448, precision:  0.869565, f1:  0.879121
epoch:4, step:20, loss:  0.182085, precision:  0.832168, f1:  0.843972
epoch:4, step:21, loss:  0.138592, precision:  0.900000, f1:  0.850394
epoch:4, step:22, loss:  0.132110, precision:  0.913386, f1:  0.875472
epoch:4, step:23, loss:  0.158561, precision:  0.868217, f1:  0.823529
epoch:4, step:24, loss:  0.138301, precision:  0.886364, f1:  0.850909
epoch:4, step:25, loss:  0.120472, precision:  0.847328, f1:  0.877470
epoch:4, step:26, loss:  0.160893, precision:  0.869565, f1:  0.880503
epoch:4, step:27, loss:  0.206997, precision:  0.808917, f1:  0.838284
epoch:4, step:28, loss:  0.183232, precision:  0.793103, f1:  0.807018
epoch:4, step:29, loss:  0.160197, precision:  0.866197, f1:  0.875445
epoch:4, step:30, loss:  0.130406, precision:  0.913386, f1:  0.878788
epoch:4, step:31, loss:  0.176909, precision:  0.858156, f1:  0.864286
epoch:4, step:32, loss:  0.177325, precision:  0.846774, f1:  0.833333
epoch:4, step:33, loss:  0.136017, precision:  0.908451, f1:  0.898955
epoch:4, step:34, loss:  0.145433, precision:  0.905512, f1:  0.884615
epoch:4, step:35, loss:  0.124959, precision:  0.883117, f1:  0.900662
epoch:4, step:36, loss:  0.105743, precision:  0.901515, f1:  0.904943
epoch:4, step:37, loss:  0.137566, precision:  0.894410, f1:  0.905660
epoch:4, step:38, loss:  0.198951, precision:  0.841060, f1:  0.849498
epoch:4, step:39, loss:  0.134425, precision:  0.940298, f1:  0.909747
epoch:4, step:40, loss:  0.148645, precision:  0.898551, f1:  0.879433
epoch:4, step:41, loss:  0.131337, precision:  0.910569, f1:  0.871595
epoch:4, step:42, loss:  0.217731, precision:  0.846154, f1:  0.795181
epoch:4, step:43, loss:  0.107350, precision:  0.887324, f1:  0.916364
epoch:4, step:44, loss:  0.238964, precision:  0.837500, f1:  0.848101
epoch:4, step:45, loss:  0.158721, precision:  0.865672, f1:  0.852941
epoch:4, step:46, loss:  0.120491, precision:  0.896000, f1:  0.878431
epoch:4, step:47, loss:  0.145993, precision:  0.905405, f1:  0.899329
epoch:4, step:48, loss:  0.208816, precision:  0.797386, f1:  0.794788
epoch:4, step:49, loss:  0.218176, precision:  0.812950, f1:  0.807143
epoch:4, step:50, loss:  0.164320, precision:  0.857143, f1:  0.868421
epoch:4, step:51, loss:  0.147405, precision:  0.901515, f1:  0.862319
epoch:4, step:52, loss:  0.138432, precision:  0.907895, f1:  0.893204
epoch:4, step:53, loss:  0.130161, precision:  0.917808, f1:  0.905405
epoch:4, step:54, loss:  0.141070, precision:  0.876712, f1:  0.885813
epoch:4, step:55, loss:  0.165338, precision:  0.845638, f1:  0.854237
epoch:4, step:56, loss:  0.159672, precision:  0.886667, f1:  0.886667
epoch:4, step:57, loss:  0.185212, precision:  0.865546, f1:  0.824000
epoch:4, step:58, loss:  0.146378, precision:  0.873016, f1:  0.866142
epoch:4, step:59, loss:  0.195655, precision:  0.875000, f1:  0.840989
epoch:4, step:60, loss:  0.168539, precision:  0.891156, f1:  0.861842
epoch:4, step:61, loss:  0.200934, precision:  0.857143, f1:  0.832117
epoch:4, step:62, loss:  0.147645, precision:  0.872611, f1:  0.867089
epoch:4, step:63, loss:  0.135877, precision:  0.847328, f1:  0.874016
epoch:4, step:64, loss:  0.138533, precision:  0.857143, f1:  0.871972
epoch:4, step:65, loss:  0.170591, precision:  0.822785, f1:  0.858086
epoch:4, step:66, loss:  0.152722, precision:  0.881481, f1:  0.850000
epoch:4, step:67, loss:  0.167255, precision:  0.885135, f1:  0.850649
epoch:4, step:68, loss:  0.136768, precision:  0.907692, f1:  0.890566
epoch:4, step:69, loss:  0.146159, precision:  0.904762, f1:  0.844444
epoch:4, step:70, loss:  0.139416, precision:  0.852941, f1:  0.856089
epoch:4, step:71, loss:  0.165405, precision:  0.883117, f1:  0.883117
epoch:4, step:72, loss:  0.179366, precision:  0.840491, f1:  0.869841
epoch:4, step:73, loss:  0.104746, precision:  0.894737, f1:  0.908397
epoch:4, step:74, loss:  0.153089, precision:  0.882353, f1:  0.846774
epoch:4, step:75, loss:  0.184789, precision:  0.884354, f1:  0.855263
epoch:4, step:76, loss:  0.215511, precision:  0.853846, f1:  0.825279
epoch:4, step:77, loss:  0.184648, precision:  0.862903, f1:  0.819923
epoch:4, step:78, loss:  0.136964, precision:  0.869565, f1:  0.895522
epoch:4, step:79, loss:  0.170713, precision:  0.821705, f1:  0.818533
epoch:4, step:80, loss:  0.143508, precision:  0.820000, f1:  0.851211
epoch:4, step:81, loss:  0.151105, precision:  0.881119, f1:  0.857143
epoch:4, step:82, loss:  0.183760, precision:  0.865672, f1:  0.843636
epoch:4, step:83, loss:  0.172635, precision:  0.853846, f1:  0.834586
epoch:4, step:84, loss:  0.159488, precision:  0.848101, f1:  0.858974
epoch:4, step:85, loss:  0.200256, precision:  0.787671, f1:  0.798611
epoch:4, step:86, loss:  0.123276, precision:  0.928571, f1:  0.915493
epoch:4, step:87, loss:  0.163883, precision:  0.873418, f1:  0.878981
epoch:4, step:88, loss:  0.176920, precision:  0.889655, f1:  0.871622
epoch:4, step:89, loss:  0.174837, precision:  0.881119, f1:  0.851351
epoch:4, step:90, loss:  0.212012, precision:  0.846667, f1:  0.811502
epoch:4, step:91, loss:  0.129017, precision:  0.858156, f1:  0.889706
epoch:4, step:92, loss:  0.167661, precision:  0.866667, f1:  0.880000
epoch:4, step:93, loss:  0.149275, precision:  0.897638, f1:  0.887160
epoch:4, step:94, loss:  0.148581, precision:  0.870968, f1:  0.870968
epoch:4, step:95, loss:  0.161998, precision:  0.895652, f1:  0.824000
epoch:4, step:96, loss:  0.181441, precision:  0.832117, f1:  0.841328
epoch:4, step:97, loss:  0.168481, precision:  0.894737, f1:  0.856115
epoch:4, step:98, loss:  0.121555, precision:  0.875000, f1:  0.884758
epoch:4, step:99, loss:  0.123833, precision:  0.861314, f1:  0.870849
epoch:4, step:100, loss:  0.139138, precision:  0.892086, f1:  0.885714
epoch:4, step:101, loss:  0.150177, precision:  0.882353, f1:  0.869565
epoch:4, step:102, loss:  0.115985, precision:  0.879195, f1:  0.900344
epoch:4, step:103, loss:  0.150190, precision:  0.904762, f1:  0.880795
epoch:4, step:104, loss:  0.123992, precision:  0.869565, f1:  0.892193
epoch:4, step:105, loss:  0.132213, precision:  0.902098, f1:  0.898955
epoch:4, step:106, loss:  0.147178, precision:  0.925926, f1:  0.912409
epoch:4, step:107, loss:  0.194499, precision:  0.838462, f1:  0.832061
epoch:4, step:108, loss:  0.129945, precision:  0.895833, f1:  0.886598
epoch:4, step:109, loss:  0.159274, precision:  0.863014, f1:  0.871972
epoch:4, step:110, loss:  0.156297, precision:  0.826087, f1:  0.832117
epoch:4, step:111, loss:  0.178487, precision:  0.839161, f1:  0.839161
epoch:4, step:112, loss:  0.144662, precision:  0.862319, f1:  0.853047
epoch:4, step:113, loss:  0.201783, precision:  0.806452, f1:  0.814332
epoch:4, step:114, loss:  0.152744, precision:  0.843537, f1:  0.846416
epoch:4, step:115, loss:  0.145738, precision:  0.865079, f1:  0.861660
epoch:4, step:116, loss:  0.157746, precision:  0.848000, f1:  0.848000
epoch:4, step:117, loss:  0.168029, precision:  0.915385, f1:  0.888060
epoch:4, step:118, loss:  0.180608, precision:  0.865248, f1:  0.844291
epoch:4, step:119, loss:  0.152802, precision:  0.863946, f1:  0.872852
epoch:4, step:120, loss:  0.193021, precision:  0.819444, f1:  0.822300
epoch:4, step:121, loss:  0.155905, precision:  0.862595, f1:  0.846442
epoch:4, step:122, loss:  0.141486, precision:  0.882812, f1:  0.882812
epoch:4, step:123, loss:  0.201589, precision:  0.891304, f1:  0.839590
epoch:4, step:124, loss:  0.161602, precision:  0.891473, f1:  0.848709
epoch:4, step:125, loss:  0.168410, precision:  0.863309, f1:  0.842105
epoch:4, step:126, loss:  0.177861, precision:  0.845070, f1:  0.857143
epoch:4, step:127, loss:  0.174704, precision:  0.834437, f1:  0.840000
epoch:4, step:128, loss:  0.161687, precision:  0.862903, f1:  0.852590
epoch:4, step:129, loss:  0.141870, precision:  0.903226, f1:  0.861538
epoch:4, step:130, loss:  0.172243, precision:  0.836066, f1:  0.816000
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.16it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.28it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.28it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.31it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.32it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.33it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.42it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.39it/s]Validating:  43%|████▎     | 9/21 [00:03<00:04,  2.41it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.41it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.42it/s]Validating:  57%|█████▋    | 12/21 [00:04<00:03,  2.55it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.45it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:02,  2.38it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.35it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.35it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.41it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.40it/s]Validating:  90%|█████████ | 19/21 [00:07<00:00,  2.37it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.53it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.46it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.41it/s]
epoch:4, step:131, loss:  0.170277, precision:  0.910959, f1:  0.883721
epoch:4, step:132, loss:  0.166622, precision:  0.895522, f1:  0.857143
epoch:4, step:133, loss:  0.202055, precision:  0.843137, f1:  0.829582
epoch:4, step:134, loss:  0.281676, precision:  0.740964, f1:  0.763975
epoch:4, step:135, loss:  0.168821, precision:  0.801471, f1:  0.816479
epoch:4, step:136, loss:  0.171247, precision:  0.875000, f1:  0.863636
epoch:4, step:137, loss:  0.146511, precision:  0.898438, f1:  0.871212
epoch:4, step:138, loss:  0.164480, precision:  0.875969, f1:  0.843284
epoch:4, step:139, loss:  0.188955, precision:  0.869231, f1:  0.821818
epoch:4, step:140, loss:  0.157789, precision:  0.846154, f1:  0.852713
epoch:4, step:141, loss:  0.180317, precision:  0.880000, f1:  0.857143
epoch:4, step:142, loss:  0.140641, precision:  0.843750, f1:  0.843750
epoch:4, step:143, loss:  0.194324, precision:  0.822695, f1:  0.802768
epoch:4, step:144, loss:  0.180807, precision:  0.845638, f1:  0.848485
epoch:4, step:145, loss:  0.140560, precision:  0.886179, f1:  0.858268
epoch:4, step:146, loss:  0.130517, precision:  0.889706, f1:  0.883212
epoch:4, step:147, loss:  0.149462, precision:  0.909091, f1:  0.879121
epoch:4, step:148, loss:  0.157482, precision:  0.883562, f1:  0.877551
epoch:4, step:149, loss:  0.157237, precision:  0.904762, f1:  0.853933
epoch:4, step:150, loss:  0.177689, precision:  0.850746, f1:  0.844444
epoch:4, step:151, loss:  0.140730, precision:  0.863014, f1:  0.865979
epoch:4, step:152, loss:  0.120653, precision:  0.872483, f1:  0.890411
epoch:4, step:153, loss:  0.111878, precision:  0.893443, f1:  0.897119
epoch:4, step:154, loss:  0.149836, precision:  0.852941, f1:  0.852941
epoch:4, step:155, loss:  0.169815, precision:  0.875912, f1:  0.845070
epoch:4, step:156, loss:  0.176739, precision:  0.880282, f1:  0.853242
epoch:4, step:157, loss:  0.155445, precision:  0.892617, f1:  0.883721
epoch:4, step:158, loss:  0.139477, precision:  0.897436, f1:  0.860656
epoch:4, step:159, loss:  0.158440, precision:  0.846154, f1:  0.851613
epoch:4, step:160, loss:  0.139183, precision:  0.894737, f1:  0.875537
epoch:4, step:161, loss:  0.184405, precision:  0.874126, f1:  0.862069
epoch:4, step:162, loss:  0.122683, precision:  0.883212, f1:  0.886447
epoch:4, step:163, loss:  0.148330, precision:  0.856000, f1:  0.856000
epoch:4, step:164, loss:  0.122972, precision:  0.907143, f1:  0.897527
epoch:4, step:165, loss:  0.153414, precision:  0.870504, f1:  0.867384
epoch:4, step:166, loss:  0.179592, precision:  0.840764, f1:  0.854369
epoch:4, step:167, loss:  0.198670, precision:  0.813953, f1:  0.840000
epoch:4, valid_f1:  0.791510, valid_precision:  0.766905, valid_recall:  0.818339
epoch:5, step:0, loss:  0.096200, precision:  0.855172, f1:  0.901818
epoch:5, step:1, loss:  0.105169, precision:  0.914894, f1:  0.921429
epoch:5, step:2, loss:  0.153952, precision:  0.898551, f1:  0.846416
epoch:5, step:3, loss:  0.096242, precision:  0.971831, f1:  0.932432
epoch:5, step:4, loss:  0.151878, precision:  0.874016, f1:  0.860465
epoch:5, step:5, loss:  0.136391, precision:  0.910448, f1:  0.887273
epoch:5, step:6, loss:  0.115978, precision:  0.893750, f1:  0.913738
epoch:5, step:7, loss:  0.181190, precision:  0.894410, f1:  0.894410
epoch:5, step:8, loss:  0.149017, precision:  0.880000, f1:  0.904110
epoch:5, step:9, loss:  0.119577, precision:  0.867188, f1:  0.880952
epoch:5, step:10, loss:  0.136988, precision:  0.880952, f1:  0.850575
epoch:5, step:11, loss:  0.100345, precision:  0.921739, f1:  0.913793
epoch:5, step:12, loss:  0.130780, precision:  0.851852, f1:  0.855019
epoch:5, step:13, loss:  0.106202, precision:  0.916031, f1:  0.898876
epoch:5, step:14, loss:  0.119102, precision:  0.914286, f1:  0.888889
epoch:5, step:15, loss:  0.123818, precision:  0.926230, f1:  0.904000
epoch:5, step:16, loss:  0.122848, precision:  0.874074, f1:  0.867647
epoch:5, step:17, loss:  0.143219, precision:  0.889655, f1:  0.895833
epoch:5, step:18, loss:  0.103102, precision:  0.871622, f1:  0.889655
epoch:5, step:19, loss:  0.131684, precision:  0.898551, f1:  0.879433
epoch:5, step:20, loss:  0.125023, precision:  0.865385, f1:  0.885246
epoch:5, step:21, loss:  0.115569, precision:  0.913386, f1:  0.885496
epoch:5, step:22, loss:  0.115021, precision:  0.893617, f1:  0.890459
epoch:5, step:23, loss:  0.157955, precision:  0.935484, f1:  0.888889
epoch:5, step:24, loss:  0.088331, precision:  0.937063, f1:  0.927336
epoch:5, step:25, loss:  0.109026, precision:  0.892617, f1:  0.910959
epoch:5, step:26, loss:  0.100834, precision:  0.905882, f1:  0.919403
epoch:5, step:27, loss:  0.126326, precision:  0.835616, f1:  0.884058
epoch:5, step:28, loss:  0.158274, precision:  0.843537, f1:  0.870175
epoch:5, step:29, loss:  0.123641, precision:  0.930233, f1:  0.905660
epoch:5, step:30, loss:  0.101786, precision:  0.923611, f1:  0.907850
epoch:5, step:31, loss:  0.088219, precision:  0.946108, f1:  0.946108
epoch:5, step:32, loss:  0.115281, precision:  0.866667, f1:  0.893471
epoch:5, step:33, loss:  0.111017, precision:  0.885246, f1:  0.885246
epoch:5, step:34, loss:  0.139980, precision:  0.911565, f1:  0.884488
epoch:5, step:35, loss:  0.130748, precision:  0.881579, f1:  0.890365
epoch:5, step:36, loss:  0.066947, precision:  0.960784, f1:  0.970297
epoch:5, step:37, loss:  0.127055, precision:  0.860140, f1:  0.901099
epoch:5, step:38, loss:  0.159383, precision:  0.838710, f1:  0.881356
epoch:5, step:39, loss:  0.130964, precision:  0.896104, f1:  0.907895
epoch:5, step:40, loss:  0.148897, precision:  0.885714, f1:  0.870175
epoch:5, step:41, loss:  0.084113, precision:  0.950413, f1:  0.894942
epoch:5, step:42, loss:  0.168113, precision:  0.912409, f1:  0.844595
epoch:5, step:43, loss:  0.156273, precision:  0.927632, f1:  0.886792
epoch:5, step:44, loss:  0.141288, precision:  0.862319, f1:  0.881481
epoch:5, step:45, loss:  0.128974, precision:  0.839416, f1:  0.851852
epoch:5, step:46, loss:  0.195561, precision:  0.819355, f1:  0.841060
epoch:5, step:47, loss:  0.124551, precision:  0.872180, f1:  0.888889
epoch:5, step:48, loss:  0.112935, precision:  0.896825, f1:  0.882812
epoch:5, step:49, loss:  0.120061, precision:  0.869565, f1:  0.898876
epoch:5, step:50, loss:  0.139646, precision:  0.937931, f1:  0.888889
epoch:5, step:51, loss:  0.117379, precision:  0.928058, f1:  0.905263
epoch:5, step:52, loss:  0.102468, precision:  0.932773, f1:  0.898785
epoch:5, step:53, loss:  0.123628, precision:  0.916084, f1:  0.912892
epoch:5, step:54, loss:  0.137848, precision:  0.907285, f1:  0.898361
epoch:5, step:55, loss:  0.137753, precision:  0.855072, f1:  0.864469
epoch:5, step:56, loss:  0.122261, precision:  0.841727, f1:  0.869888
epoch:5, step:57, loss:  0.120636, precision:  0.885350, f1:  0.899676
epoch:5, step:58, loss:  0.114990, precision:  0.901515, f1:  0.898113
epoch:5, step:59, loss:  0.135421, precision:  0.895522, f1:  0.888889
epoch:5, step:60, loss:  0.145054, precision:  0.868056, f1:  0.859107
epoch:5, step:61, loss:  0.167906, precision:  0.912162, f1:  0.888158
epoch:5, step:62, loss:  0.098061, precision:  0.916667, f1:  0.899628
epoch:5, step:63, loss:  0.113031, precision:  0.927007, f1:  0.894366
epoch:5, step:64, loss:  0.120328, precision:  0.926175, f1:  0.904918
epoch:5, step:65, loss:  0.105672, precision:  0.866197, f1:  0.897810
epoch:5, step:66, loss:  0.114541, precision:  0.869565, f1:  0.900322
epoch:5, step:67, loss:  0.099518, precision:  0.893617, f1:  0.896797
epoch:5, step:68, loss:  0.162286, precision:  0.840000, f1:  0.842809
epoch:5, step:69, loss:  0.144261, precision:  0.920530, f1:  0.891026
epoch:5, step:70, loss:  0.137559, precision:  0.883721, f1:  0.873563
epoch:5, step:71, loss:  0.117930, precision:  0.943262, f1:  0.923611
epoch:5, step:72, loss:  0.086128, precision:  0.942857, f1:  0.929577
epoch:5, step:73, loss:  0.181522, precision:  0.781250, f1:  0.806452
epoch:5, step:74, loss:  0.100117, precision:  0.893939, f1:  0.914729
epoch:5, step:75, loss:  0.119521, precision:  0.886667, f1:  0.889632
epoch:5, step:76, loss:  0.115479, precision:  0.895105, f1:  0.901408
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:07,  2.72it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.58it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.52it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.41it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.41it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.47it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.43it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.39it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.31it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.22it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.17it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.12it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.20it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.16it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.33it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.30it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.25it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.22it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.20it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.28it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.25it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.28it/s]
epoch:5, step:77, loss:  0.096321, precision:  0.906977, f1:  0.906977
epoch:5, step:78, loss:  0.129911, precision:  0.926471, f1:  0.903226
epoch:5, step:79, loss:  0.119931, precision:  0.925676, f1:  0.904290
epoch:5, step:80, loss:  0.097344, precision:  0.938356, f1:  0.928814
epoch:5, step:81, loss:  0.091138, precision:  0.947368, f1:  0.947368
epoch:5, step:82, loss:  0.170112, precision:  0.855172, f1:  0.864111
epoch:5, step:83, loss:  0.136686, precision:  0.881944, f1:  0.894366
epoch:5, step:84, loss:  0.145721, precision:  0.869863, f1:  0.878893
epoch:5, step:85, loss:  0.103619, precision:  0.916667, f1:  0.902985
epoch:5, step:86, loss:  0.086664, precision:  0.923664, f1:  0.906367
epoch:5, step:87, loss:  0.113668, precision:  0.923611, f1:  0.898649
epoch:5, step:88, loss:  0.124780, precision:  0.917808, f1:  0.911565
epoch:5, step:89, loss:  0.147319, precision:  0.894737, f1:  0.885993
epoch:5, step:90, loss:  0.094308, precision:  0.907895, f1:  0.913907
epoch:5, step:91, loss:  0.137892, precision:  0.865079, f1:  0.872000
epoch:5, step:92, loss:  0.149434, precision:  0.862319, f1:  0.878229
epoch:5, step:93, loss:  0.129731, precision:  0.878205, f1:  0.883871
epoch:5, step:94, loss:  0.114509, precision:  0.854305, f1:  0.902098
epoch:5, step:95, loss:  0.118550, precision:  0.879699, f1:  0.886364
epoch:5, step:96, loss:  0.145950, precision:  0.873333, f1:  0.879195
epoch:5, step:97, loss:  0.144716, precision:  0.886525, f1:  0.865052
epoch:5, step:98, loss:  0.128958, precision:  0.912162, f1:  0.903010
epoch:5, step:99, loss:  0.114908, precision:  0.927536, f1:  0.898246
epoch:5, step:100, loss:  0.128612, precision:  0.845161, f1:  0.876254
epoch:5, step:101, loss:  0.139047, precision:  0.864865, f1:  0.867797
epoch:5, step:102, loss:  0.105454, precision:  0.868421, f1:  0.901024
epoch:5, step:103, loss:  0.094764, precision:  0.915385, f1:  0.926070
epoch:5, step:104, loss:  0.120609, precision:  0.903448, f1:  0.903448
epoch:5, step:105, loss:  0.114628, precision:  0.901786, f1:  0.897778
epoch:5, step:106, loss:  0.169013, precision:  0.896296, f1:  0.876812
epoch:5, step:107, loss:  0.105579, precision:  0.943089, f1:  0.902724
epoch:5, step:108, loss:  0.148337, precision:  0.883212, f1:  0.883212
epoch:5, step:109, loss:  0.157343, precision:  0.874172, f1:  0.877076
epoch:5, step:110, loss:  0.117858, precision:  0.864286, f1:  0.876812
epoch:5, step:111, loss:  0.119195, precision:  0.930435, f1:  0.887967
epoch:5, step:112, loss:  0.166589, precision:  0.846715, f1:  0.846715
epoch:5, step:113, loss:  0.092327, precision:  0.924242, f1:  0.927757
epoch:5, step:114, loss:  0.151613, precision:  0.845638, f1:  0.871972
epoch:5, step:115, loss:  0.151591, precision:  0.857143, f1:  0.875912
epoch:5, step:116, loss:  0.161988, precision:  0.832168, f1:  0.832168
epoch:5, step:117, loss:  0.106236, precision:  0.902098, f1:  0.892734
epoch:5, step:118, loss:  0.109705, precision:  0.891473, f1:  0.888031
epoch:5, step:119, loss:  0.151087, precision:  0.912409, f1:  0.874126
epoch:5, step:120, loss:  0.133276, precision:  0.906977, f1:  0.876405
epoch:5, step:121, loss:  0.153320, precision:  0.875912, f1:  0.869565
epoch:5, step:122, loss:  0.150717, precision:  0.903226, f1:  0.864865
epoch:5, step:123, loss:  0.128781, precision:  0.842105, f1:  0.861953
epoch:5, step:124, loss:  0.140032, precision:  0.851351, f1:  0.871972
epoch:5, step:125, loss:  0.122990, precision:  0.924528, f1:  0.915888
epoch:5, step:126, loss:  0.118759, precision:  0.855263, f1:  0.884354
epoch:5, step:127, loss:  0.115674, precision:  0.874074, f1:  0.883895
epoch:5, step:128, loss:  0.107487, precision:  0.925000, f1:  0.898785
epoch:5, step:129, loss:  0.156610, precision:  0.889706, f1:  0.849123
epoch:5, step:130, loss:  0.087390, precision:  0.939189, f1:  0.920530
epoch:5, step:131, loss:  0.142769, precision:  0.891304, f1:  0.878571
epoch:5, step:132, loss:  0.102145, precision:  0.909091, f1:  0.905923
epoch:5, step:133, loss:  0.108128, precision:  0.916667, f1:  0.913495
epoch:5, step:134, loss:  0.109240, precision:  0.902778, f1:  0.902778
epoch:5, step:135, loss:  0.134254, precision:  0.876712, f1:  0.885813
epoch:5, step:136, loss:  0.118131, precision:  0.900000, f1:  0.893617
epoch:5, step:137, loss:  0.096637, precision:  0.921986, f1:  0.909091
epoch:5, step:138, loss:  0.105023, precision:  0.910448, f1:  0.917293
epoch:5, step:139, loss:  0.174124, precision:  0.858209, f1:  0.839416
epoch:5, step:140, loss:  0.173476, precision:  0.864286, f1:  0.846154
epoch:5, step:141, loss:  0.102143, precision:  0.902098, f1:  0.898955
epoch:5, step:142, loss:  0.158161, precision:  0.897810, f1:  0.863158
epoch:5, step:143, loss:  0.134224, precision:  0.927419, f1:  0.888031
epoch:5, step:144, loss:  0.147661, precision:  0.872611, f1:  0.869841
epoch:5, step:145, loss:  0.099081, precision:  0.909774, f1:  0.899628
epoch:5, step:146, loss:  0.152815, precision:  0.868056, f1:  0.874126
epoch:5, step:147, loss:  0.154780, precision:  0.871429, f1:  0.853147
epoch:5, step:148, loss:  0.100966, precision:  0.889764, f1:  0.900398
epoch:5, step:149, loss:  0.138693, precision:  0.849315, f1:  0.861111
epoch:5, step:150, loss:  0.129890, precision:  0.893617, f1:  0.896797
epoch:5, step:151, loss:  0.194625, precision:  0.859155, f1:  0.838488
epoch:5, step:152, loss:  0.117370, precision:  0.874074, f1:  0.897338
epoch:5, step:153, loss:  0.148704, precision:  0.921429, f1:  0.874576
epoch:5, step:154, loss:  0.139452, precision:  0.875912, f1:  0.872727
epoch:5, step:155, loss:  0.122420, precision:  0.891156, f1:  0.906574
epoch:5, step:156, loss:  0.101176, precision:  0.909836, f1:  0.877470
epoch:5, step:157, loss:  0.118881, precision:  0.874126, f1:  0.880282
epoch:5, step:158, loss:  0.181103, precision:  0.814286, f1:  0.835165
epoch:5, step:159, loss:  0.129736, precision:  0.838462, f1:  0.832061
epoch:5, step:160, loss:  0.118792, precision:  0.892617, f1:  0.895623
epoch:5, step:161, loss:  0.106072, precision:  0.907692, f1:  0.904215
epoch:5, step:162, loss:  0.098774, precision:  0.932836, f1:  0.899281
epoch:5, step:163, loss:  0.094140, precision:  0.920290, f1:  0.910394
epoch:5, step:164, loss:  0.132317, precision:  0.845070, f1:  0.866426
epoch:5, step:165, loss:  0.172954, precision:  0.846667, f1:  0.858108
epoch:5, step:166, loss:  0.153260, precision:  0.863014, f1:  0.865979
epoch:5, step:167, loss:  0.138355, precision:  0.853846, f1:  0.860465
epoch:5, valid_f1:  0.787271, valid_precision:  0.774948, valid_recall:  0.800678
epoch:6, step:0, loss:  0.136188, precision:  0.860927, f1:  0.881356
epoch:6, step:1, loss:  0.128494, precision:  0.909722, f1:  0.891156
epoch:6, step:2, loss:  0.108342, precision:  0.891473, f1:  0.888031
epoch:6, step:3, loss:  0.072298, precision:  0.957447, f1:  0.947368
epoch:6, step:4, loss:  0.083991, precision:  0.974684, f1:  0.977778
epoch:6, step:5, loss:  0.100774, precision:  0.863309, f1:  0.882353
epoch:6, step:6, loss:  0.103857, precision:  0.888889, f1:  0.902256
epoch:6, step:7, loss:  0.101653, precision:  0.896000, f1:  0.906883
epoch:6, step:8, loss:  0.083734, precision:  0.900000, f1:  0.907563
epoch:6, step:9, loss:  0.087720, precision:  0.946667, f1:  0.922078
epoch:6, step:10, loss:  0.084689, precision:  0.897059, f1:  0.903704
epoch:6, step:11, loss:  0.110733, precision:  0.907143, f1:  0.907143
epoch:6, step:12, loss:  0.085592, precision:  0.898649, f1:  0.917241
epoch:6, step:13, loss:  0.141640, precision:  0.901408, f1:  0.879725
epoch:6, step:14, loss:  0.104821, precision:  0.895105, f1:  0.907801
epoch:6, step:15, loss:  0.074610, precision:  0.963768, f1:  0.953405
epoch:6, step:16, loss:  0.100733, precision:  0.940000, f1:  0.943144
epoch:6, step:17, loss:  0.115461, precision:  0.848485, f1:  0.877743
epoch:6, step:18, loss:  0.063381, precision:  0.957747, f1:  0.954386
epoch:6, step:19, loss:  0.109332, precision:  0.876712, f1:  0.885813
epoch:6, step:20, loss:  0.095123, precision:  0.930556, f1:  0.930556
epoch:6, step:21, loss:  0.131758, precision:  0.919463, f1:  0.898361
epoch:6, step:22, loss:  0.110007, precision:  0.888112, f1:  0.900709
epoch:6, step:23, loss:  0.090462, precision:  0.946970, f1:  0.919118
epoch:6, step:24, loss:  0.107742, precision:  0.927007, f1:  0.916968
epoch:6, step:25, loss:  0.096568, precision:  0.901408, f1:  0.914286
epoch:6, step:26, loss:  0.079919, precision:  0.911111, f1:  0.928302
epoch:6, step:27, loss:  0.120589, precision:  0.890805, f1:  0.909091
epoch:6, step:28, loss:  0.096146, precision:  0.914894, f1:  0.914894
epoch:6, step:29, loss:  0.115682, precision:  0.851562, f1:  0.865079
epoch:6, step:30, loss:  0.141722, precision:  0.850340, f1:  0.868056
epoch:6, step:31, loss:  0.095877, precision:  0.946154, f1:  0.907749
epoch:6, step:32, loss:  0.113022, precision:  0.928571, f1:  0.915493
epoch:6, step:33, loss:  0.151100, precision:  0.887324, f1:  0.884211
epoch:6, step:34, loss:  0.127462, precision:  0.886364, f1:  0.876405
epoch:6, step:35, loss:  0.112486, precision:  0.923077, f1:  0.912548
epoch:6, step:36, loss:  0.101659, precision:  0.949367, f1:  0.931677
epoch:6, step:37, loss:  0.123579, precision:  0.940741, f1:  0.913669
epoch:6, step:38, loss:  0.102116, precision:  0.881579, f1:  0.914676
epoch:6, step:39, loss:  0.074796, precision:  0.971429, f1:  0.964539
epoch:6, step:40, loss:  0.056975, precision:  0.958042, f1:  0.954704
epoch:6, step:41, loss:  0.079223, precision:  0.923664, f1:  0.920152
epoch:6, step:42, loss:  0.143083, precision:  0.835616, f1:  0.853147
epoch:6, step:43, loss:  0.117261, precision:  0.960630, f1:  0.924242
epoch:6, step:44, loss:  0.079894, precision:  0.961832, f1:  0.943820
epoch:6, step:45, loss:  0.089243, precision:  0.938462, f1:  0.938462
epoch:6, step:46, loss:  0.066345, precision:  0.940298, f1:  0.947368
epoch:6, step:47, loss:  0.096197, precision:  0.908497, f1:  0.917492
epoch:6, step:48, loss:  0.148957, precision:  0.823529, f1:  0.865979
epoch:6, step:49, loss:  0.106334, precision:  0.912162, f1:  0.927835
epoch:6, step:50, loss:  0.072769, precision:  0.948387, f1:  0.951456
epoch:6, step:51, loss:  0.089989, precision:  0.946154, f1:  0.928302
epoch:6, step:52, loss:  0.081823, precision:  0.928058, f1:  0.924731
epoch:6, step:53, loss:  0.103555, precision:  0.955882, f1:  0.915493
epoch:6, step:54, loss:  0.079461, precision:  0.950413, f1:  0.938776
epoch:6, step:55, loss:  0.138819, precision:  0.861314, f1:  0.851986
epoch:6, step:56, loss:  0.123274, precision:  0.895105, f1:  0.904594
epoch:6, step:57, loss:  0.092723, precision:  0.908451, f1:  0.911661
epoch:6, step:58, loss:  0.050958, precision:  0.956204, f1:  0.963235
epoch:6, step:59, loss:  0.072489, precision:  0.909677, f1:  0.936877
epoch:6, step:60, loss:  0.081197, precision:  0.933333, f1:  0.939597
epoch:6, step:61, loss:  0.106810, precision:  0.912752, f1:  0.922034
epoch:6, step:62, loss:  0.091248, precision:  0.940000, f1:  0.936877
epoch:6, step:63, loss:  0.072732, precision:  0.937063, f1:  0.937063
epoch:6, step:64, loss:  0.070465, precision:  0.979452, f1:  0.959732
epoch:6, step:65, loss:  0.108367, precision:  0.905512, f1:  0.905512
epoch:6, step:66, loss:  0.083520, precision:  0.907801, f1:  0.924188
epoch:6, step:67, loss:  0.122433, precision:  0.896774, f1:  0.905537
epoch:6, step:68, loss:  0.089424, precision:  0.935484, f1:  0.935484
epoch:6, step:69, loss:  0.099416, precision:  0.923077, f1:  0.941176
epoch:6, step:70, loss:  0.095060, precision:  0.900000, f1:  0.906475
epoch:6, step:71, loss:  0.101921, precision:  0.923077, f1:  0.932862
epoch:6, step:72, loss:  0.088348, precision:  0.921788, f1:  0.932203
epoch:6, step:73, loss:  0.125312, precision:  0.874214, f1:  0.888179
epoch:6, step:74, loss:  0.095626, precision:  0.927007, f1:  0.916968
epoch:6, step:75, loss:  0.082762, precision:  0.931298, f1:  0.920755
epoch:6, step:76, loss:  0.089996, precision:  0.922535, f1:  0.925795
epoch:6, step:77, loss:  0.099127, precision:  0.925373, f1:  0.892086
epoch:6, step:78, loss:  0.060706, precision:  0.944056, f1:  0.954064
epoch:6, step:79, loss:  0.104522, precision:  0.894737, f1:  0.916168
epoch:6, step:80, loss:  0.132436, precision:  0.824324, f1:  0.862191
epoch:6, step:81, loss:  0.097716, precision:  0.880000, f1:  0.910345
epoch:6, step:82, loss:  0.081281, precision:  0.939850, f1:  0.943396
epoch:6, step:83, loss:  0.105711, precision:  0.909722, f1:  0.916084
epoch:6, step:84, loss:  0.118833, precision:  0.886364, f1:  0.873134
epoch:6, step:85, loss:  0.096552, precision:  0.941176, f1:  0.899598
epoch:6, step:86, loss:  0.101492, precision:  0.931818, f1:  0.928302
epoch:6, step:87, loss:  0.095890, precision:  0.902597, f1:  0.914474
epoch:6, step:88, loss:  0.120675, precision:  0.905405, f1:  0.911565
epoch:6, step:89, loss:  0.104236, precision:  0.907285, f1:  0.916388
epoch:6, step:90, loss:  0.124404, precision:  0.865772, f1:  0.877551
epoch:6, step:91, loss:  0.077627, precision:  0.891892, f1:  0.926316
epoch:6, step:92, loss:  0.089833, precision:  0.860140, f1:  0.904412
epoch:6, step:93, loss:  0.101943, precision:  0.917241, f1:  0.914089
epoch:6, step:94, loss:  0.087508, precision:  0.938053, f1:  0.917749
epoch:6, step:95, loss:  0.086069, precision:  0.924242, f1:  0.938462
epoch:6, step:96, loss:  0.091501, precision:  0.957747, f1:  0.928328
epoch:6, step:97, loss:  0.116157, precision:  0.917722, f1:  0.917722
epoch:6, step:98, loss:  0.069839, precision:  0.928571, f1:  0.942029
epoch:6, step:99, loss:  0.081651, precision:  0.908537, f1:  0.931250
epoch:6, step:100, loss:  0.101606, precision:  0.904459, f1:  0.922078
epoch:6, step:101, loss:  0.107202, precision:  0.913043, f1:  0.909747
epoch:6, step:102, loss:  0.119964, precision:  0.863636, f1:  0.890625
epoch:6, step:103, loss:  0.096400, precision:  0.912162, f1:  0.921502
epoch:6, step:104, loss:  0.094356, precision:  0.894309, f1:  0.894309
epoch:6, step:105, loss:  0.083726, precision:  0.931973, f1:  0.925676
epoch:6, step:106, loss:  0.092919, precision:  0.902778, f1:  0.905923
epoch:6, step:107, loss:  0.073939, precision:  0.933775, f1:  0.949495
epoch:6, step:108, loss:  0.105507, precision:  0.919463, f1:  0.928814
epoch:6, step:109, loss:  0.105060, precision:  0.885350, f1:  0.911475
epoch:6, step:110, loss:  0.080725, precision:  0.916667, f1:  0.936170
epoch:6, step:111, loss:  0.115618, precision:  0.932432, f1:  0.913907
epoch:6, step:112, loss:  0.133582, precision:  0.850299, f1:  0.879257
epoch:6, step:113, loss:  0.077464, precision:  0.942029, f1:  0.935252
epoch:6, step:114, loss:  0.199097, precision:  0.830065, f1:  0.838284
epoch:6, step:115, loss:  0.078722, precision:  0.928571, f1:  0.928571
epoch:6, step:116, loss:  0.098206, precision:  0.907285, f1:  0.922559
epoch:6, step:117, loss:  0.122532, precision:  0.924812, f1:  0.878571
epoch:6, step:118, loss:  0.142345, precision:  0.876812, f1:  0.867384
epoch:6, step:119, loss:  0.085933, precision:  0.932331, f1:  0.928839
epoch:6, step:120, loss:  0.075706, precision:  0.940741, f1:  0.947761
epoch:6, step:121, loss:  0.136188, precision:  0.886076, f1:  0.909091
epoch:6, step:122, loss:  0.150955, precision:  0.820144, f1:  0.857143
epoch:6, step:123, loss:  0.105369, precision:  0.890511, f1:  0.893773
epoch:6, step:124, loss:  0.141436, precision:  0.831081, f1:  0.857143
epoch:6, step:125, loss:  0.087459, precision:  0.930769, f1:  0.920152
epoch:6, step:126, loss:  0.180362, precision:  0.882759, f1:  0.839344
epoch:6, step:127, loss:  0.117709, precision:  0.896000, f1:  0.878431
epoch:6, step:128, loss:  0.097878, precision:  0.970803, f1:  0.933333
epoch:6, step:129, loss:  0.128478, precision:  0.898649, f1:  0.889632
epoch:6, step:130, loss:  0.110976, precision:  0.895425, f1:  0.913333
epoch:6, step:131, loss:  0.059710, precision:  0.960265, f1:  0.960265
epoch:6, step:132, loss:  0.119642, precision:  0.815603, f1:  0.867925
epoch:6, step:133, loss:  0.082291, precision:  0.909091, f1:  0.935252
epoch:6, step:134, loss:  0.072486, precision:  0.922535, f1:  0.935714
epoch:6, step:135, loss:  0.128071, precision:  0.890511, f1:  0.887273
epoch:6, step:136, loss:  0.080422, precision:  0.923077, f1:  0.920128
epoch:6, step:137, loss:  0.101695, precision:  0.933884, f1:  0.886275
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.06it/s]Validating:  10%|▉         | 2/21 [00:00<00:09,  2.10it/s]Validating:  14%|█▍        | 3/21 [00:01<00:08,  2.06it/s]Validating:  19%|█▉        | 4/21 [00:01<00:08,  2.09it/s]Validating:  24%|██▍       | 5/21 [00:02<00:07,  2.14it/s]Validating:  29%|██▊       | 6/21 [00:02<00:07,  2.08it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.15it/s]Validating:  38%|███▊      | 8/21 [00:03<00:06,  2.02it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.14it/s]Validating:  48%|████▊     | 10/21 [00:04<00:05,  2.18it/s]Validating:  52%|█████▏    | 11/21 [00:05<00:04,  2.16it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.11it/s]Validating:  62%|██████▏   | 13/21 [00:06<00:03,  2.13it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.29it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.26it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.31it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.29it/s]Validating:  86%|████████▌ | 18/21 [00:08<00:01,  2.25it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.29it/s]Validating:  95%|█████████▌| 20/21 [00:09<00:00,  2.25it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.36it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.21it/s]
epoch:6, step:138, loss:  0.097688, precision:  0.936170, f1:  0.926316
epoch:6, step:139, loss:  0.151293, precision:  0.892405, f1:  0.870370
epoch:6, step:140, loss:  0.106964, precision:  0.930233, f1:  0.919540
epoch:6, step:141, loss:  0.064511, precision:  0.906977, f1:  0.928571
epoch:6, step:142, loss:  0.171932, precision:  0.853503, f1:  0.864516
epoch:6, step:143, loss:  0.122358, precision:  0.872483, f1:  0.902778
epoch:6, step:144, loss:  0.076344, precision:  0.902256, f1:  0.919540
epoch:6, step:145, loss:  0.096350, precision:  0.944444, f1:  0.944444
epoch:6, step:146, loss:  0.121900, precision:  0.892617, f1:  0.898649
epoch:6, step:147, loss:  0.133085, precision:  0.919355, f1:  0.863636
epoch:6, step:148, loss:  0.109129, precision:  0.943548, f1:  0.896552
epoch:6, step:149, loss:  0.124793, precision:  0.907143, f1:  0.907143
epoch:6, step:150, loss:  0.090812, precision:  0.914062, f1:  0.906977
epoch:6, step:151, loss:  0.090934, precision:  0.936620, f1:  0.930070
epoch:6, step:152, loss:  0.089409, precision:  0.881988, f1:  0.925081
epoch:6, step:153, loss:  0.118570, precision:  0.920530, f1:  0.905537
epoch:6, step:154, loss:  0.097410, precision:  0.907692, f1:  0.904215
epoch:6, step:155, loss:  0.072676, precision:  0.964029, f1:  0.946996
epoch:6, step:156, loss:  0.122806, precision:  0.905797, f1:  0.905797
epoch:6, step:157, loss:  0.094120, precision:  0.943262, f1:  0.933333
epoch:6, step:158, loss:  0.107786, precision:  0.880952, f1:  0.867188
epoch:6, step:159, loss:  0.130843, precision:  0.895105, f1:  0.882759
epoch:6, step:160, loss:  0.129233, precision:  0.846774, f1:  0.830040
epoch:6, step:161, loss:  0.072861, precision:  0.938776, f1:  0.945205
epoch:6, step:162, loss:  0.057423, precision:  0.941606, f1:  0.966292
epoch:6, step:163, loss:  0.123283, precision:  0.893333, f1:  0.902357
epoch:6, step:164, loss:  0.088560, precision:  0.953125, f1:  0.934866
epoch:6, step:165, loss:  0.079089, precision:  0.933775, f1:  0.946309
epoch:6, step:166, loss:  0.062412, precision:  0.926471, f1:  0.936803
epoch:6, step:167, loss:  0.069189, precision:  0.937063, f1:  0.946996
epoch:6, valid_f1:  0.793249, valid_precision:  0.777172, valid_recall:  0.810446
epoch:7, step:0, loss:  0.054184, precision:  0.955556, f1:  0.952030
epoch:7, step:1, loss:  0.058728, precision:  0.924051, f1:  0.948052
epoch:7, step:2, loss:  0.080216, precision:  0.955975, f1:  0.952978
epoch:7, step:3, loss:  0.076241, precision:  0.929487, f1:  0.932476
epoch:7, step:4, loss:  0.070645, precision:  0.938776, f1:  0.938776
epoch:7, step:5, loss:  0.055325, precision:  0.932331, f1:  0.953846
epoch:7, step:6, loss:  0.075766, precision:  0.951724, f1:  0.938776
epoch:7, step:7, loss:  0.066548, precision:  0.953020, f1:  0.953020
epoch:7, step:8, loss:  0.097835, precision:  0.918519, f1:  0.908425
epoch:7, step:9, loss:  0.073903, precision:  0.931973, f1:  0.944828
epoch:7, step:10, loss:  0.094889, precision:  0.932836, f1:  0.919118
epoch:7, step:11, loss:  0.091248, precision:  0.920530, f1:  0.929766
epoch:7, step:12, loss:  0.082083, precision:  0.936306, f1:  0.942308
epoch:7, step:13, loss:  0.074534, precision:  0.909722, f1:  0.922535
epoch:7, step:14, loss:  0.073897, precision:  0.926667, f1:  0.920530
epoch:7, step:15, loss:  0.045461, precision:  0.965035, f1:  0.968421
epoch:7, step:16, loss:  0.076100, precision:  0.939189, f1:  0.945578
epoch:7, step:17, loss:  0.068871, precision:  0.923664, f1:  0.923664
epoch:7, step:18, loss:  0.071900, precision:  0.916667, f1:  0.929577
epoch:7, step:19, loss:  0.074612, precision:  0.924812, f1:  0.949807
epoch:7, step:20, loss:  0.063036, precision:  0.944056, f1:  0.940767
epoch:7, step:21, loss:  0.107434, precision:  0.920000, f1:  0.923077
epoch:7, step:22, loss:  0.034888, precision:  0.974138, f1:  0.969957
epoch:7, step:23, loss:  0.073695, precision:  0.905797, f1:  0.922509
epoch:7, step:24, loss:  0.053963, precision:  0.927007, f1:  0.944238
epoch:7, step:25, loss:  0.093222, precision:  0.939024, f1:  0.950617
epoch:7, step:26, loss:  0.094386, precision:  0.960000, f1:  0.941176
epoch:7, step:27, loss:  0.087119, precision:  0.929577, f1:  0.919861
epoch:7, step:28, loss:  0.087407, precision:  0.909091, f1:  0.933333
epoch:7, step:29, loss:  0.118191, precision:  0.908451, f1:  0.911661
epoch:7, step:30, loss:  0.090155, precision:  0.910345, f1:  0.916667
epoch:7, step:31, loss:  0.055688, precision:  0.939189, f1:  0.961938
epoch:7, step:32, loss:  0.094226, precision:  0.908397, f1:  0.898113
epoch:7, step:33, loss:  0.072566, precision:  0.909091, f1:  0.933333
epoch:7, step:34, loss:  0.063810, precision:  0.946970, f1:  0.946970
epoch:7, step:35, loss:  0.095114, precision:  0.902256, f1:  0.916031
epoch:7, step:36, loss:  0.117103, precision:  0.915493, f1:  0.893471
epoch:7, step:37, loss:  0.142791, precision:  0.922581, f1:  0.890966
epoch:7, step:38, loss:  0.077531, precision:  0.955696, f1:  0.946708
epoch:7, step:39, loss:  0.104055, precision:  0.868966, f1:  0.906475
epoch:7, step:40, loss:  0.064052, precision:  0.906040, f1:  0.937500
epoch:7, step:41, loss:  0.093849, precision:  0.916667, f1:  0.916667
epoch:7, step:42, loss:  0.085056, precision:  0.909091, f1:  0.923077
epoch:7, step:43, loss:  0.058537, precision:  0.957447, f1:  0.960854
epoch:7, step:44, loss:  0.097466, precision:  0.884058, f1:  0.900369
epoch:7, step:45, loss:  0.085485, precision:  0.970588, f1:  0.949640
epoch:7, step:46, loss:  0.089883, precision:  0.951219, f1:  0.928571
epoch:7, step:47, loss:  0.070656, precision:  0.930070, f1:  0.926829
epoch:7, step:48, loss:  0.062231, precision:  0.947368, f1:  0.950495
epoch:7, step:49, loss:  0.068679, precision:  0.940789, f1:  0.959732
epoch:7, step:50, loss:  0.121780, precision:  0.852941, f1:  0.882129
epoch:7, step:51, loss:  0.100553, precision:  0.886667, f1:  0.901695
epoch:7, step:52, loss:  0.098501, precision:  0.909091, f1:  0.915493
epoch:7, step:53, loss:  0.048709, precision:  0.960317, f1:  0.952756
epoch:7, step:54, loss:  0.092592, precision:  0.925170, f1:  0.918919
epoch:7, step:55, loss:  0.042234, precision:  0.978873, f1:  0.968641
epoch:7, step:56, loss:  0.066656, precision:  0.966942, f1:  0.936000
epoch:7, step:57, loss:  0.073494, precision:  0.925926, f1:  0.936330
epoch:7, step:58, loss:  0.062278, precision:  0.946667, f1:  0.959459
epoch:7, step:59, loss:  0.056453, precision:  0.953642, f1:  0.966443
epoch:7, step:60, loss:  0.066494, precision:  0.940000, f1:  0.949495
epoch:7, step:61, loss:  0.075883, precision:  0.924138, f1:  0.940351
epoch:7, step:62, loss:  0.085334, precision:  0.932203, f1:  0.940171
epoch:7, step:63, loss:  0.106854, precision:  0.871212, f1:  0.905512
epoch:7, step:64, loss:  0.086941, precision:  0.932961, f1:  0.935574
epoch:7, step:65, loss:  0.072824, precision:  0.926471, f1:  0.926471
epoch:7, step:66, loss:  0.086616, precision:  0.911565, f1:  0.920962
epoch:7, step:67, loss:  0.113043, precision:  0.927152, f1:  0.924092
epoch:7, step:68, loss:  0.098079, precision:  0.940397, f1:  0.937294
epoch:7, step:69, loss:  0.039214, precision:  0.985611, f1:  0.971631
epoch:7, step:70, loss:  0.111593, precision:  0.871429, f1:  0.903704
epoch:7, step:71, loss:  0.075767, precision:  0.941606, f1:  0.945055
epoch:7, step:72, loss:  0.109157, precision:  0.885714, f1:  0.908425
epoch:7, step:73, loss:  0.082049, precision:  0.917197, f1:  0.932039
epoch:7, step:74, loss:  0.061968, precision:  0.948529, f1:  0.948529
epoch:7, step:75, loss:  0.150746, precision:  0.889610, f1:  0.889610
epoch:7, step:76, loss:  0.100615, precision:  0.938596, f1:  0.910638
epoch:7, step:77, loss:  0.084274, precision:  0.957747, f1:  0.941176
epoch:7, step:78, loss:  0.068470, precision:  0.950704, f1:  0.957447
epoch:7, step:79, loss:  0.063849, precision:  0.965278, f1:  0.968641
epoch:7, step:80, loss:  0.091694, precision:  0.922535, f1:  0.922535
epoch:7, step:81, loss:  0.090965, precision:  0.938272, f1:  0.935385
epoch:7, step:82, loss:  0.093601, precision:  0.929032, f1:  0.935065
epoch:7, step:83, loss:  0.124656, precision:  0.853503, f1:  0.896321
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:07,  2.74it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.48it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.42it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.31it/s]Validating:  24%|██▍       | 5/21 [00:02<00:07,  2.28it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.21it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.10it/s]Validating:  38%|███▊      | 8/21 [00:03<00:06,  2.11it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.11it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.34it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.29it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.24it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.25it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.28it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.40it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.33it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.33it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.37it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.27it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.43it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.30it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.27it/s]
epoch:7, step:84, loss:  0.098853, precision:  0.911765, f1:  0.925373
epoch:7, step:85, loss:  0.099158, precision:  0.920863, f1:  0.934307
epoch:7, step:86, loss:  0.066828, precision:  0.978571, f1:  0.964789
epoch:7, step:87, loss:  0.068415, precision:  0.926230, f1:  0.937759
epoch:7, step:88, loss:  0.073363, precision:  0.940298, f1:  0.933333
epoch:7, step:89, loss:  0.076501, precision:  0.946565, f1:  0.946565
epoch:7, step:90, loss:  0.054898, precision:  0.950704, f1:  0.954064
epoch:7, step:91, loss:  0.076456, precision:  0.950355, f1:  0.937063
epoch:7, step:92, loss:  0.107398, precision:  0.904192, f1:  0.920732
epoch:7, step:93, loss:  0.088080, precision:  0.901961, f1:  0.920000
epoch:7, step:94, loss:  0.095080, precision:  0.829630, f1:  0.878431
epoch:7, step:95, loss:  0.097536, precision:  0.897059, f1:  0.910448
epoch:7, step:96, loss:  0.079249, precision:  0.963235, f1:  0.925795
epoch:7, step:97, loss:  0.136103, precision:  0.911950, f1:  0.900621
epoch:7, step:98, loss:  0.057585, precision:  0.961240, f1:  0.972549
epoch:7, step:99, loss:  0.050373, precision:  0.968354, f1:  0.977636
epoch:7, step:100, loss:  0.069934, precision:  0.950000, f1:  0.953405
epoch:7, step:101, loss:  0.082804, precision:  0.911111, f1:  0.907749
epoch:7, step:102, loss:  0.114230, precision:  0.851351, f1:  0.884211
epoch:7, step:103, loss:  0.069960, precision:  0.922535, f1:  0.919298
epoch:7, step:104, loss:  0.065063, precision:  0.935484, f1:  0.943089
epoch:7, step:105, loss:  0.085521, precision:  0.930769, f1:  0.934363
epoch:7, step:106, loss:  0.103710, precision:  0.876712, f1:  0.898246
epoch:7, step:107, loss:  0.080233, precision:  0.916667, f1:  0.920152
epoch:7, step:108, loss:  0.079040, precision:  0.940298, f1:  0.923077
epoch:7, step:109, loss:  0.042102, precision:  0.941176, f1:  0.962406
epoch:7, step:110, loss:  0.109544, precision:  0.924051, f1:  0.918239
epoch:7, step:111, loss:  0.068520, precision:  0.968992, f1:  0.954198
epoch:7, step:112, loss:  0.099453, precision:  0.882759, f1:  0.904594
epoch:7, step:113, loss:  0.077839, precision:  0.943662, f1:  0.950355
epoch:7, step:114, loss:  0.102407, precision:  0.912791, f1:  0.928994
epoch:7, step:115, loss:  0.060794, precision:  0.905797, f1:  0.936330
epoch:7, step:116, loss:  0.091548, precision:  0.918919, f1:  0.931507
epoch:7, step:117, loss:  0.131935, precision:  0.915493, f1:  0.893471
epoch:7, step:118, loss:  0.080616, precision:  0.942029, f1:  0.928571
epoch:7, step:119, loss:  0.093610, precision:  0.925676, f1:  0.916388
epoch:7, step:120, loss:  0.107082, precision:  0.946667, f1:  0.916129
epoch:7, step:121, loss:  0.064388, precision:  0.929078, f1:  0.935714
epoch:7, step:122, loss:  0.116038, precision:  0.829787, f1:  0.869888
epoch:7, step:123, loss:  0.167301, precision:  0.861446, f1:  0.864048
epoch:7, step:124, loss:  0.067264, precision:  0.914474, f1:  0.939189
epoch:7, step:125, loss:  0.071993, precision:  0.901316, f1:  0.935154
epoch:7, step:126, loss:  0.107987, precision:  0.915493, f1:  0.912281
epoch:7, step:127, loss:  0.085043, precision:  0.933884, f1:  0.922449
epoch:7, step:128, loss:  0.071598, precision:  0.983740, f1:  0.945312
epoch:7, step:129, loss:  0.042667, precision:  0.966942, f1:  0.966942
epoch:7, step:130, loss:  0.082673, precision:  0.896296, f1:  0.916667
epoch:7, step:131, loss:  0.080605, precision:  0.936416, f1:  0.941860
epoch:7, step:132, loss:  0.125715, precision:  0.867133, f1:  0.885714
epoch:7, step:133, loss:  0.083535, precision:  0.935897, f1:  0.948052
epoch:7, step:134, loss:  0.080997, precision:  0.924658, f1:  0.924658
epoch:7, step:135, loss:  0.100069, precision:  0.843750, f1:  0.888889
epoch:7, step:136, loss:  0.097700, precision:  0.924419, f1:  0.935294
epoch:7, step:137, loss:  0.082575, precision:  0.916667, f1:  0.942857
epoch:7, step:138, loss:  0.064594, precision:  0.955556, f1:  0.941606
epoch:7, step:139, loss:  0.103572, precision:  0.958621, f1:  0.914474
epoch:7, step:140, loss:  0.103758, precision:  0.900709, f1:  0.907143
epoch:7, step:141, loss:  0.072117, precision:  0.953846, f1:  0.946565
epoch:7, step:142, loss:  0.121898, precision:  0.899225, f1:  0.895753
epoch:7, step:143, loss:  0.051906, precision:  0.939850, f1:  0.946970
epoch:7, step:144, loss:  0.092601, precision:  0.931035, f1:  0.921502
epoch:7, step:145, loss:  0.081668, precision:  0.891156, f1:  0.919298
epoch:7, step:146, loss:  0.098548, precision:  0.905660, f1:  0.917197
epoch:7, step:147, loss:  0.109325, precision:  0.902098, f1:  0.905263
epoch:7, step:148, loss:  0.110305, precision:  0.895522, f1:  0.916031
epoch:7, step:149, loss:  0.083904, precision:  0.877863, f1:  0.909091
epoch:7, step:150, loss:  0.050803, precision:  0.972603, f1:  0.959459
epoch:7, step:151, loss:  0.102807, precision:  0.906977, f1:  0.914062
epoch:7, step:152, loss:  0.100795, precision:  0.903448, f1:  0.909722
epoch:7, step:153, loss:  0.063885, precision:  0.961538, f1:  0.939850
epoch:7, step:154, loss:  0.057378, precision:  0.951219, f1:  0.939759
epoch:7, step:155, loss:  0.070165, precision:  0.940298, f1:  0.943820
epoch:7, step:156, loss:  0.083539, precision:  0.925373, f1:  0.921933
epoch:7, step:157, loss:  0.066261, precision:  0.936620, f1:  0.939929
epoch:7, step:158, loss:  0.107037, precision:  0.920000, f1:  0.923077
epoch:7, step:159, loss:  0.105749, precision:  0.928571, f1:  0.928571
epoch:7, step:160, loss:  0.059965, precision:  0.916129, f1:  0.953020
epoch:7, step:161, loss:  0.080352, precision:  0.891720, f1:  0.927152
epoch:7, step:162, loss:  0.078501, precision:  0.908497, f1:  0.917492
epoch:7, step:163, loss:  0.097198, precision:  0.933824, f1:  0.933824
epoch:7, step:164, loss:  0.088627, precision:  0.963504, f1:  0.929577
epoch:7, step:165, loss:  0.090015, precision:  0.924242, f1:  0.910448
epoch:7, step:166, loss:  0.103413, precision:  0.937500, f1:  0.905660
epoch:7, step:167, loss:  0.074207, precision:  0.940298, f1:  0.947368
epoch:7, valid_f1:  0.795977, valid_precision:  0.783673, valid_recall:  0.808869
epoch:8, step:0, loss:  0.077995, precision:  0.959732, f1:  0.959732
epoch:8, step:1, loss:  0.071689, precision:  0.938931, f1:  0.942529
epoch:8, step:2, loss:  0.064803, precision:  0.944056, f1:  0.950704
epoch:8, step:3, loss:  0.081588, precision:  0.921569, f1:  0.936877
epoch:8, step:4, loss:  0.075160, precision:  0.916168, f1:  0.944444
epoch:8, step:5, loss:  0.065775, precision:  0.913043, f1:  0.933333
epoch:8, step:6, loss:  0.069784, precision:  0.935714, f1:  0.935714
epoch:8, step:7, loss:  0.054109, precision:  0.978571, f1:  0.964789
epoch:8, step:8, loss:  0.047142, precision:  0.970588, f1:  0.960000
epoch:8, step:9, loss:  0.070221, precision:  0.965517, f1:  0.955631
epoch:8, step:10, loss:  0.058919, precision:  0.963235, f1:  0.959707
epoch:8, step:11, loss:  0.054132, precision:  0.948387, f1:  0.960784
epoch:8, step:12, loss:  0.061541, precision:  0.931973, f1:  0.951389
epoch:8, step:13, loss:  0.070845, precision:  0.907514, f1:  0.940120
epoch:8, step:14, loss:  0.048892, precision:  0.952055, f1:  0.961938
epoch:8, step:15, loss:  0.049857, precision:  0.956790, f1:  0.977918
epoch:8, step:16, loss:  0.058728, precision:  0.948529, f1:  0.948529
epoch:8, step:17, loss:  0.064755, precision:  0.954248, f1:  0.957377
epoch:8, step:18, loss:  0.070680, precision:  0.941935, f1:  0.944984
epoch:8, step:19, loss:  0.057605, precision:  0.968000, f1:  0.949020
epoch:8, step:20, loss:  0.061354, precision:  0.955882, f1:  0.938628
epoch:8, step:21, loss:  0.067358, precision:  0.945736, f1:  0.945736
epoch:8, step:22, loss:  0.083570, precision:  0.905660, f1:  0.920128
epoch:8, step:23, loss:  0.100767, precision:  0.896104, f1:  0.904918
epoch:8, step:24, loss:  0.073857, precision:  0.911765, f1:  0.939394
epoch:8, step:25, loss:  0.047144, precision:  0.944444, f1:  0.957747
epoch:8, step:26, loss:  0.065772, precision:  0.956522, f1:  0.950617
epoch:8, step:27, loss:  0.079611, precision:  0.909091, f1:  0.926641
epoch:8, step:28, loss:  0.065084, precision:  0.949275, f1:  0.942446
epoch:8, step:29, loss:  0.052357, precision:  0.962963, f1:  0.959410
epoch:8, step:30, loss:  0.034991, precision:  0.968992, f1:  0.972763
epoch:8, step:31, loss:  0.063006, precision:  0.978261, f1:  0.960854
epoch:8, step:32, loss:  0.056591, precision:  0.951724, f1:  0.958333
epoch:8, step:33, loss:  0.062240, precision:  0.921986, f1:  0.935252
epoch:8, step:34, loss:  0.072551, precision:  0.935897, f1:  0.938907
epoch:8, step:35, loss:  0.075504, precision:  0.925926, f1:  0.943396
epoch:8, step:36, loss:  0.037798, precision:  0.961538, f1:  0.972763
epoch:8, step:37, loss:  0.041157, precision:  0.948148, f1:  0.962406
epoch:8, step:38, loss:  0.048027, precision:  0.954545, f1:  0.961832
epoch:8, step:39, loss:  0.068298, precision:  0.948052, f1:  0.948052
epoch:8, step:40, loss:  0.085875, precision:  0.938776, f1:  0.929293
epoch:8, step:41, loss:  0.051128, precision:  0.960000, f1:  0.956811
epoch:8, step:42, loss:  0.077110, precision:  0.888889, f1:  0.911032
epoch:8, step:43, loss:  0.057000, precision:  0.959732, f1:  0.966216
epoch:8, step:44, loss:  0.069647, precision:  0.943548, f1:  0.936000
epoch:8, step:45, loss:  0.032865, precision:  0.937500, f1:  0.956175
epoch:8, step:46, loss:  0.093964, precision:  0.916129, f1:  0.934211
epoch:8, step:47, loss:  0.043305, precision:  0.934211, f1:  0.962712
epoch:8, step:48, loss:  0.094350, precision:  0.926175, f1:  0.929293
epoch:8, step:49, loss:  0.053746, precision:  0.972789, f1:  0.966216
epoch:8, step:50, loss:  0.060852, precision:  0.958042, f1:  0.954704
epoch:8, step:51, loss:  0.060999, precision:  0.928105, f1:  0.949833
epoch:8, step:52, loss:  0.058464, precision:  0.938356, f1:  0.951389
epoch:8, step:53, loss:  0.043550, precision:  0.958042, f1:  0.968198
epoch:8, step:54, loss:  0.068356, precision:  0.929078, f1:  0.916084
epoch:8, step:55, loss:  0.066579, precision:  0.933824, f1:  0.933824
epoch:8, step:56, loss:  0.044738, precision:  0.963235, f1:  0.966790
epoch:8, step:57, loss:  0.050294, precision:  0.943662, f1:  0.957143
epoch:8, step:58, loss:  0.064031, precision:  0.948529, f1:  0.934783
epoch:8, step:59, loss:  0.047609, precision:  0.945312, f1:  0.960317
epoch:8, step:60, loss:  0.070196, precision:  0.911565, f1:  0.937063
epoch:8, step:61, loss:  0.061150, precision:  0.955128, f1:  0.958199
epoch:8, step:62, loss:  0.081211, precision:  0.905797, f1:  0.925926
epoch:8, step:63, loss:  0.027676, precision:  0.975806, f1:  0.971888
epoch:8, step:64, loss:  0.061567, precision:  0.943662, f1:  0.957143
epoch:8, step:65, loss:  0.063422, precision:  0.935252, f1:  0.948905
epoch:8, step:66, loss:  0.093469, precision:  0.916667, f1:  0.919614
epoch:8, step:67, loss:  0.075588, precision:  0.926667, f1:  0.942373
epoch:8, step:68, loss:  0.058638, precision:  0.954545, f1:  0.960784
epoch:8, step:69, loss:  0.059230, precision:  0.975207, f1:  0.947791
epoch:8, step:70, loss:  0.054022, precision:  0.969136, f1:  0.963190
epoch:8, step:71, loss:  0.060043, precision:  0.960784, f1:  0.957655
epoch:8, step:72, loss:  0.049468, precision:  0.950355, f1:  0.964029
epoch:8, step:73, loss:  0.034817, precision:  0.977941, f1:  0.974359
epoch:8, step:74, loss:  0.131075, precision:  0.890411, f1:  0.902778
epoch:8, step:75, loss:  0.072261, precision:  0.932836, f1:  0.936330
epoch:8, step:76, loss:  0.031638, precision:  0.978873, f1:  0.982332
epoch:8, step:77, loss:  0.069503, precision:  0.930233, f1:  0.923077
epoch:8, step:78, loss:  0.082570, precision:  0.897059, f1:  0.900369
epoch:8, step:79, loss:  0.087979, precision:  0.922414, f1:  0.918455
epoch:8, step:80, loss:  0.057190, precision:  0.960938, f1:  0.931818
epoch:8, step:81, loss:  0.062075, precision:  0.972603, f1:  0.953020
epoch:8, step:82, loss:  0.034074, precision:  0.949640, f1:  0.963504
epoch:8, step:83, loss:  0.065279, precision:  0.921053, f1:  0.939597
epoch:8, step:84, loss:  0.103029, precision:  0.897959, f1:  0.913495
epoch:8, step:85, loss:  0.078334, precision:  0.906040, f1:  0.921502
epoch:8, step:86, loss:  0.111080, precision:  0.908537, f1:  0.925466
epoch:8, step:87, loss:  0.047736, precision:  0.954545, f1:  0.970297
epoch:8, step:88, loss:  0.040868, precision:  0.938356, f1:  0.954704
epoch:8, step:89, loss:  0.057420, precision:  0.948905, f1:  0.952381
epoch:8, step:90, loss:  0.088041, precision:  0.934307, f1:  0.930909
epoch:8, step:91, loss:  0.048692, precision:  0.940789, f1:  0.956522
epoch:8, step:92, loss:  0.110377, precision:  0.909091, f1:  0.896552
epoch:8, step:93, loss:  0.058984, precision:  0.946154, f1:  0.946154
epoch:8, step:94, loss:  0.035875, precision:  0.975806, f1:  0.964143
epoch:8, step:95, loss:  0.068740, precision:  0.939597, f1:  0.939597
epoch:8, step:96, loss:  0.065332, precision:  0.924658, f1:  0.940767
epoch:8, step:97, loss:  0.067766, precision:  0.906475, f1:  0.936803
epoch:8, step:98, loss:  0.068929, precision:  0.942029, f1:  0.945455
epoch:8, step:99, loss:  0.044661, precision:  0.962687, f1:  0.962687
epoch:8, step:100, loss:  0.095687, precision:  0.945736, f1:  0.924242
epoch:8, step:101, loss:  0.086529, precision:  0.959459, f1:  0.949833
epoch:8, step:102, loss:  0.036745, precision:  0.975806, f1:  0.971888
epoch:8, step:103, loss:  0.069178, precision:  0.960938, f1:  0.953488
epoch:8, step:104, loss:  0.067177, precision:  0.967320, f1:  0.964169
epoch:8, step:105, loss:  0.065829, precision:  0.936000, f1:  0.939759
epoch:8, step:106, loss:  0.075258, precision:  0.934783, f1:  0.948529
epoch:8, step:107, loss:  0.077700, precision:  0.915493, f1:  0.935252
epoch:8, step:108, loss:  0.081444, precision:  0.919463, f1:  0.944828
epoch:8, step:109, loss:  0.065147, precision:  0.925676, f1:  0.938356
epoch:8, step:110, loss:  0.076573, precision:  0.906250, f1:  0.916996
epoch:8, step:111, loss:  0.066366, precision:  0.952055, f1:  0.942373
epoch:8, step:112, loss:  0.085893, precision:  0.902439, f1:  0.902439
epoch:8, step:113, loss:  0.086925, precision:  0.930380, f1:  0.933333
epoch:8, step:114, loss:  0.070211, precision:  0.946565, f1:  0.942966
epoch:8, step:115, loss:  0.069402, precision:  0.920000, f1:  0.926175
epoch:8, step:116, loss:  0.038300, precision:  0.972789, f1:  0.976109
epoch:8, step:117, loss:  0.077555, precision:  0.961290, f1:  0.940063
epoch:8, step:118, loss:  0.070871, precision:  0.907975, f1:  0.939683
epoch:8, step:119, loss:  0.083342, precision:  0.901734, f1:  0.925816
epoch:8, step:120, loss:  0.088839, precision:  0.897638, f1:  0.915663
epoch:8, step:121, loss:  0.094041, precision:  0.894737, f1:  0.918919
epoch:8, step:122, loss:  0.101103, precision:  0.957747, f1:  0.909699
epoch:8, step:123, loss:  0.049420, precision:  0.973856, f1:  0.961290
epoch:8, step:124, loss:  0.086375, precision:  0.941606, f1:  0.924731
epoch:8, step:125, loss:  0.070747, precision:  0.958678, f1:  0.939271
epoch:8, step:126, loss:  0.085281, precision:  0.937931, f1:  0.944444
epoch:8, step:127, loss:  0.076121, precision:  0.953488, f1:  0.924812
epoch:8, step:128, loss:  0.078918, precision:  0.919118, f1:  0.922509
epoch:8, step:129, loss:  0.070190, precision:  0.931298, f1:  0.931298
epoch:8, step:130, loss:  0.103084, precision:  0.872483, f1:  0.896552
epoch:8, step:131, loss:  0.084151, precision:  0.933333, f1:  0.933333
epoch:8, step:132, loss:  0.062143, precision:  0.902439, f1:  0.942675
epoch:8, step:133, loss:  0.065720, precision:  0.902778, f1:  0.935252
epoch:8, step:134, loss:  0.057487, precision:  0.962687, f1:  0.948529
epoch:8, step:135, loss:  0.089700, precision:  0.942446, f1:  0.939068
epoch:8, step:136, loss:  0.088273, precision:  0.944882, f1:  0.930233
epoch:8, step:137, loss:  0.058550, precision:  0.965753, f1:  0.955932
epoch:8, step:138, loss:  0.091618, precision:  0.942675, f1:  0.936709
epoch:8, step:139, loss:  0.065672, precision:  0.921986, f1:  0.931900
epoch:8, step:140, loss:  0.097171, precision:  0.886667, f1:  0.917241
epoch:8, step:141, loss:  0.060548, precision:  0.961832, f1:  0.943820
epoch:8, step:142, loss:  0.067417, precision:  0.941606, f1:  0.948529
epoch:8, step:143, loss:  0.073411, precision:  0.923611, f1:  0.930070
epoch:8, step:144, loss:  0.073047, precision:  0.898649, f1:  0.930070
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:08,  2.35it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.27it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.29it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.19it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.33it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.20it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.25it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.20it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.23it/s]Validating:  48%|████▊     | 10/21 [00:04<00:05,  2.18it/s]Validating:  52%|█████▏    | 11/21 [00:05<00:04,  2.15it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.30it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.18it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.33it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.23it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.23it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.15it/s]Validating:  86%|████████▌ | 18/21 [00:08<00:01,  2.12it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.14it/s]Validating:  95%|█████████▌| 20/21 [00:09<00:00,  2.13it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.05it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.18it/s]
epoch:8, step:145, loss:  0.048358, precision:  0.966942, f1:  0.951219
epoch:8, step:146, loss:  0.061790, precision:  0.950000, f1:  0.933333
epoch:8, step:147, loss:  0.084000, precision:  0.913907, f1:  0.923077
epoch:8, step:148, loss:  0.073161, precision:  0.907895, f1:  0.923077
epoch:8, step:149, loss:  0.062490, precision:  0.945578, f1:  0.945578
epoch:8, step:150, loss:  0.054734, precision:  0.947712, f1:  0.953947
epoch:8, step:151, loss:  0.063333, precision:  0.930818, f1:  0.933754
epoch:8, step:152, loss:  0.065879, precision:  0.926230, f1:  0.937759
epoch:8, step:153, loss:  0.041673, precision:  0.960000, f1:  0.966443
epoch:8, step:154, loss:  0.084670, precision:  0.930070, f1:  0.933333
epoch:8, step:155, loss:  0.046888, precision:  0.926829, f1:  0.947040
epoch:8, step:156, loss:  0.054726, precision:  0.949367, f1:  0.964630
epoch:8, step:157, loss:  0.087678, precision:  0.923077, f1:  0.936170
epoch:8, step:158, loss:  0.068601, precision:  0.932836, f1:  0.939850
epoch:8, step:159, loss:  0.072604, precision:  0.920863, f1:  0.934307
epoch:8, step:160, loss:  0.055480, precision:  0.948148, f1:  0.944649
epoch:8, step:161, loss:  0.091831, precision:  0.943038, f1:  0.928349
epoch:8, step:162, loss:  0.079083, precision:  0.941606, f1:  0.938182
epoch:8, step:163, loss:  0.060233, precision:  0.946309, f1:  0.965753
epoch:8, step:164, loss:  0.104348, precision:  0.857143, f1:  0.882943
epoch:8, step:165, loss:  0.054062, precision:  0.950920, f1:  0.956790
epoch:8, step:166, loss:  0.052785, precision:  0.934426, f1:  0.957983
epoch:8, step:167, loss:  0.070075, precision:  0.944056, f1:  0.944056
epoch:8, valid_f1:  0.787849, valid_precision:  0.776192, valid_recall:  0.800238
epoch:9, step:0, loss:  0.038385, precision:  0.959350, f1:  0.959350
epoch:9, step:1, loss:  0.065542, precision:  0.923611, f1:  0.936620
epoch:9, step:2, loss:  0.059406, precision:  0.954248, f1:  0.948052
epoch:9, step:3, loss:  0.056946, precision:  0.969466, f1:  0.962121
epoch:9, step:4, loss:  0.053316, precision:  0.968354, f1:  0.962264
epoch:9, step:5, loss:  0.064792, precision:  0.956204, f1:  0.949275
epoch:9, step:6, loss:  0.049132, precision:  0.946970, f1:  0.950570
epoch:9, step:7, loss:  0.048601, precision:  0.949275, f1:  0.956204
epoch:9, step:8, loss:  0.048565, precision:  0.949275, f1:  0.952727
epoch:9, step:9, loss:  0.035620, precision:  0.958621, f1:  0.968641
epoch:9, step:10, loss:  0.087856, precision:  0.929078, f1:  0.916084
epoch:9, step:11, loss:  0.042286, precision:  0.960938, f1:  0.972332
epoch:9, step:12, loss:  0.054779, precision:  0.936306, f1:  0.954545
epoch:9, step:13, loss:  0.057319, precision:  0.939597, f1:  0.949153
epoch:9, step:14, loss:  0.036337, precision:  0.963504, f1:  0.970588
epoch:9, step:15, loss:  0.042794, precision:  0.953642, f1:  0.960000
epoch:9, step:16, loss:  0.050102, precision:  0.970588, f1:  0.956522
epoch:9, step:17, loss:  0.034865, precision:  0.979452, f1:  0.969492
epoch:9, step:18, loss:  0.088889, precision:  0.904762, f1:  0.907850
epoch:9, step:19, loss:  0.046742, precision:  0.942029, f1:  0.948905
epoch:9, step:20, loss:  0.056626, precision:  0.940741, f1:  0.947761
epoch:9, step:21, loss:  0.087327, precision:  0.931507, f1:  0.931507
epoch:9, step:22, loss:  0.034455, precision:  0.950704, f1:  0.971223
epoch:9, step:23, loss:  0.063372, precision:  0.918367, f1:  0.944056
epoch:9, step:24, loss:  0.098768, precision:  0.920245, f1:  0.931677
epoch:9, step:25, loss:  0.083151, precision:  0.952055, f1:  0.945578
epoch:9, step:26, loss:  0.027586, precision:  0.980132, f1:  0.983389
epoch:9, step:27, loss:  0.036798, precision:  0.965753, f1:  0.972414
epoch:9, step:28, loss:  0.066869, precision:  0.952703, f1:  0.955932
epoch:9, step:29, loss:  0.033783, precision:  0.955224, f1:  0.969697
epoch:9, step:30, loss:  0.068930, precision:  0.951219, f1:  0.924901
epoch:9, step:31, loss:  0.046433, precision:  0.966887, f1:  0.966887
epoch:9, step:32, loss:  0.054838, precision:  0.977941, f1:  0.970803
epoch:9, step:33, loss:  0.032056, precision:  0.958621, f1:  0.975439
epoch:9, step:34, loss:  0.076931, precision:  0.897727, f1:  0.934911
epoch:9, step:35, loss:  0.055412, precision:  0.925926, f1:  0.952381
epoch:9, step:36, loss:  0.050904, precision:  0.964286, f1:  0.967742
epoch:9, step:37, loss:  0.084149, precision:  0.902778, f1:  0.921986
epoch:9, step:38, loss:  0.059408, precision:  0.958678, f1:  0.958678
epoch:9, step:39, loss:  0.068146, precision:  0.936306, f1:  0.948387
epoch:9, step:40, loss:  0.064559, precision:  0.941176, f1:  0.927536
epoch:9, step:41, loss:  0.075077, precision:  0.942446, f1:  0.942446
epoch:9, step:42, loss:  0.062137, precision:  0.963768, f1:  0.930070
epoch:9, step:43, loss:  0.052999, precision:  0.938776, f1:  0.951724
epoch:9, step:44, loss:  0.053022, precision:  0.935252, f1:  0.959410
epoch:9, step:45, loss:  0.071178, precision:  0.941176, f1:  0.951673
epoch:9, step:46, loss:  0.046912, precision:  0.961538, f1:  0.961538
epoch:9, step:47, loss:  0.062484, precision:  0.909722, f1:  0.935714
epoch:9, step:48, loss:  0.030415, precision:  0.973333, f1:  0.979866
epoch:9, step:49, loss:  0.068899, precision:  0.912752, f1:  0.934708
epoch:9, step:50, loss:  0.039528, precision:  0.958042, f1:  0.961403
epoch:9, step:51, loss:  0.059917, precision:  0.945578, f1:  0.945578
epoch:9, step:52, loss:  0.045160, precision:  0.942446, f1:  0.952727
epoch:9, step:53, loss:  0.040731, precision:  0.948718, f1:  0.940678
epoch:9, step:54, loss:  0.041289, precision:  0.972028, f1:  0.965278
epoch:9, step:55, loss:  0.051319, precision:  0.953020, f1:  0.962712
epoch:9, step:56, loss:  0.045526, precision:  0.962733, f1:  0.968750
epoch:9, step:57, loss:  0.050188, precision:  0.947020, f1:  0.962963
epoch:9, step:58, loss:  0.033482, precision:  0.969136, f1:  0.969136
epoch:9, step:59, loss:  0.033152, precision:  0.928058, f1:  0.955556
epoch:9, step:60, loss:  0.044682, precision:  0.951049, f1:  0.971429
epoch:9, step:61, loss:  0.040607, precision:  0.940789, f1:  0.956522
epoch:9, step:62, loss:  0.057330, precision:  0.931035, f1:  0.937500
epoch:9, step:63, loss:  0.064591, precision:  0.942308, f1:  0.957655
epoch:9, step:64, loss:  0.044782, precision:  0.967949, f1:  0.974194
epoch:9, step:65, loss:  0.050786, precision:  0.953020, f1:  0.949833
epoch:9, step:66, loss:  0.096296, precision:  0.915584, f1:  0.918567
epoch:9, step:67, loss:  0.056462, precision:  0.949275, f1:  0.942446
epoch:9, step:68, loss:  0.035707, precision:  0.977444, f1:  0.981132
epoch:9, step:69, loss:  0.047353, precision:  0.971631, f1:  0.968198
epoch:9, step:70, loss:  0.053060, precision:  0.972973, f1:  0.960000
epoch:9, step:71, loss:  0.040268, precision:  0.971631, f1:  0.971631
epoch:9, step:72, loss:  0.047441, precision:  0.957447, f1:  0.947368
epoch:9, step:73, loss:  0.088219, precision:  0.902098, f1:  0.918149
epoch:9, step:74, loss:  0.051649, precision:  0.954545, f1:  0.954545
epoch:9, step:75, loss:  0.043765, precision:  0.970149, f1:  0.962963
epoch:9, step:76, loss:  0.037999, precision:  0.958042, f1:  0.968198
epoch:9, step:77, loss:  0.059064, precision:  0.971223, f1:  0.957447
epoch:9, step:78, loss:  0.079539, precision:  0.884058, f1:  0.903704
epoch:9, step:79, loss:  0.048082, precision:  0.965986, f1:  0.972603
epoch:9, step:80, loss:  0.037252, precision:  0.952055, f1:  0.965278
epoch:9, step:81, loss:  0.070729, precision:  0.924658, f1:  0.934256
epoch:9, step:82, loss:  0.043779, precision:  0.965753, f1:  0.959184
epoch:9, step:83, loss:  0.044278, precision:  0.946309, f1:  0.959184
epoch:9, step:84, loss:  0.053612, precision:  0.940000, f1:  0.949495
epoch:9, step:85, loss:  0.039236, precision:  0.965035, f1:  0.968421
epoch:9, step:86, loss:  0.058049, precision:  0.955882, f1:  0.942029
epoch:9, step:87, loss:  0.052487, precision:  0.944828, f1:  0.948097
epoch:9, step:88, loss:  0.054634, precision:  0.984733, f1:  0.955556
epoch:9, step:89, loss:  0.072141, precision:  0.925170, f1:  0.928328
epoch:9, step:90, loss:  0.045080, precision:  0.971223, f1:  0.964286
epoch:9, step:91, loss:  0.053372, precision:  0.948148, f1:  0.962406
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:08,  2.32it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.52it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.48it/s]Validating:  19%|█▉        | 4/21 [00:01<00:06,  2.47it/s]Validating:  24%|██▍       | 5/21 [00:01<00:05,  2.68it/s]Validating:  29%|██▊       | 6/21 [00:02<00:05,  2.57it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.46it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.41it/s]Validating:  43%|████▎     | 9/21 [00:03<00:04,  2.42it/s]Validating:  48%|████▊     | 10/21 [00:03<00:04,  2.45it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.40it/s]Validating:  57%|█████▋    | 12/21 [00:04<00:03,  2.38it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.52it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:02,  2.45it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.43it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.37it/s]Validating:  81%|████████  | 17/21 [00:06<00:01,  2.32it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.42it/s]Validating:  90%|█████████ | 19/21 [00:07<00:00,  2.36it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.40it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.36it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.44it/s]
epoch:9, step:92, loss:  0.047587, precision:  0.957747, f1:  0.964539
epoch:9, step:93, loss:  0.071285, precision:  0.885496, f1:  0.906250
epoch:9, step:94, loss:  0.072949, precision:  0.906475, f1:  0.936803
epoch:9, step:95, loss:  0.085603, precision:  0.915152, f1:  0.926380
epoch:9, step:96, loss:  0.050401, precision:  0.949045, f1:  0.961290
epoch:9, step:97, loss:  0.066906, precision:  0.955882, f1:  0.959410
epoch:9, step:98, loss:  0.090529, precision:  0.956250, f1:  0.932927
epoch:9, step:99, loss:  0.087690, precision:  0.914062, f1:  0.896552
epoch:9, step:100, loss:  0.069238, precision:  0.936620, f1:  0.936620
epoch:9, step:101, loss:  0.050541, precision:  0.984375, f1:  0.958175
epoch:9, step:102, loss:  0.062254, precision:  0.943750, f1:  0.949686
epoch:9, step:103, loss:  0.068468, precision:  0.934783, f1:  0.934783
epoch:9, step:104, loss:  0.033933, precision:  0.940298, f1:  0.972973
epoch:9, step:105, loss:  0.063431, precision:  0.916129, f1:  0.937294
epoch:9, step:106, loss:  0.044339, precision:  0.945946, f1:  0.965517
epoch:9, step:107, loss:  0.049295, precision:  0.930556, f1:  0.946996
epoch:9, step:108, loss:  0.051394, precision:  0.963768, f1:  0.967273
epoch:9, step:109, loss:  0.055853, precision:  0.953846, f1:  0.942966
epoch:9, step:110, loss:  0.039568, precision:  0.971631, f1:  0.964789
epoch:9, step:111, loss:  0.064602, precision:  0.919463, f1:  0.938356
epoch:9, step:112, loss:  0.067164, precision:  0.953333, f1:  0.947020
epoch:9, step:113, loss:  0.057940, precision:  0.955556, f1:  0.955556
epoch:9, step:114, loss:  0.057337, precision:  0.943662, f1:  0.950355
epoch:9, step:115, loss:  0.076881, precision:  0.947761, f1:  0.923636
epoch:9, step:116, loss:  0.056261, precision:  0.944444, f1:  0.951049
epoch:9, step:117, loss:  0.046984, precision:  0.961039, f1:  0.961039
epoch:9, step:118, loss:  0.047209, precision:  0.960265, f1:  0.969900
epoch:9, step:119, loss:  0.048538, precision:  0.960784, f1:  0.954545
epoch:9, step:120, loss:  0.076465, precision:  0.932432, f1:  0.929293
epoch:9, step:121, loss:  0.040510, precision:  0.955975, f1:  0.965079
epoch:9, step:122, loss:  0.053789, precision:  0.950704, f1:  0.960854
epoch:9, step:123, loss:  0.078470, precision:  0.944444, f1:  0.944444
epoch:9, step:124, loss:  0.031827, precision:  0.986014, f1:  0.972414
epoch:9, step:125, loss:  0.087839, precision:  0.912752, f1:  0.931507
epoch:9, step:126, loss:  0.052577, precision:  0.970370, f1:  0.963235
epoch:9, step:127, loss:  0.086376, precision:  0.901316, f1:  0.928814
epoch:9, step:128, loss:  0.047022, precision:  0.951389, f1:  0.961403
epoch:9, step:129, loss:  0.037524, precision:  0.960317, f1:  0.968000
epoch:9, step:130, loss:  0.048053, precision:  0.956522, f1:  0.967033
epoch:9, step:131, loss:  0.028920, precision:  0.954887, f1:  0.965779
epoch:9, step:132, loss:  0.083953, precision:  0.925373, f1:  0.921933
epoch:9, step:133, loss:  0.056411, precision:  0.962963, f1:  0.955882
epoch:9, step:134, loss:  0.033806, precision:  0.977099, f1:  0.980843
epoch:9, step:135, loss:  0.042178, precision:  0.969925, f1:  0.962687
epoch:9, step:136, loss:  0.032823, precision:  0.984496, f1:  0.980695
epoch:9, step:137, loss:  0.038992, precision:  0.954128, f1:  0.958525
epoch:9, step:138, loss:  0.031605, precision:  0.975410, f1:  0.971429
epoch:9, step:139, loss:  0.046086, precision:  0.937107, f1:  0.955128
epoch:9, step:140, loss:  0.059737, precision:  0.935065, f1:  0.960000
epoch:9, step:141, loss:  0.101197, precision:  0.870748, f1:  0.907801
epoch:9, step:142, loss:  0.068449, precision:  0.928571, f1:  0.935252
epoch:9, step:143, loss:  0.045037, precision:  0.978723, f1:  0.968421
epoch:9, step:144, loss:  0.076452, precision:  0.932836, f1:  0.925926
epoch:9, step:145, loss:  0.051162, precision:  0.954545, f1:  0.943820
epoch:9, step:146, loss:  0.061210, precision:  0.951389, f1:  0.938356
epoch:9, step:147, loss:  0.040063, precision:  0.965035, f1:  0.971831
epoch:9, step:148, loss:  0.047246, precision:  0.937500, f1:  0.964286
epoch:9, step:149, loss:  0.070560, precision:  0.935252, f1:  0.945455
epoch:9, step:150, loss:  0.096554, precision:  0.931973, f1:  0.935154
epoch:9, step:151, loss:  0.042077, precision:  0.967105, f1:  0.980000
epoch:9, step:152, loss:  0.050121, precision:  0.958621, f1:  0.965278
epoch:9, step:153, loss:  0.072869, precision:  0.955556, f1:  0.945055
epoch:9, step:154, loss:  0.055885, precision:  0.936620, f1:  0.943262
epoch:9, step:155, loss:  0.075162, precision:  0.966887, f1:  0.954248
epoch:9, step:156, loss:  0.063878, precision:  0.915493, f1:  0.928571
epoch:9, step:157, loss:  0.064929, precision:  0.937984, f1:  0.937984
epoch:9, step:158, loss:  0.067534, precision:  0.941558, f1:  0.947712
epoch:9, step:159, loss:  0.049099, precision:  0.966887, f1:  0.976589
epoch:9, step:160, loss:  0.055703, precision:  0.937107, f1:  0.961290
epoch:9, step:161, loss:  0.060036, precision:  0.935484, f1:  0.935484
epoch:9, step:162, loss:  0.049193, precision:  0.947368, f1:  0.950943
epoch:9, step:163, loss:  0.057051, precision:  0.945205, f1:  0.945205
epoch:9, step:164, loss:  0.061476, precision:  0.949640, f1:  0.956522
epoch:9, step:165, loss:  0.030000, precision:  0.956835, f1:  0.967273
epoch:9, step:166, loss:  0.048813, precision:  0.965753, f1:  0.969072
epoch:9, step:167, loss:  0.027681, precision:  0.969466, f1:  0.973180
epoch:9, valid_f1:  0.787843, valid_precision:  0.770441, valid_recall:  0.806542
epoch:10, step:0, loss:  0.032380, precision:  0.943662, f1:  0.971014
epoch:10, step:1, loss:  0.062278, precision:  0.938931, f1:  0.931818
epoch:10, step:2, loss:  0.029923, precision:  0.954545, f1:  0.969231
epoch:10, step:3, loss:  0.060028, precision:  0.945312, f1:  0.941634
epoch:10, step:4, loss:  0.036529, precision:  0.973684, f1:  0.976898
epoch:10, step:5, loss:  0.033691, precision:  0.969697, f1:  0.973384
epoch:10, step:6, loss:  0.031123, precision:  0.958333, f1:  0.968421
epoch:10, step:7, loss:  0.041355, precision:  0.984127, f1:  0.968750
epoch:10, step:8, loss:  0.022955, precision:  0.977444, f1:  0.984848
epoch:10, step:9, loss:  0.049282, precision:  0.943662, f1:  0.953737
epoch:10, step:10, loss:  0.025431, precision:  0.965035, f1:  0.982206
epoch:10, step:11, loss:  0.054294, precision:  0.965753, f1:  0.949495
epoch:10, step:12, loss:  0.054021, precision:  0.945946, f1:  0.949153
epoch:10, step:13, loss:  0.060375, precision:  0.946565, f1:  0.957529
epoch:10, step:14, loss:  0.080097, precision:  0.958621, f1:  0.955326
epoch:10, step:15, loss:  0.024069, precision:  0.979592, f1:  0.986301
epoch:10, step:16, loss:  0.031609, precision:  0.973856, f1:  0.977049
epoch:10, step:17, loss:  0.027074, precision:  0.962687, f1:  0.969925
epoch:10, step:18, loss:  0.027729, precision:  0.971831, f1:  0.975265
epoch:10, step:19, loss:  0.027746, precision:  0.965753, f1:  0.972414
epoch:10, step:20, loss:  0.034880, precision:  0.970370, f1:  0.977612
epoch:10, step:21, loss:  0.050109, precision:  0.973510, f1:  0.963934
epoch:10, step:22, loss:  0.050998, precision:  0.965278, f1:  0.975439
epoch:10, step:23, loss:  0.048410, precision:  0.969697, f1:  0.962406
epoch:10, step:24, loss:  0.049895, precision:  0.953642, f1:  0.956811
epoch:10, step:25, loss:  0.066231, precision:  0.906040, f1:  0.931035
epoch:10, step:26, loss:  0.028625, precision:  0.934783, f1:  0.959108
epoch:10, step:27, loss:  0.039917, precision:  0.955882, f1:  0.962963
epoch:10, step:28, loss:  0.024628, precision:  0.980519, f1:  0.983713
epoch:10, step:29, loss:  0.062500, precision:  0.952381, f1:  0.939597
epoch:10, step:30, loss:  0.056421, precision:  0.939394, f1:  0.939394
epoch:10, step:31, loss:  0.038678, precision:  0.958042, f1:  0.968198
epoch:10, step:32, loss:  0.038173, precision:  0.986207, f1:  0.976109
epoch:10, step:33, loss:  0.049875, precision:  0.934641, f1:  0.956522
epoch:10, step:34, loss:  0.020820, precision:  0.975309, f1:  0.987500
epoch:10, step:35, loss:  0.050271, precision:  0.956897, f1:  0.956897
epoch:10, step:36, loss:  0.043649, precision:  0.956204, f1:  0.966790
epoch:10, step:37, loss:  0.053038, precision:  0.958904, f1:  0.958904
epoch:10, step:38, loss:  0.043623, precision:  0.967532, f1:  0.964401
epoch:10, step:39, loss:  0.028129, precision:  0.950355, f1:  0.964029
epoch:10, step:40, loss:  0.043269, precision:  0.971429, f1:  0.974910
epoch:10, step:41, loss:  0.044290, precision:  0.964789, f1:  0.968198
epoch:10, step:42, loss:  0.027475, precision:  0.978102, f1:  0.974545
epoch:10, step:43, loss:  0.056561, precision:  0.944785, f1:  0.953560
epoch:10, step:44, loss:  0.059677, precision:  0.942029, f1:  0.952381
epoch:10, step:45, loss:  0.051050, precision:  0.957143, f1:  0.950355
epoch:10, step:46, loss:  0.041157, precision:  0.969925, f1:  0.966292
epoch:10, step:47, loss:  0.027594, precision:  0.974522, f1:  0.987097
epoch:10, step:48, loss:  0.034201, precision:  0.978102, f1:  0.967509
epoch:10, step:49, loss:  0.085430, precision:  0.937500, f1:  0.937500
epoch:10, step:50, loss:  0.041044, precision:  0.962406, f1:  0.966038
epoch:10, step:51, loss:  0.073732, precision:  0.906040, f1:  0.921502
epoch:10, step:52, loss:  0.069134, precision:  0.960630, f1:  0.953125
epoch:10, step:53, loss:  0.045972, precision:  0.965035, f1:  0.968421
epoch:10, step:54, loss:  0.013139, precision:  0.984252, f1:  0.996016
epoch:10, step:55, loss:  0.035595, precision:  0.950000, f1:  0.970803
epoch:10, step:56, loss:  0.038052, precision:  0.960317, f1:  0.964143
epoch:10, step:57, loss:  0.058974, precision:  0.923077, f1:  0.946237
epoch:10, step:58, loss:  0.052658, precision:  0.939850, f1:  0.954198
epoch:10, step:59, loss:  0.041783, precision:  0.976000, f1:  0.964427
epoch:10, step:60, loss:  0.032071, precision:  0.962406, f1:  0.980843
epoch:10, step:61, loss:  0.042661, precision:  0.953333, f1:  0.959732
epoch:10, step:62, loss:  0.048480, precision:  0.942446, f1:  0.956204
epoch:10, step:63, loss:  0.033340, precision:  0.978102, f1:  0.967509
epoch:10, step:64, loss:  0.052844, precision:  0.962121, f1:  0.940741
epoch:10, step:65, loss:  0.077419, precision:  0.944056, f1:  0.934256
epoch:10, step:66, loss:  0.037981, precision:  0.961832, f1:  0.961832
epoch:10, step:67, loss:  0.028257, precision:  0.972028, f1:  0.978873
epoch:10, step:68, loss:  0.033752, precision:  0.954887, f1:  0.962121
epoch:10, step:69, loss:  0.034031, precision:  0.959732, f1:  0.982818
epoch:10, step:70, loss:  0.052085, precision:  0.956204, f1:  0.959707
epoch:10, step:71, loss:  0.036479, precision:  0.957055, f1:  0.975000
epoch:10, step:72, loss:  0.038837, precision:  0.950704, f1:  0.957447
epoch:10, step:73, loss:  0.029064, precision:  0.958904, f1:  0.975610
epoch:10, step:74, loss:  0.048650, precision:  0.952381, f1:  0.965517
epoch:10, step:75, loss:  0.085761, precision:  0.950355, f1:  0.937063
epoch:10, step:76, loss:  0.028900, precision:  0.977444, f1:  0.973783
epoch:10, step:77, loss:  0.051414, precision:  0.950000, f1:  0.962025
epoch:10, step:78, loss:  0.040380, precision:  0.970803, f1:  0.963768
epoch:10, step:79, loss:  0.033547, precision:  0.976378, f1:  0.976378
epoch:10, step:80, loss:  0.029423, precision:  0.965517, f1:  0.979021
epoch:10, step:81, loss:  0.032041, precision:  0.964789, f1:  0.975089
epoch:10, step:82, loss:  0.053341, precision:  0.939597, f1:  0.955631
epoch:10, step:83, loss:  0.049753, precision:  0.947368, f1:  0.950495
epoch:10, step:84, loss:  0.019203, precision:  0.979452, f1:  0.993056
epoch:10, step:85, loss:  0.042751, precision:  0.943396, f1:  0.964630
epoch:10, step:86, loss:  0.049219, precision:  0.916667, f1:  0.949640
epoch:10, step:87, loss:  0.021886, precision:  0.980392, f1:  0.990099
epoch:10, step:88, loss:  0.057946, precision:  0.974194, f1:  0.967949
epoch:10, step:89, loss:  0.046940, precision:  0.955128, f1:  0.961290
epoch:10, step:90, loss:  0.034153, precision:  0.973510, f1:  0.973510
epoch:10, step:91, loss:  0.071129, precision:  0.943089, f1:  0.935484
epoch:10, step:92, loss:  0.052113, precision:  0.954248, f1:  0.957377
epoch:10, step:93, loss:  0.072137, precision:  0.930818, f1:  0.939683
epoch:10, step:94, loss:  0.074179, precision:  0.924051, f1:  0.944984
epoch:10, step:95, loss:  0.052697, precision:  0.934783, f1:  0.945055
epoch:10, step:96, loss:  0.050984, precision:  0.944444, f1:  0.965300
epoch:10, step:97, loss:  0.032546, precision:  0.961240, f1:  0.964981
epoch:10, step:98, loss:  0.043587, precision:  0.955882, f1:  0.955882
epoch:10, step:99, loss:  0.070675, precision:  0.937008, f1:  0.918919
epoch:10, step:100, loss:  0.043913, precision:  0.962733, f1:  0.965732
epoch:10, step:101, loss:  0.042540, precision:  0.971631, f1:  0.958042
epoch:10, step:102, loss:  0.043106, precision:  0.970803, f1:  0.960289
epoch:10, step:103, loss:  0.029238, precision:  0.972414, f1:  0.975779
epoch:10, step:104, loss:  0.041054, precision:  0.971014, f1:  0.967509
epoch:10, step:105, loss:  0.060131, precision:  0.949045, f1:  0.955128
epoch:10, step:106, loss:  0.051051, precision:  0.953125, f1:  0.953125
epoch:10, step:107, loss:  0.071211, precision:  0.925373, f1:  0.946565
epoch:10, step:108, loss:  0.049539, precision:  0.951724, f1:  0.961672
epoch:10, step:109, loss:  0.074687, precision:  0.923077, f1:  0.936170
epoch:10, step:110, loss:  0.071791, precision:  0.933824, f1:  0.933824
epoch:10, step:111, loss:  0.039875, precision:  0.959184, f1:  0.959184
epoch:10, step:112, loss:  0.052070, precision:  0.964286, f1:  0.960854
epoch:10, step:113, loss:  0.042775, precision:  0.970803, f1:  0.970803
epoch:10, step:114, loss:  0.035274, precision:  0.972222, f1:  0.962199
epoch:10, step:115, loss:  0.063494, precision:  0.934959, f1:  0.942623
epoch:10, step:116, loss:  0.053388, precision:  0.962264, f1:  0.959248
epoch:10, step:117, loss:  0.046556, precision:  0.956250, f1:  0.959248
epoch:10, step:118, loss:  0.061485, precision:  0.937107, f1:  0.946032
epoch:10, step:119, loss:  0.036805, precision:  0.960000, f1:  0.979592
epoch:10, step:120, loss:  0.036377, precision:  0.951049, f1:  0.961131
epoch:10, step:121, loss:  0.054160, precision:  0.973333, f1:  0.966887
epoch:10, step:122, loss:  0.034474, precision:  0.962687, f1:  0.962687
epoch:10, step:123, loss:  0.037361, precision:  0.973154, f1:  0.969900
epoch:10, step:124, loss:  0.051963, precision:  0.950355, f1:  0.957143
epoch:10, step:125, loss:  0.056163, precision:  0.963636, f1:  0.952096
epoch:10, step:126, loss:  0.100099, precision:  0.941606, f1:  0.941606
epoch:10, step:127, loss:  0.056947, precision:  0.933735, f1:  0.948012
epoch:10, step:128, loss:  0.051633, precision:  0.921875, f1:  0.932806
epoch:10, step:129, loss:  0.030120, precision:  0.946970, f1:  0.968992
epoch:10, step:130, loss:  0.032408, precision:  0.971223, f1:  0.978261
epoch:10, step:131, loss:  0.060620, precision:  0.941606, f1:  0.959108
epoch:10, step:132, loss:  0.041459, precision:  0.958904, f1:  0.975610
epoch:10, step:133, loss:  0.062272, precision:  0.959064, f1:  0.947977
epoch:10, step:134, loss:  0.049922, precision:  0.975155, f1:  0.978193
epoch:10, step:135, loss:  0.074491, precision:  0.932886, f1:  0.936027
epoch:10, step:136, loss:  0.065800, precision:  0.944444, f1:  0.944444
epoch:10, step:137, loss:  0.022888, precision:  0.981013, f1:  0.987261
epoch:10, step:138, loss:  0.045736, precision:  0.935714, f1:  0.956204
epoch:10, step:139, loss:  0.108155, precision:  0.891892, f1:  0.894915
epoch:10, step:140, loss:  0.050994, precision:  0.964029, f1:  0.971014
epoch:10, step:141, loss:  0.056995, precision:  0.951219, f1:  0.968944
epoch:10, step:142, loss:  0.025691, precision:  0.978417, f1:  0.967972
epoch:10, step:143, loss:  0.037056, precision:  0.972414, f1:  0.979167
epoch:10, step:144, loss:  0.054460, precision:  0.952381, f1:  0.945946
epoch:10, step:145, loss:  0.058084, precision:  0.935252, f1:  0.942029
epoch:10, step:146, loss:  0.057951, precision:  0.937931, f1:  0.947735
epoch:10, step:147, loss:  0.061091, precision:  0.938356, f1:  0.944828
epoch:10, step:148, loss:  0.058442, precision:  0.950311, f1:  0.956250
epoch:10, step:149, loss:  0.042409, precision:  0.960784, f1:  0.963934
epoch:10, step:150, loss:  0.034248, precision:  0.947761, f1:  0.958491
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.13it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.22it/s]Validating:  14%|█▍        | 3/21 [00:01<00:08,  2.18it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.19it/s]Validating:  24%|██▍       | 5/21 [00:02<00:07,  2.28it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.25it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.33it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.26it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.23it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.23it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.25it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.14it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.16it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.25it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.22it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.27it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.24it/s]Validating:  86%|████████▌ | 18/21 [00:08<00:01,  2.29it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.32it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.27it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.37it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.27it/s]
epoch:10, step:151, loss:  0.041816, precision:  0.940476, f1:  0.966361
epoch:10, step:152, loss:  0.060157, precision:  0.952096, f1:  0.952096
epoch:10, step:153, loss:  0.038238, precision:  0.951389, f1:  0.961403
epoch:10, step:154, loss:  0.076096, precision:  0.930233, f1:  0.930233
epoch:10, step:155, loss:  0.091319, precision:  0.921986, f1:  0.915493
epoch:10, step:156, loss:  0.045671, precision:  0.960526, f1:  0.957377
epoch:10, step:157, loss:  0.050326, precision:  0.947368, f1:  0.954545
epoch:10, step:158, loss:  0.031892, precision:  0.969925, f1:  0.977273
epoch:10, step:159, loss:  0.027147, precision:  0.963504, f1:  0.970588
epoch:10, step:160, loss:  0.037148, precision:  0.953125, f1:  0.960630
epoch:10, step:161, loss:  0.062505, precision:  0.943548, f1:  0.943548
epoch:10, step:162, loss:  0.034406, precision:  0.943262, f1:  0.967273
epoch:10, step:163, loss:  0.080175, precision:  0.899329, f1:  0.908475
epoch:10, step:164, loss:  0.058617, precision:  0.945578, f1:  0.955326
epoch:10, step:165, loss:  0.049579, precision:  0.917808, f1:  0.946996
epoch:10, step:166, loss:  0.033788, precision:  0.971429, f1:  0.974910
epoch:10, step:167, loss:  0.050887, precision:  0.944056, f1:  0.947368
epoch:10, valid_f1:  0.785327, valid_precision:  0.766049, valid_recall:  0.806150
epoch:11, step:0, loss:  0.046462, precision:  0.945578, f1:  0.968641
epoch:11, step:1, loss:  0.037616, precision:  0.962121, f1:  0.962121
epoch:11, step:2, loss:  0.040212, precision:  0.936508, f1:  0.947791
epoch:11, step:3, loss:  0.048013, precision:  0.948905, f1:  0.955882
epoch:11, step:4, loss:  0.026667, precision:  0.964286, f1:  0.978261
epoch:11, step:5, loss:  0.035875, precision:  0.953846, f1:  0.961240
epoch:11, step:6, loss:  0.049999, precision:  0.959184, f1:  0.969072
epoch:11, step:7, loss:  0.015501, precision:  0.985816, f1:  0.996416
epoch:11, step:8, loss:  0.049074, precision:  0.971223, f1:  0.967742
epoch:11, step:9, loss:  0.027515, precision:  0.971831, f1:  0.978723
epoch:11, step:10, loss:  0.047198, precision:  0.964286, f1:  0.954064
epoch:11, step:11, loss:  0.042446, precision:  0.956790, f1:  0.971787
epoch:11, step:12, loss:  0.022297, precision:  0.986486, f1:  0.993197
epoch:11, step:13, loss:  0.039356, precision:  0.965217, f1:  0.969432
epoch:11, step:14, loss:  0.031534, precision:  0.962733, f1:  0.971787
epoch:11, step:15, loss:  0.031049, precision:  0.968354, f1:  0.977636
epoch:11, step:16, loss:  0.040360, precision:  0.952381, f1:  0.966767
epoch:11, step:17, loss:  0.053879, precision:  0.921569, f1:  0.946309
epoch:11, step:18, loss:  0.029826, precision:  0.964072, f1:  0.978723
epoch:11, step:19, loss:  0.041980, precision:  0.969880, f1:  0.975758
epoch:11, step:20, loss:  0.041480, precision:  0.962963, f1:  0.962963
epoch:11, step:21, loss:  0.037705, precision:  0.965278, f1:  0.972028
epoch:11, step:22, loss:  0.055563, precision:  0.928105, f1:  0.949833
epoch:11, step:23, loss:  0.029547, precision:  0.981132, f1:  0.981132
epoch:11, step:24, loss:  0.035773, precision:  0.964286, f1:  0.967742
epoch:11, step:25, loss:  0.026657, precision:  0.971223, f1:  0.974729
epoch:11, step:26, loss:  0.042361, precision:  0.975904, f1:  0.978852
epoch:11, step:27, loss:  0.057661, precision:  0.935252, f1:  0.942029
epoch:11, step:28, loss:  0.039536, precision:  0.961538, f1:  0.974026
epoch:11, step:29, loss:  0.040537, precision:  0.953488, f1:  0.957198
epoch:11, step:30, loss:  0.036603, precision:  0.952381, f1:  0.958904
epoch:11, step:31, loss:  0.036154, precision:  0.956790, f1:  0.971787
epoch:11, step:32, loss:  0.036129, precision:  0.962963, f1:  0.968944
epoch:11, step:33, loss:  0.043252, precision:  0.915584, f1:  0.949495
epoch:11, step:34, loss:  0.051983, precision:  0.950355, f1:  0.957143
epoch:11, step:35, loss:  0.039147, precision:  0.972414, f1:  0.972414
epoch:11, step:36, loss:  0.023057, precision:  0.984127, f1:  0.988048
epoch:11, step:37, loss:  0.038399, precision:  0.979167, f1:  0.975779
epoch:11, step:38, loss:  0.035612, precision:  0.970803, f1:  0.967273
epoch:11, step:39, loss:  0.051063, precision:  0.952703, f1:  0.949495
epoch:11, step:40, loss:  0.025828, precision:  0.970588, f1:  0.981413
epoch:11, step:41, loss:  0.040826, precision:  0.966216, f1:  0.976109
epoch:11, step:42, loss:  0.047621, precision:  0.943662, f1:  0.960573
epoch:11, step:43, loss:  0.036115, precision:  0.958904, f1:  0.958904
epoch:11, step:44, loss:  0.034083, precision:  0.988571, f1:  0.988571
epoch:11, step:45, loss:  0.026449, precision:  0.953125, f1:  0.972112
epoch:11, step:46, loss:  0.043053, precision:  0.961538, f1:  0.957854
epoch:11, step:47, loss:  0.035197, precision:  0.959184, f1:  0.965753
epoch:11, step:48, loss:  0.071793, precision:  0.933824, f1:  0.937269
epoch:11, step:49, loss:  0.036162, precision:  0.974843, f1:  0.974843
epoch:11, step:50, loss:  0.019696, precision:  0.953488, f1:  0.972332
epoch:11, step:51, loss:  0.040704, precision:  0.942857, f1:  0.960000
epoch:11, step:52, loss:  0.054939, precision:  0.930556, f1:  0.950355
epoch:11, step:53, loss:  0.053025, precision:  0.948148, f1:  0.948148
epoch:11, step:54, loss:  0.056071, precision:  0.944828, f1:  0.958042
epoch:11, step:55, loss:  0.032690, precision:  0.968254, f1:  0.949416
epoch:11, step:56, loss:  0.045081, precision:  0.983740, f1:  0.960317
epoch:11, step:57, loss:  0.012172, precision:  0.992000, f1:  0.995984
epoch:11, step:58, loss:  0.035446, precision:  0.977941, f1:  0.977941
epoch:11, step:59, loss:  0.050177, precision:  0.962687, f1:  0.955556
epoch:11, step:60, loss:  0.017519, precision:  0.978571, f1:  0.989170
epoch:11, step:61, loss:  0.035339, precision:  0.961290, f1:  0.970684
epoch:11, step:62, loss:  0.033364, precision:  0.942029, f1:  0.962963
epoch:11, step:63, loss:  0.024119, precision:  0.964029, f1:  0.978102
epoch:11, step:64, loss:  0.046222, precision:  0.937063, f1:  0.957143
epoch:11, step:65, loss:  0.038035, precision:  0.962264, f1:  0.974522
epoch:11, step:66, loss:  0.018726, precision:  0.981132, f1:  0.990476
epoch:11, step:67, loss:  0.026585, precision:  0.969925, f1:  0.977273
epoch:11, step:68, loss:  0.028657, precision:  0.984962, f1:  0.977612
epoch:11, step:69, loss:  0.039649, precision:  0.971831, f1:  0.961672
epoch:11, step:70, loss:  0.022780, precision:  0.985915, f1:  0.985915
epoch:11, step:71, loss:  0.035278, precision:  0.958621, f1:  0.965278
epoch:11, step:72, loss:  0.044991, precision:  0.956790, f1:  0.968750
epoch:11, step:73, loss:  0.029367, precision:  0.951219, f1:  0.979079
epoch:11, step:74, loss:  0.016139, precision:  0.993671, f1:  0.990536
epoch:11, step:75, loss:  0.038121, precision:  0.970370, f1:  0.977612
epoch:11, step:76, loss:  0.031228, precision:  0.984733, f1:  0.973585
epoch:11, step:77, loss:  0.016558, precision:  0.979452, f1:  0.986207
epoch:11, step:78, loss:  0.064045, precision:  0.944444, f1:  0.944444
epoch:11, step:79, loss:  0.021521, precision:  0.980000, f1:  0.989899
epoch:11, step:80, loss:  0.049359, precision:  0.946970, f1:  0.946970
epoch:11, step:81, loss:  0.042173, precision:  0.975309, f1:  0.978328
epoch:11, step:82, loss:  0.055564, precision:  0.972603, f1:  0.969283
epoch:11, step:83, loss:  0.019483, precision:  0.985816, f1:  0.989324
epoch:11, step:84, loss:  0.030542, precision:  0.963504, f1:  0.974170
epoch:11, step:85, loss:  0.041486, precision:  0.957143, f1:  0.960573
epoch:11, step:86, loss:  0.051359, precision:  0.946565, f1:  0.953846
epoch:11, step:87, loss:  0.043363, precision:  0.968000, f1:  0.964143
epoch:11, step:88, loss:  0.058845, precision:  0.949686, f1:  0.952681
epoch:11, step:89, loss:  0.039827, precision:  0.947020, f1:  0.959732
epoch:11, step:90, loss:  0.018500, precision:  0.965986, f1:  0.982699
epoch:11, step:91, loss:  0.044357, precision:  0.933333, f1:  0.950943
epoch:11, step:92, loss:  0.034635, precision:  0.961538, f1:  0.967742
epoch:11, step:93, loss:  0.055220, precision:  0.942446, f1:  0.952727
epoch:11, step:94, loss:  0.025209, precision:  0.979866, f1:  0.983165
epoch:11, step:95, loss:  0.024180, precision:  0.967105, f1:  0.980000
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:07,  2.61it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.44it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.49it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.38it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.34it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.38it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.33it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.42it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.31it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.31it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.24it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.22it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.18it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.15it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.38it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.32it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.31it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.28it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.12it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.23it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.26it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.28it/s]
epoch:11, step:96, loss:  0.044956, precision:  0.975000, f1:  0.981132
epoch:11, step:97, loss:  0.040362, precision:  0.970803, f1:  0.963768
epoch:11, step:98, loss:  0.039191, precision:  0.966942, f1:  0.962963
epoch:11, step:99, loss:  0.035947, precision:  0.945946, f1:  0.958904
epoch:11, step:100, loss:  0.015733, precision:  0.966443, f1:  0.986301
epoch:11, step:101, loss:  0.042785, precision:  0.984848, f1:  0.981132
epoch:11, step:102, loss:  0.040579, precision:  0.929936, f1:  0.957377
epoch:11, step:103, loss:  0.028568, precision:  0.946154, f1:  0.968504
epoch:11, step:104, loss:  0.036337, precision:  0.960630, f1:  0.964427
epoch:11, step:105, loss:  0.025340, precision:  0.992701, f1:  0.981949
epoch:11, step:106, loss:  0.019619, precision:  0.986014, f1:  0.986014
epoch:11, step:107, loss:  0.029738, precision:  0.961538, f1:  0.970874
epoch:11, step:108, loss:  0.049695, precision:  0.934959, f1:  0.938776
epoch:11, step:109, loss:  0.046664, precision:  0.959732, f1:  0.966216
epoch:11, step:110, loss:  0.014635, precision:  0.985401, f1:  0.992647
epoch:11, step:111, loss:  0.033304, precision:  0.952756, f1:  0.971888
epoch:11, step:112, loss:  0.041568, precision:  0.961538, f1:  0.961538
epoch:11, step:113, loss:  0.046289, precision:  0.918750, f1:  0.951456
epoch:11, step:114, loss:  0.030356, precision:  0.966667, f1:  0.973154
epoch:11, step:115, loss:  0.055682, precision:  0.947368, f1:  0.941176
epoch:11, step:116, loss:  0.041137, precision:  0.949045, f1:  0.958199
epoch:11, step:117, loss:  0.035706, precision:  0.954887, f1:  0.954887
epoch:11, step:118, loss:  0.023764, precision:  0.978571, f1:  0.982079
epoch:11, step:119, loss:  0.025801, precision:  0.979167, f1:  0.982578
epoch:11, step:120, loss:  0.023797, precision:  0.977273, f1:  0.980989
epoch:11, step:121, loss:  0.021457, precision:  0.985294, f1:  0.985294
epoch:11, step:122, loss:  0.045282, precision:  0.954545, f1:  0.960784
epoch:11, step:123, loss:  0.045198, precision:  0.957447, f1:  0.960854
epoch:11, step:124, loss:  0.048257, precision:  0.953488, f1:  0.960938
epoch:11, step:125, loss:  0.039329, precision:  0.946667, f1:  0.959459
epoch:11, step:126, loss:  0.013512, precision:  0.985075, f1:  0.992481
epoch:11, step:127, loss:  0.029371, precision:  0.965753, f1:  0.979167
epoch:11, step:128, loss:  0.045879, precision:  0.948052, f1:  0.966887
epoch:11, step:129, loss:  0.046181, precision:  0.965035, f1:  0.968421
epoch:11, step:130, loss:  0.029275, precision:  0.978723, f1:  0.975265
epoch:11, step:131, loss:  0.025926, precision:  0.979866, f1:  0.979866
epoch:11, step:132, loss:  0.031522, precision:  0.978723, f1:  0.968421
epoch:11, step:133, loss:  0.046357, precision:  0.973684, f1:  0.964169
epoch:11, step:134, loss:  0.029696, precision:  0.959016, f1:  0.966942
epoch:11, step:135, loss:  0.036629, precision:  0.958333, f1:  0.965035
epoch:11, step:136, loss:  0.041752, precision:  0.953642, f1:  0.972973
epoch:11, step:137, loss:  0.043321, precision:  0.948052, f1:  0.960526
epoch:11, step:138, loss:  0.038370, precision:  0.946970, f1:  0.950570
epoch:11, step:139, loss:  0.045282, precision:  0.947712, f1:  0.957096
epoch:11, step:140, loss:  0.054231, precision:  0.945578, f1:  0.955326
epoch:11, step:141, loss:  0.056646, precision:  0.958621, f1:  0.955326
epoch:11, step:142, loss:  0.032670, precision:  0.981481, f1:  0.972477
epoch:11, step:143, loss:  0.035367, precision:  0.979167, f1:  0.975779
epoch:11, step:144, loss:  0.020544, precision:  0.993197, f1:  0.989830
epoch:11, step:145, loss:  0.066005, precision:  0.929032, f1:  0.950495
epoch:11, step:146, loss:  0.040785, precision:  0.959732, f1:  0.969492
epoch:11, step:147, loss:  0.044699, precision:  0.938462, f1:  0.953125
epoch:11, step:148, loss:  0.022488, precision:  0.971631, f1:  0.978571
epoch:11, step:149, loss:  0.020663, precision:  0.970370, f1:  0.984962
epoch:11, step:150, loss:  0.016161, precision:  0.970149, f1:  0.984848
epoch:11, step:151, loss:  0.064615, precision:  0.907801, f1:  0.924188
epoch:11, step:152, loss:  0.052173, precision:  0.976744, f1:  0.958175
epoch:11, step:153, loss:  0.059035, precision:  0.942308, f1:  0.951456
epoch:11, step:154, loss:  0.036539, precision:  0.992424, f1:  0.977612
epoch:11, step:155, loss:  0.057453, precision:  0.939850, f1:  0.950570
epoch:11, step:156, loss:  0.043383, precision:  0.962264, f1:  0.974522
epoch:11, step:157, loss:  0.053111, precision:  0.940789, f1:  0.953333
epoch:11, step:158, loss:  0.051075, precision:  0.962687, f1:  0.962687
epoch:11, step:159, loss:  0.026126, precision:  0.956204, f1:  0.973978
epoch:11, step:160, loss:  0.054784, precision:  0.940298, f1:  0.954545
epoch:11, step:161, loss:  0.021513, precision:  0.978102, f1:  0.985294
epoch:11, step:162, loss:  0.042254, precision:  0.979866, f1:  0.970100
epoch:11, step:163, loss:  0.038102, precision:  0.973684, f1:  0.973684
epoch:11, step:164, loss:  0.030933, precision:  0.970370, f1:  0.970370
epoch:11, step:165, loss:  0.039284, precision:  0.965278, f1:  0.968641
epoch:11, step:166, loss:  0.026919, precision:  0.971631, f1:  0.971631
epoch:11, step:167, loss:  0.042296, precision:  0.959459, f1:  0.962712
epoch:11, valid_f1:  0.789717, valid_precision:  0.777488, valid_recall:  0.802669
epoch:12, step:0, loss:  0.019462, precision:  0.986207, f1:  0.989619
epoch:12, step:1, loss:  0.030740, precision:  0.961039, f1:  0.976898
epoch:12, step:2, loss:  0.037930, precision:  0.956250, f1:  0.974522
epoch:12, step:3, loss:  0.034171, precision:  0.961039, f1:  0.967320
epoch:12, step:4, loss:  0.019433, precision:  0.993056, f1:  0.996516
epoch:12, step:5, loss:  0.029799, precision:  0.962121, f1:  0.973180
epoch:12, step:6, loss:  0.043175, precision:  0.934307, f1:  0.955224
epoch:12, step:7, loss:  0.031320, precision:  0.951049, f1:  0.967972
epoch:12, step:8, loss:  0.025364, precision:  0.971429, f1:  0.978417
epoch:12, step:9, loss:  0.026973, precision:  0.986111, f1:  0.982699
epoch:12, step:10, loss:  0.040779, precision:  0.964539, f1:  0.954386
epoch:12, step:11, loss:  0.028935, precision:  0.964789, f1:  0.975089
epoch:12, step:12, loss:  0.017609, precision:  0.986577, f1:  0.986577
epoch:12, step:13, loss:  0.020433, precision:  0.979592, f1:  0.986301
epoch:12, step:14, loss:  0.028600, precision:  0.986486, f1:  0.986486
epoch:12, step:15, loss:  0.043384, precision:  0.964286, f1:  0.981818
epoch:12, step:16, loss:  0.032996, precision:  0.953020, f1:  0.969283
epoch:12, step:17, loss:  0.018055, precision:  0.969925, f1:  0.988506
epoch:12, step:18, loss:  0.012211, precision:  0.979730, f1:  0.989761
epoch:12, step:19, loss:  0.034655, precision:  0.978571, f1:  0.975089
epoch:12, step:20, loss:  0.026007, precision:  0.984000, f1:  0.987952
epoch:12, step:21, loss:  0.047617, precision:  0.968750, f1:  0.977918
epoch:12, step:22, loss:  0.022149, precision:  0.969466, f1:  0.980695
epoch:12, step:23, loss:  0.045004, precision:  0.978261, f1:  0.964286
epoch:12, step:24, loss:  0.014738, precision:  0.992366, f1:  0.996169
epoch:12, step:25, loss:  0.014231, precision:  0.986667, f1:  0.993289
epoch:12, step:26, loss:  0.053784, precision:  0.970803, f1:  0.960289
epoch:12, step:27, loss:  0.022735, precision:  0.965035, f1:  0.978723
epoch:12, step:28, loss:  0.043342, precision:  0.966216, f1:  0.979452
epoch:12, step:29, loss:  0.024902, precision:  0.956522, f1:  0.970588
epoch:12, step:30, loss:  0.068504, precision:  0.947712, f1:  0.957096
epoch:12, step:31, loss:  0.020729, precision:  0.965986, f1:  0.979310
epoch:12, step:32, loss:  0.036626, precision:  0.958904, f1:  0.962199
epoch:12, step:33, loss:  0.028617, precision:  0.943262, f1:  0.960289
epoch:12, step:34, loss:  0.051831, precision:  0.951724, f1:  0.948454
epoch:12, step:35, loss:  0.033171, precision:  0.961538, f1:  0.970874
epoch:12, step:36, loss:  0.034513, precision:  0.973684, f1:  0.976898
epoch:12, step:37, loss:  0.032747, precision:  0.974359, f1:  0.977492
epoch:12, step:38, loss:  0.024916, precision:  0.977778, f1:  0.985075
epoch:12, step:39, loss:  0.029992, precision:  0.960265, f1:  0.976431
epoch:12, step:40, loss:  0.034300, precision:  0.962963, f1:  0.970149
epoch:12, step:41, loss:  0.025632, precision:  0.963190, f1:  0.984326
epoch:12, step:42, loss:  0.026647, precision:  0.948148, f1:  0.966038
epoch:12, step:43, loss:  0.047478, precision:  0.967105, f1:  0.967105
epoch:12, step:44, loss:  0.029590, precision:  0.968254, f1:  0.976000
epoch:12, step:45, loss:  0.021228, precision:  0.984962, f1:  0.988679
epoch:12, step:46, loss:  0.030032, precision:  0.972414, f1:  0.979167
epoch:12, step:47, loss:  0.025345, precision:  0.967532, f1:  0.980263
epoch:12, step:48, loss:  0.035051, precision:  0.960000, f1:  0.972973
epoch:12, step:49, loss:  0.019591, precision:  0.971831, f1:  0.985714
epoch:12, step:50, loss:  0.034358, precision:  0.965517, f1:  0.972222
epoch:12, step:51, loss:  0.039569, precision:  0.966667, f1:  0.969900
epoch:12, step:52, loss:  0.051916, precision:  0.965035, f1:  0.965035
epoch:12, step:53, loss:  0.031126, precision:  0.979452, f1:  0.979452
epoch:12, step:54, loss:  0.054164, precision:  0.943262, f1:  0.950000
epoch:12, step:55, loss:  0.024848, precision:  0.971831, f1:  0.978723
epoch:12, step:56, loss:  0.021366, precision:  0.977778, f1:  0.985075
epoch:12, step:57, loss:  0.020619, precision:  0.984848, f1:  0.977444
epoch:12, step:58, loss:  0.026058, precision:  0.973154, f1:  0.983051
epoch:12, step:59, loss:  0.021417, precision:  0.985507, f1:  0.985507
epoch:12, step:60, loss:  0.057304, precision:  0.959016, f1:  0.962963
epoch:12, step:61, loss:  0.026117, precision:  0.972973, f1:  0.982935
epoch:12, step:62, loss:  0.053579, precision:  0.938776, f1:  0.951724
epoch:12, step:63, loss:  0.014435, precision:  0.979452, f1:  0.993056
epoch:12, step:64, loss:  0.039611, precision:  0.956522, f1:  0.967033
epoch:12, step:65, loss:  0.047592, precision:  0.978723, f1:  0.978723
epoch:12, step:66, loss:  0.023718, precision:  0.963235, f1:  0.984962
epoch:12, step:67, loss:  0.029984, precision:  0.984848, f1:  0.973783
epoch:12, step:68, loss:  0.026403, precision:  0.986207, f1:  0.982818
epoch:12, step:69, loss:  0.015166, precision:  0.978571, f1:  0.985611
epoch:12, step:70, loss:  0.025712, precision:  0.965517, f1:  0.975610
epoch:12, step:71, loss:  0.017247, precision:  0.984962, f1:  0.984962
epoch:12, step:72, loss:  0.030138, precision:  0.979167, f1:  0.986014
epoch:12, step:73, loss:  0.031134, precision:  0.945205, f1:  0.971831
epoch:12, step:74, loss:  0.013673, precision:  0.979310, f1:  0.993007
epoch:12, step:75, loss:  0.018649, precision:  0.979310, f1:  0.982699
epoch:12, step:76, loss:  0.025857, precision:  0.953333, f1:  0.969492
epoch:12, step:77, loss:  0.018853, precision:  0.963504, f1:  0.981413
epoch:12, step:78, loss:  0.036001, precision:  0.975000, f1:  0.975000
epoch:12, step:79, loss:  0.040719, precision:  0.945578, f1:  0.958621
epoch:12, step:80, loss:  0.040704, precision:  0.969925, f1:  0.969925
epoch:12, step:81, loss:  0.015792, precision:  0.977612, f1:  0.988679
epoch:12, step:82, loss:  0.052819, precision:  0.942675, f1:  0.948718
epoch:12, step:83, loss:  0.045566, precision:  0.930070, f1:  0.953405
epoch:12, step:84, loss:  0.013244, precision:  0.993103, f1:  0.996540
epoch:12, step:85, loss:  0.023768, precision:  0.979730, f1:  0.983051
epoch:12, step:86, loss:  0.034647, precision:  0.972789, f1:  0.972789
epoch:12, step:87, loss:  0.051000, precision:  0.959459, f1:  0.969283
epoch:12, step:88, loss:  0.057100, precision:  0.956790, f1:  0.953846
epoch:12, step:89, loss:  0.041475, precision:  0.947761, f1:  0.962121
epoch:12, step:90, loss:  0.045107, precision:  0.900662, f1:  0.941176
epoch:12, step:91, loss:  0.034996, precision:  0.953020, f1:  0.965986
epoch:12, step:92, loss:  0.020121, precision:  0.985611, f1:  0.989170
epoch:12, step:93, loss:  0.036921, precision:  0.974522, f1:  0.968354
epoch:12, step:94, loss:  0.043284, precision:  0.935484, f1:  0.946939
epoch:12, step:95, loss:  0.028732, precision:  0.963235, f1:  0.966790
epoch:12, step:96, loss:  0.028434, precision:  0.974026, f1:  0.977199
epoch:12, step:97, loss:  0.046099, precision:  0.949045, f1:  0.964401
epoch:12, step:98, loss:  0.073392, precision:  0.954248, f1:  0.951140
epoch:12, step:99, loss:  0.030776, precision:  0.961240, f1:  0.968750
epoch:12, step:100, loss:  0.018595, precision:  0.992248, f1:  0.992248
epoch:12, step:101, loss:  0.030557, precision:  0.945578, f1:  0.968641
epoch:12, step:102, loss:  0.044493, precision:  0.945578, f1:  0.961938
epoch:12, step:103, loss:  0.032822, precision:  0.954545, f1:  0.967105
epoch:12, step:104, loss:  0.029047, precision:  0.971014, f1:  0.971014
epoch:12, step:105, loss:  0.015084, precision:  0.984496, f1:  0.992188
epoch:12, step:106, loss:  0.025441, precision:  0.960317, f1:  0.979757
epoch:12, step:107, loss:  0.023426, precision:  0.972028, f1:  0.972028
epoch:12, step:108, loss:  0.012653, precision:  0.992126, f1:  0.988235
epoch:12, step:109, loss:  0.035459, precision:  0.970370, f1:  0.973978
epoch:12, step:110, loss:  0.015533, precision:  0.987261, f1:  0.990415
epoch:12, step:111, loss:  0.039834, precision:  0.948905, f1:  0.948905
epoch:12, step:112, loss:  0.040671, precision:  0.964539, f1:  0.964539
epoch:12, step:113, loss:  0.028532, precision:  0.973154, f1:  0.983051
epoch:12, step:114, loss:  0.024056, precision:  0.975309, f1:  0.981366
epoch:12, step:115, loss:  0.042745, precision:  0.968504, f1:  0.953488
epoch:12, step:116, loss:  0.058166, precision:  0.951049, f1:  0.951049
epoch:12, step:117, loss:  0.017600, precision:  0.979310, f1:  0.982699
epoch:12, step:118, loss:  0.015239, precision:  0.992481, f1:  0.996226
epoch:12, step:119, loss:  0.044257, precision:  0.978417, f1:  0.974910
epoch:12, step:120, loss:  0.049275, precision:  0.952381, f1:  0.965517
epoch:12, step:121, loss:  0.040495, precision:  0.962733, f1:  0.974843
epoch:12, step:122, loss:  0.020227, precision:  0.975610, f1:  0.971660
epoch:12, step:123, loss:  0.031550, precision:  0.965753, f1:  0.975779
epoch:12, step:124, loss:  0.024847, precision:  0.969512, f1:  0.978462
epoch:12, step:125, loss:  0.024630, precision:  0.971223, f1:  0.978261
epoch:12, step:126, loss:  0.040715, precision:  0.961290, f1:  0.970684
epoch:12, step:127, loss:  0.032871, precision:  0.948387, f1:  0.970297
epoch:12, step:128, loss:  0.022657, precision:  0.985401, f1:  0.985401
epoch:12, step:129, loss:  0.036010, precision:  0.981132, f1:  0.975000
epoch:12, step:130, loss:  0.042327, precision:  0.948718, f1:  0.967320
epoch:12, step:131, loss:  0.044387, precision:  0.958621, f1:  0.968641
epoch:12, step:132, loss:  0.026459, precision:  0.984848, f1:  0.981132
epoch:12, step:133, loss:  0.018092, precision:  0.978102, f1:  0.981685
epoch:12, step:134, loss:  0.031746, precision:  0.993243, f1:  0.980000
epoch:12, step:135, loss:  0.044185, precision:  0.964286, f1:  0.957447
epoch:12, step:136, loss:  0.042422, precision:  0.963235, f1:  0.963235
epoch:12, step:137, loss:  0.024241, precision:  0.963768, f1:  0.977941
epoch:12, step:138, loss:  0.012806, precision:  0.977612, f1:  0.988679
epoch:12, step:139, loss:  0.029850, precision:  0.950000, f1:  0.963768
epoch:12, step:140, loss:  0.028890, precision:  0.956522, f1:  0.967033
epoch:12, step:141, loss:  0.028981, precision:  0.956790, f1:  0.977918
epoch:12, step:142, loss:  0.019831, precision:  0.968992, f1:  0.984252
epoch:12, step:143, loss:  0.041151, precision:  0.935714, f1:  0.959707
epoch:12, step:144, loss:  0.029718, precision:  0.961538, f1:  0.972763
epoch:12, step:145, loss:  0.026933, precision:  0.945205, f1:  0.975265
epoch:12, step:146, loss:  0.037870, precision:  0.985075, f1:  0.974170
epoch:12, step:147, loss:  0.037633, precision:  0.945205, f1:  0.968421
epoch:12, step:148, loss:  0.045478, precision:  0.971223, f1:  0.967742
epoch:12, step:149, loss:  0.020221, precision:  0.976744, f1:  0.976744
epoch:12, step:150, loss:  0.024895, precision:  0.986207, f1:  0.979452
epoch:12, step:151, loss:  0.087798, precision:  0.938462, f1:  0.945736
epoch:12, step:152, loss:  0.044509, precision:  0.964539, f1:  0.951049
epoch:12, step:153, loss:  0.014092, precision:  0.993151, f1:  0.993151
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:09,  2.06it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.12it/s]Validating:  14%|█▍        | 3/21 [00:01<00:08,  2.13it/s]Validating:  19%|█▉        | 4/21 [00:01<00:08,  2.11it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.38it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.32it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.29it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.21it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.20it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.25it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.23it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.37it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.24it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.27it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.40it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.29it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.39it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.32it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.22it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.22it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.23it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.27it/s]
epoch:12, step:154, loss:  0.026782, precision:  0.985401, f1:  0.981818
epoch:12, step:155, loss:  0.027087, precision:  0.962687, f1:  0.977273
epoch:12, step:156, loss:  0.026063, precision:  0.966667, f1:  0.983051
epoch:12, step:157, loss:  0.032216, precision:  0.962500, f1:  0.977778
epoch:12, step:158, loss:  0.049226, precision:  0.956250, f1:  0.965300
epoch:12, step:159, loss:  0.034588, precision:  0.965035, f1:  0.975265
epoch:12, step:160, loss:  0.043109, precision:  0.960526, f1:  0.976589
epoch:12, step:161, loss:  0.049978, precision:  0.924528, f1:  0.948387
epoch:12, step:162, loss:  0.038867, precision:  0.976048, f1:  0.978979
epoch:12, step:163, loss:  0.028133, precision:  0.980769, f1:  0.980769
epoch:12, step:164, loss:  0.045293, precision:  0.992647, f1:  0.978261
epoch:12, step:165, loss:  0.065721, precision:  0.936620, f1:  0.930070
epoch:12, step:166, loss:  0.027297, precision:  0.972789, f1:  0.979452
epoch:12, step:167, loss:  0.053571, precision:  0.944882, f1:  0.952381
epoch:12, valid_f1:  0.788318, valid_precision:  0.784194, valid_recall:  0.792886
epoch:13, step:0, loss:  0.015125, precision:  0.981595, f1:  0.993789
epoch:13, step:1, loss:  0.019469, precision:  0.985915, f1:  0.985915
epoch:13, step:2, loss:  0.017102, precision:  0.973684, f1:  0.986667
epoch:13, step:3, loss:  0.039545, precision:  0.962121, f1:  0.976923
epoch:13, step:4, loss:  0.020104, precision:  0.975460, f1:  0.990654
epoch:13, step:5, loss:  0.051810, precision:  0.970149, f1:  0.962963
epoch:13, step:6, loss:  0.015304, precision:  0.985075, f1:  0.988764
epoch:13, step:7, loss:  0.037723, precision:  0.961783, f1:  0.971061
epoch:13, step:8, loss:  0.009295, precision:  0.993333, f1:  1.000000
epoch:13, step:9, loss:  0.042465, precision:  0.962406, f1:  0.973384
epoch:13, step:10, loss:  0.035068, precision:  0.965035, f1:  0.965035
epoch:13, step:11, loss:  0.016158, precision:  0.976923, f1:  0.980695
epoch:13, step:12, loss:  0.030356, precision:  0.978102, f1:  0.971014
epoch:13, step:13, loss:  0.016226, precision:  0.992806, f1:  0.992806
epoch:13, step:14, loss:  0.014526, precision:  0.986207, f1:  0.989619
epoch:13, step:15, loss:  0.022924, precision:  0.979866, f1:  0.983165
epoch:13, step:16, loss:  0.038011, precision:  0.986667, f1:  0.976898
epoch:13, step:17, loss:  0.014907, precision:  0.980892, f1:  0.990354
epoch:13, step:18, loss:  0.029745, precision:  0.962406, f1:  0.973384
epoch:13, step:19, loss:  0.012530, precision:  0.985294, f1:  0.992593
epoch:13, step:20, loss:  0.062960, precision:  0.946667, f1:  0.953020
epoch:13, step:21, loss:  0.051046, precision:  0.963415, f1:  0.969325
epoch:13, step:22, loss:  0.037197, precision:  0.958904, f1:  0.972222
epoch:13, step:23, loss:  0.027112, precision:  0.980519, f1:  0.980519
epoch:13, step:24, loss:  0.019051, precision:  0.987261, f1:  0.990415
epoch:13, step:25, loss:  0.038720, precision:  0.980000, f1:  0.980000
epoch:13, step:26, loss:  0.028213, precision:  0.977273, f1:  0.966292
epoch:13, step:27, loss:  0.024520, precision:  0.977099, f1:  0.977099
epoch:13, step:28, loss:  0.013587, precision:  0.993590, f1:  0.993590
epoch:13, step:29, loss:  0.033386, precision:  0.971831, f1:  0.982206
epoch:13, step:30, loss:  0.025135, precision:  0.969925, f1:  0.973585
epoch:13, step:31, loss:  0.010959, precision:  0.978723, f1:  0.992806
epoch:13, step:32, loss:  0.028627, precision:  0.965986, f1:  0.972603
epoch:13, step:33, loss:  0.027833, precision:  0.966216, f1:  0.976109
epoch:13, step:34, loss:  0.014297, precision:  0.977099, f1:  0.988417
epoch:13, step:35, loss:  0.037936, precision:  0.962264, f1:  0.971429
epoch:13, step:36, loss:  0.026478, precision:  0.951724, f1:  0.968421
epoch:13, step:37, loss:  0.030200, precision:  0.987730, f1:  0.981707
epoch:13, step:38, loss:  0.028719, precision:  0.940741, f1:  0.965779
epoch:13, step:39, loss:  0.031875, precision:  0.941606, f1:  0.966292
epoch:13, step:40, loss:  0.013236, precision:  0.985401, f1:  0.992647
epoch:13, step:41, loss:  0.024437, precision:  0.955224, f1:  0.966038
epoch:13, step:42, loss:  0.020469, precision:  0.985401, f1:  0.981818
epoch:13, step:43, loss:  0.036565, precision:  0.981818, f1:  0.972973
epoch:13, step:44, loss:  0.033835, precision:  0.981481, f1:  0.978462
epoch:13, step:45, loss:  0.004579, precision:  0.993421, f1:  1.000000
epoch:13, step:46, loss:  0.018586, precision:  0.976562, f1:  0.980392
epoch:13, step:47, loss:  0.019289, precision:  0.976923, f1:  0.976923
epoch:13, step:48, loss:  0.046829, precision:  0.927152, f1:  0.955631
epoch:13, step:49, loss:  0.027750, precision:  0.946108, f1:  0.966361
epoch:13, step:50, loss:  0.038280, precision:  0.964539, f1:  0.974910
epoch:13, step:51, loss:  0.022561, precision:  0.984615, f1:  0.988417
epoch:13, step:52, loss:  0.019145, precision:  0.986667, f1:  0.986667
epoch:13, step:53, loss:  0.020910, precision:  0.975155, f1:  0.984326
epoch:13, step:54, loss:  0.021101, precision:  0.976744, f1:  0.984375
epoch:13, step:55, loss:  0.036683, precision:  0.963504, f1:  0.970588
epoch:13, step:56, loss:  0.024199, precision:  0.979021, f1:  0.979021
epoch:13, step:57, loss:  0.018705, precision:  0.980132, f1:  0.989967
epoch:13, step:58, loss:  0.014586, precision:  0.978723, f1:  0.989247
epoch:13, step:59, loss:  0.023731, precision:  0.978723, f1:  0.985714
epoch:13, step:60, loss:  0.030790, precision:  0.980263, f1:  0.970684
epoch:13, step:61, loss:  0.027386, precision:  0.984127, f1:  0.988048
epoch:13, step:62, loss:  0.010969, precision:  0.992857, f1:  0.992857
epoch:13, step:63, loss:  0.062074, precision:  0.961326, f1:  0.963989
epoch:13, step:64, loss:  0.023574, precision:  0.978723, f1:  0.992806
epoch:13, step:65, loss:  0.026253, precision:  0.963235, f1:  0.977612
epoch:13, step:66, loss:  0.034699, precision:  0.977444, f1:  0.977444
epoch:13, step:67, loss:  0.059470, precision:  0.952663, f1:  0.975758
epoch:13, step:68, loss:  0.012330, precision:  0.985915, f1:  0.996441
epoch:13, step:69, loss:  0.009873, precision:  0.976562, f1:  0.992063
epoch:13, step:70, loss:  0.019635, precision:  0.972028, f1:  0.985816
epoch:13, step:71, loss:  0.034245, precision:  0.965812, f1:  0.965812
epoch:13, step:72, loss:  0.020900, precision:  0.971014, f1:  0.978102
epoch:13, step:73, loss:  0.026600, precision:  0.978723, f1:  0.975265
epoch:13, step:74, loss:  0.021355, precision:  0.970149, f1:  0.977444
epoch:13, step:75, loss:  0.019161, precision:  0.985401, f1:  0.989011
epoch:13, step:76, loss:  0.040170, precision:  0.962025, f1:  0.974359
epoch:13, step:77, loss:  0.019998, precision:  0.977941, f1:  0.985185
epoch:13, step:78, loss:  0.047633, precision:  0.954545, f1:  0.960784
epoch:13, step:79, loss:  0.022256, precision:  0.957447, f1:  0.974729
epoch:13, step:80, loss:  0.079427, precision:  0.946309, f1:  0.943144
epoch:13, step:81, loss:  0.017219, precision:  0.982249, f1:  0.991045
epoch:13, step:82, loss:  0.040414, precision:  0.969466, f1:  0.973180
epoch:13, step:83, loss:  0.017175, precision:  0.985401, f1:  0.989011
epoch:13, step:84, loss:  0.022406, precision:  0.957747, f1:  0.974910
epoch:13, step:85, loss:  0.025817, precision:  0.978723, f1:  0.982206
epoch:13, step:86, loss:  0.030906, precision:  0.956835, f1:  0.967273
epoch:13, step:87, loss:  0.041917, precision:  0.956522, f1:  0.962500
epoch:13, step:88, loss:  0.049427, precision:  0.945122, f1:  0.956790
epoch:13, step:89, loss:  0.024467, precision:  0.987013, f1:  0.977492
epoch:13, step:90, loss:  0.062860, precision:  0.956522, f1:  0.953069
epoch:13, step:91, loss:  0.056490, precision:  0.971831, f1:  0.971831
epoch:13, step:92, loss:  0.026492, precision:  0.951724, f1:  0.968421
epoch:13, step:93, loss:  0.031589, precision:  0.971429, f1:  0.981949
epoch:13, step:94, loss:  0.060354, precision:  0.931298, f1:  0.949416
epoch:13, step:95, loss:  0.016348, precision:  0.992000, f1:  0.995984
epoch:13, step:96, loss:  0.035643, precision:  0.957143, f1:  0.960573
epoch:13, step:97, loss:  0.028579, precision:  0.978417, f1:  0.981949
epoch:13, step:98, loss:  0.028389, precision:  0.972028, f1:  0.972028
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:08,  2.42it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.37it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.43it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.33it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.34it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.43it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.39it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.39it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.32it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.28it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.34it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.29it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.40it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:03,  2.30it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.23it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:02,  2.22it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.16it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.17it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.14it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.21it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.22it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.28it/s]
epoch:13, step:99, loss:  0.018586, precision:  0.979167, f1:  0.986014
epoch:13, step:100, loss:  0.032796, precision:  0.959732, f1:  0.976109
epoch:13, step:101, loss:  0.034533, precision:  0.947368, f1:  0.965517
epoch:13, step:102, loss:  0.015916, precision:  0.993421, f1:  0.990164
epoch:13, step:103, loss:  0.049034, precision:  0.939394, f1:  0.946565
epoch:13, step:104, loss:  0.038805, precision:  0.958824, f1:  0.967359
epoch:13, step:105, loss:  0.031391, precision:  0.953333, f1:  0.969492
epoch:13, step:106, loss:  0.023828, precision:  0.978417, f1:  0.978417
epoch:13, step:107, loss:  0.029871, precision:  0.977612, f1:  0.981273
epoch:13, step:108, loss:  0.027037, precision:  0.979167, f1:  0.982578
epoch:13, step:109, loss:  0.035090, precision:  0.971429, f1:  0.971429
epoch:13, step:110, loss:  0.034172, precision:  0.964789, f1:  0.971631
epoch:13, step:111, loss:  0.022610, precision:  0.973333, f1:  0.986486
epoch:13, step:112, loss:  0.028730, precision:  0.977778, f1:  0.977778
epoch:13, step:113, loss:  0.032269, precision:  0.978873, f1:  0.982332
epoch:13, step:114, loss:  0.035979, precision:  0.958042, f1:  0.971631
epoch:13, step:115, loss:  0.031835, precision:  0.971223, f1:  0.967742
epoch:13, step:116, loss:  0.051474, precision:  0.948718, f1:  0.964169
epoch:13, step:117, loss:  0.026338, precision:  0.977778, f1:  0.981413
epoch:13, step:118, loss:  0.017162, precision:  0.978102, f1:  0.981685
epoch:13, step:119, loss:  0.039405, precision:  0.982353, f1:  0.982353
epoch:13, step:120, loss:  0.018611, precision:  0.971014, f1:  0.985294
epoch:13, step:121, loss:  0.049671, precision:  0.919708, f1:  0.940298
epoch:13, step:122, loss:  0.017472, precision:  0.983871, f1:  0.995918
epoch:13, step:123, loss:  0.025528, precision:  0.979167, f1:  0.986014
epoch:13, step:124, loss:  0.017735, precision:  0.987097, f1:  0.996743
epoch:13, step:125, loss:  0.035444, precision:  0.938931, f1:  0.949807
epoch:13, step:126, loss:  0.031288, precision:  0.961832, f1:  0.965517
epoch:13, step:127, loss:  0.041482, precision:  0.978873, f1:  0.961938
epoch:13, step:128, loss:  0.025005, precision:  0.979310, f1:  0.986111
epoch:13, step:129, loss:  0.037582, precision:  0.971014, f1:  0.971014
epoch:13, step:130, loss:  0.013816, precision:  0.985714, f1:  0.992806
epoch:13, step:131, loss:  0.032936, precision:  0.984252, f1:  0.972763
epoch:13, step:132, loss:  0.045704, precision:  0.955556, f1:  0.962687
epoch:13, step:133, loss:  0.028544, precision:  0.965986, f1:  0.982699
epoch:13, step:134, loss:  0.011980, precision:  0.986755, f1:  0.996656
epoch:13, step:135, loss:  0.042044, precision:  0.970803, f1:  0.981550
epoch:13, step:136, loss:  0.050160, precision:  0.938356, f1:  0.958042
epoch:13, step:137, loss:  0.036193, precision:  0.959459, f1:  0.965986
epoch:13, step:138, loss:  0.017997, precision:  0.974522, f1:  0.987097
epoch:13, step:139, loss:  0.041044, precision:  0.968750, f1:  0.972549
epoch:13, step:140, loss:  0.063638, precision:  0.929032, f1:  0.947368
epoch:13, step:141, loss:  0.041535, precision:  0.964789, f1:  0.961403
epoch:13, step:142, loss:  0.026374, precision:  0.979592, f1:  0.979592
epoch:13, step:143, loss:  0.029749, precision:  0.979730, f1:  0.979730
epoch:13, step:144, loss:  0.051232, precision:  0.966887, f1:  0.960526
epoch:13, step:145, loss:  0.018156, precision:  0.978873, f1:  0.985816
epoch:13, step:146, loss:  0.020297, precision:  0.984848, f1:  0.984848
epoch:13, step:147, loss:  0.017519, precision:  0.967320, f1:  0.980132
epoch:13, step:148, loss:  0.029897, precision:  0.954887, f1:  0.962121
epoch:13, step:149, loss:  0.034387, precision:  0.972973, f1:  0.972973
epoch:13, step:150, loss:  0.038306, precision:  0.955696, f1:  0.974194
epoch:13, step:151, loss:  0.042074, precision:  0.930233, f1:  0.952381
epoch:13, step:152, loss:  0.039237, precision:  0.945946, f1:  0.968858
epoch:13, step:153, loss:  0.024755, precision:  0.959350, f1:  0.967213
epoch:13, step:154, loss:  0.039223, precision:  0.973684, f1:  0.980132
epoch:13, step:155, loss:  0.018925, precision:  0.986755, f1:  0.993333
epoch:13, step:156, loss:  0.035440, precision:  0.992754, f1:  0.978571
epoch:13, step:157, loss:  0.049391, precision:  0.952381, f1:  0.952381
epoch:13, step:158, loss:  0.028507, precision:  0.963504, f1:  0.970588
epoch:13, step:159, loss:  0.018043, precision:  0.962121, f1:  0.980695
epoch:13, step:160, loss:  0.026453, precision:  0.971631, f1:  0.971631
epoch:13, step:161, loss:  0.036338, precision:  0.953125, f1:  0.968254
epoch:13, step:162, loss:  0.022510, precision:  0.986842, f1:  0.983607
epoch:13, step:163, loss:  0.046757, precision:  0.943262, f1:  0.950000
epoch:13, step:164, loss:  0.040777, precision:  0.953020, f1:  0.965986
epoch:13, step:165, loss:  0.030346, precision:  0.964029, f1:  0.974545
epoch:13, step:166, loss:  0.020526, precision:  0.985507, f1:  0.981949
epoch:13, step:167, loss:  0.057229, precision:  0.969231, f1:  0.961832
epoch:13, valid_f1:  0.790160, valid_precision:  0.790119, valid_recall:  0.790527
epoch:14, step:0, loss:  0.021063, precision:  0.979021, f1:  0.982456
epoch:14, step:1, loss:  0.012485, precision:  0.988024, f1:  0.993976
epoch:14, step:2, loss:  0.015568, precision:  0.979592, f1:  0.993103
epoch:14, step:3, loss:  0.029511, precision:  0.971223, f1:  0.974729
epoch:14, step:4, loss:  0.024412, precision:  0.993506, f1:  0.990291
epoch:14, step:5, loss:  0.040447, precision:  0.966443, f1:  0.960000
epoch:14, step:6, loss:  0.015300, precision:  0.980769, f1:  0.990291
epoch:14, step:7, loss:  0.015887, precision:  0.968750, f1:  0.988048
epoch:14, step:8, loss:  0.035552, precision:  0.957447, f1:  0.967742
epoch:14, step:9, loss:  0.020895, precision:  0.971631, f1:  0.985611
epoch:14, step:10, loss:  0.007670, precision:  0.992366, f1:  0.996169
epoch:14, step:11, loss:  0.035137, precision:  0.966216, f1:  0.972789
epoch:14, step:12, loss:  0.039175, precision:  0.971831, f1:  0.968421
epoch:14, step:13, loss:  0.018199, precision:  0.978417, f1:  0.989091
epoch:14, step:14, loss:  0.022623, precision:  0.986667, f1:  0.983389
epoch:14, step:15, loss:  0.010402, precision:  0.992806, f1:  0.996390
epoch:14, step:16, loss:  0.024962, precision:  0.978417, f1:  0.978417
epoch:14, step:17, loss:  0.007166, precision:  0.992701, f1:  1.000000
epoch:14, step:18, loss:  0.028827, precision:  0.979452, f1:  0.979452
epoch:14, step:19, loss:  0.017287, precision:  0.969925, f1:  0.984733
epoch:14, step:20, loss:  0.016977, precision:  0.980392, f1:  0.993378
epoch:14, step:21, loss:  0.009037, precision:  0.993243, f1:  1.000000
epoch:14, step:22, loss:  0.034111, precision:  0.986577, f1:  0.973510
epoch:14, step:23, loss:  0.013954, precision:  0.985507, f1:  0.992701
epoch:14, step:24, loss:  0.018509, precision:  0.971831, f1:  0.982206
epoch:14, step:25, loss:  0.017691, precision:  0.978873, f1:  0.982332
epoch:14, step:26, loss:  0.016782, precision:  0.955556, f1:  0.980989
epoch:14, step:27, loss:  0.027841, precision:  0.972222, f1:  0.979021
epoch:14, step:28, loss:  0.015055, precision:  0.980519, f1:  0.986928
epoch:14, step:29, loss:  0.016421, precision:  0.972222, f1:  0.979021
epoch:14, step:30, loss:  0.021782, precision:  0.978417, f1:  0.985507
epoch:14, step:31, loss:  0.020800, precision:  0.974359, f1:  0.987013
epoch:14, step:32, loss:  0.023921, precision:  0.968992, f1:  0.976562
epoch:14, step:33, loss:  0.033090, precision:  0.969466, f1:  0.973180
epoch:14, step:34, loss:  0.017583, precision:  0.985816, f1:  0.989324
epoch:14, step:35, loss:  0.023798, precision:  0.978723, f1:  0.978723
epoch:14, step:36, loss:  0.013341, precision:  0.984962, f1:  0.988679
epoch:14, step:37, loss:  0.017886, precision:  0.985507, f1:  0.989091
epoch:14, step:38, loss:  0.030216, precision:  0.961290, f1:  0.973856
epoch:14, step:39, loss:  0.034282, precision:  0.964602, f1:  0.981982
epoch:14, step:40, loss:  0.018114, precision:  0.974026, f1:  0.983607
epoch:14, step:41, loss:  0.032642, precision:  0.967320, f1:  0.973684
epoch:14, step:42, loss:  0.018923, precision:  0.987013, f1:  0.990228
epoch:14, step:43, loss:  0.021640, precision:  0.978571, f1:  0.982079
epoch:14, step:44, loss:  0.018547, precision:  0.985075, f1:  0.981413
epoch:14, step:45, loss:  0.035050, precision:  0.978417, f1:  0.978417
epoch:14, step:46, loss:  0.027158, precision:  0.976923, f1:  0.984496
epoch:14, step:47, loss:  0.055536, precision:  0.960317, f1:  0.964143
epoch:14, step:48, loss:  0.014016, precision:  0.978102, f1:  0.985294
epoch:14, step:49, loss:  0.060448, precision:  0.967742, f1:  0.963855
epoch:14, step:50, loss:  0.018477, precision:  0.965517, f1:  0.985915
epoch:14, step:51, loss:  0.024848, precision:  0.981132, f1:  0.981132
epoch:14, step:52, loss:  0.011587, precision:  0.979021, f1:  0.992908
epoch:14, step:53, loss:  0.005189, precision:  0.992126, f1:  0.996047
epoch:14, step:54, loss:  0.035457, precision:  0.967320, f1:  0.964169
epoch:14, step:55, loss:  0.029590, precision:  0.970760, f1:  0.976471
epoch:14, step:56, loss:  0.012346, precision:  0.986301, f1:  0.993103
epoch:14, step:57, loss:  0.007600, precision:  0.992958, f1:  1.000000
epoch:14, step:58, loss:  0.037679, precision:  0.962025, f1:  0.968153
epoch:14, step:59, loss:  0.016059, precision:  0.986667, f1:  0.989967
epoch:14, step:60, loss:  0.024193, precision:  0.965986, f1:  0.972603
epoch:14, step:61, loss:  0.030631, precision:  0.980263, f1:  0.980263
epoch:14, step:62, loss:  0.013185, precision:  0.984848, f1:  0.988593
epoch:14, step:63, loss:  0.014438, precision:  0.986014, f1:  0.989474
epoch:14, step:64, loss:  0.044708, precision:  0.942675, f1:  0.954839
epoch:14, step:65, loss:  0.007644, precision:  0.985401, f1:  0.996310
epoch:14, step:66, loss:  0.025811, precision:  0.957143, f1:  0.978102
epoch:14, step:67, loss:  0.015330, precision:  0.987261, f1:  0.993590
epoch:14, step:68, loss:  0.041265, precision:  0.935714, f1:  0.945848
epoch:14, step:69, loss:  0.027713, precision:  0.992806, f1:  0.985714
epoch:14, step:70, loss:  0.020489, precision:  0.986301, f1:  0.989691
epoch:14, step:71, loss:  0.023065, precision:  0.985816, f1:  0.982332
epoch:14, step:72, loss:  0.038455, precision:  0.946154, f1:  0.946154
epoch:14, step:73, loss:  0.026415, precision:  0.960938, f1:  0.972332
epoch:14, step:74, loss:  0.023091, precision:  0.978571, f1:  0.985611
epoch:14, step:75, loss:  0.028922, precision:  0.976744, f1:  0.980545
epoch:14, step:76, loss:  0.029463, precision:  0.969925, f1:  0.966292
epoch:14, step:77, loss:  0.039822, precision:  0.971831, f1:  0.975265
epoch:14, step:78, loss:  0.022141, precision:  0.978102, f1:  0.985294
epoch:14, step:79, loss:  0.019280, precision:  0.974359, f1:  0.987013
epoch:14, step:80, loss:  0.023406, precision:  0.979167, f1:  0.989474
epoch:14, step:81, loss:  0.012584, precision:  0.972222, f1:  0.989399
epoch:14, step:82, loss:  0.025410, precision:  0.977778, f1:  0.981413
epoch:14, step:83, loss:  0.014555, precision:  0.986395, f1:  0.993151
epoch:14, step:84, loss:  0.026791, precision:  0.970149, f1:  0.981132
epoch:14, step:85, loss:  0.011284, precision:  0.993590, f1:  0.996785
epoch:14, step:86, loss:  0.017460, precision:  0.979310, f1:  0.982699
epoch:14, step:87, loss:  0.017443, precision:  0.985915, f1:  0.985915
epoch:14, step:88, loss:  0.030601, precision:  0.965035, f1:  0.978723
epoch:14, step:89, loss:  0.018205, precision:  0.985915, f1:  0.989399
epoch:14, step:90, loss:  0.028085, precision:  0.985611, f1:  0.982079
epoch:14, step:91, loss:  0.014079, precision:  0.993827, f1:  0.996904
epoch:14, step:92, loss:  0.023042, precision:  0.993151, f1:  0.993151
epoch:14, step:93, loss:  0.034036, precision:  0.955414, f1:  0.970874
epoch:14, step:94, loss:  0.031668, precision:  0.974026, f1:  0.980392
epoch:14, step:95, loss:  0.008726, precision:  0.984496, f1:  0.992188
epoch:14, step:96, loss:  0.016436, precision:  0.979866, f1:  0.989830
epoch:14, step:97, loss:  0.029001, precision:  0.971631, f1:  0.982079
epoch:14, step:98, loss:  0.012822, precision:  0.993827, f1:  0.993827
epoch:14, step:99, loss:  0.029257, precision:  0.964789, f1:  0.982079
epoch:14, step:100, loss:  0.013238, precision:  0.985401, f1:  0.985401
epoch:14, step:101, loss:  0.014111, precision:  0.986014, f1:  0.992958
epoch:14, step:102, loss:  0.014088, precision:  0.973684, f1:  0.989967
epoch:14, step:103, loss:  0.016564, precision:  0.968750, f1:  0.980237
epoch:14, step:104, loss:  0.040516, precision:  0.953020, f1:  0.969283
epoch:14, step:105, loss:  0.032533, precision:  0.966216, f1:  0.969492
epoch:14, step:106, loss:  0.020181, precision:  0.971223, f1:  0.985401
epoch:14, step:107, loss:  0.028419, precision:  0.954887, f1:  0.969466
epoch:14, step:108, loss:  0.038472, precision:  0.977273, f1:  0.977273
epoch:14, step:109, loss:  0.017275, precision:  0.986842, f1:  0.993378
epoch:14, step:110, loss:  0.016671, precision:  0.971631, f1:  0.985611
epoch:14, step:111, loss:  0.016231, precision:  0.977612, f1:  0.988679
epoch:14, step:112, loss:  0.025375, precision:  0.978417, f1:  0.981949
epoch:14, step:113, loss:  0.025771, precision:  0.973684, f1:  0.980132
epoch:14, step:114, loss:  0.026028, precision:  0.968153, f1:  0.974359
epoch:14, step:115, loss:  0.011440, precision:  0.986755, f1:  0.993333
epoch:14, step:116, loss:  0.029089, precision:  0.992958, f1:  0.982578
epoch:14, step:117, loss:  0.026828, precision:  0.965986, f1:  0.975945
epoch:14, step:118, loss:  0.014463, precision:  0.979310, f1:  0.989547
epoch:14, step:119, loss:  0.015943, precision:  0.965278, f1:  0.985816
epoch:14, step:120, loss:  0.016995, precision:  0.970370, f1:  0.988679
epoch:14, step:121, loss:  0.016204, precision:  0.986395, f1:  0.986395
epoch:14, step:122, loss:  0.037417, precision:  0.931973, f1:  0.948097
epoch:14, step:123, loss:  0.040857, precision:  0.960784, f1:  0.970297
epoch:14, step:124, loss:  0.032573, precision:  0.956835, f1:  0.967273
epoch:14, step:125, loss:  0.035570, precision:  0.954887, f1:  0.965779
epoch:14, step:126, loss:  0.017744, precision:  0.977444, f1:  0.988593
epoch:14, step:127, loss:  0.027493, precision:  0.985507, f1:  0.981949
epoch:14, step:128, loss:  0.018849, precision:  0.987654, f1:  0.987654
epoch:14, step:129, loss:  0.039373, precision:  0.965035, f1:  0.968421
epoch:14, step:130, loss:  0.009100, precision:  0.991597, f1:  0.991597
epoch:14, step:131, loss:  0.035391, precision:  0.980645, f1:  0.977492
epoch:14, step:132, loss:  0.044904, precision:  0.977099, f1:  0.973384
epoch:14, step:133, loss:  0.015225, precision:  0.970588, f1:  0.985075
epoch:14, step:134, loss:  0.032322, precision:  0.973684, f1:  0.976898
epoch:14, step:135, loss:  0.030250, precision:  0.964029, f1:  0.971014
epoch:14, step:136, loss:  0.034661, precision:  0.937008, f1:  0.948207
epoch:14, step:137, loss:  0.026072, precision:  0.981481, f1:  0.984520
epoch:14, step:138, loss:  0.017660, precision:  0.965217, f1:  0.977974
epoch:14, step:139, loss:  0.046799, precision:  0.947020, f1:  0.959732
epoch:14, step:140, loss:  0.019110, precision:  0.984615, f1:  0.992248
epoch:14, step:141, loss:  0.023805, precision:  0.976562, f1:  0.976562
epoch:14, step:142, loss:  0.035860, precision:  0.962963, f1:  0.977444
epoch:14, step:143, loss:  0.016544, precision:  0.971631, f1:  0.985611
epoch:14, step:144, loss:  0.039845, precision:  0.958333, f1:  0.965035
epoch:14, step:145, loss:  0.024286, precision:  0.987500, f1:  0.981366
epoch:14, step:146, loss:  0.025396, precision:  0.985075, f1:  0.981413
epoch:14, step:147, loss:  0.013935, precision:  0.984962, f1:  0.984962
epoch:14, step:148, loss:  0.027394, precision:  0.979310, f1:  0.975945
epoch:14, step:149, loss:  0.015136, precision:  0.979730, f1:  0.986395
epoch:14, step:150, loss:  0.023004, precision:  0.973856, f1:  0.980263
epoch:14, step:151, loss:  0.034764, precision:  0.961290, f1:  0.977049
epoch:14, step:152, loss:  0.027732, precision:  0.963235, f1:  0.977612
epoch:14, step:153, loss:  0.026060, precision:  0.986207, f1:  0.982818
epoch:14, step:154, loss:  0.022543, precision:  0.972028, f1:  0.985816
epoch:14, step:155, loss:  0.023572, precision:  0.973510, f1:  0.980000

Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:08,  2.36it/s]Validating:  10%|▉         | 2/21 [00:00<00:08,  2.28it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.27it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.32it/s]Validating:  24%|██▍       | 5/21 [00:02<00:07,  2.23it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.44it/s]Validating:  33%|███▎      | 7/21 [00:03<00:06,  2.25it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.26it/s]Validating:  43%|████▎     | 9/21 [00:04<00:05,  2.14it/s]Validating:  48%|████▊     | 10/21 [00:04<00:05,  2.18it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.15it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:04,  2.14it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.13it/s]Validating:  67%|██████▋   | 14/21 [00:06<00:03,  2.14it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.25it/s]Validating:  76%|███████▌  | 16/21 [00:07<00:02,  2.23it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.28it/s]Validating:  86%|████████▌ | 18/21 [00:08<00:01,  2.21it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.23it/s]Validating:  95%|█████████▌| 20/21 [00:09<00:00,  2.21it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.23it/s]Validating: 100%|██████████| 21/21 [00:09<00:00,  2.22it/s]epoch:14, step:156, loss:  0.022762, precision:  0.980392, f1:  0.986842
epoch:14, step:157, loss:  0.026401, precision:  0.971831, f1:  0.982206
epoch:14, step:158, loss:  0.011078, precision:  0.982143, f1:  0.990991
epoch:14, step:159, loss:  0.032828, precision:  0.961783, f1:  0.964856
epoch:14, step:160, loss:  0.014967, precision:  0.992701, f1:  0.992701
epoch:14, step:161, loss:  0.014310, precision:  0.992857, f1:  0.992857
epoch:14, step:162, loss:  0.039315, precision:  0.979021, f1:  0.975610
epoch:14, step:163, loss:  0.018885, precision:  0.986395, f1:  0.989761
epoch:14, step:164, loss:  0.018001, precision:  0.986577, f1:  0.993243
epoch:14, step:165, loss:  0.019951, precision:  0.980000, f1:  0.986577
epoch:14, step:166, loss:  0.014684, precision:  0.986395, f1:  0.996564
epoch:14, step:167, loss:  0.017823, precision:  0.985401, f1:  0.985401
epoch:14, valid_f1:  0.791396, valid_precision:  0.782878, valid_recall:  0.800504
epoch:15, step:0, loss:  0.008575, precision:  0.985507, f1:  0.989091
epoch:15, step:1, loss:  0.015514, precision:  0.979167, f1:  0.989474
epoch:15, step:2, loss:  0.011503, precision:  0.984496, f1:  0.992188
epoch:15, step:3, loss:  0.015870, precision:  0.973510, f1:  0.986577
epoch:15, step:4, loss:  0.022302, precision:  0.957747, f1:  0.971429
epoch:15, step:5, loss:  0.021760, precision:  0.971429, f1:  0.971429
epoch:15, step:6, loss:  0.027520, precision:  0.964029, f1:  0.978102
epoch:15, step:7, loss:  0.010073, precision:  0.974790, f1:  0.991453
epoch:15, step:8, loss:  0.018796, precision:  0.971223, f1:  0.981818
epoch:15, step:9, loss:  0.013892, precision:  0.973510, f1:  0.986577
epoch:15, step:10, loss:  0.015630, precision:  0.978723, f1:  0.985714
epoch:15, step:11, loss:  0.006617, precision:  0.992537, f1:  1.000000
epoch:15, step:12, loss:  0.018688, precision:  0.986577, f1:  0.989899
epoch:15, step:13, loss:  0.023060, precision:  0.967949, f1:  0.983713
epoch:15, step:14, loss:  0.011970, precision:  0.983333, f1:  0.983333
epoch:15, step:15, loss:  0.014980, precision:  0.972789, f1:  0.989619
epoch:15, step:16, loss:  0.030415, precision:  0.977941, f1:  0.981550
epoch:15, step:17, loss:  0.027705, precision:  0.968354, f1:  0.977636
epoch:15, step:18, loss:  0.028424, precision:  0.981013, f1:  0.977918
epoch:15, step:19, loss:  0.020361, precision:  0.980645, f1:  0.983819
epoch:15, step:20, loss:  0.024440, precision:  0.979866, f1:  0.983165
epoch:15, step:21, loss:  0.026061, precision:  0.968944, f1:  0.971963
epoch:15, step:22, loss:  0.022580, precision:  0.973154, f1:  0.986395
epoch:15, step:23, loss:  0.012856, precision:  0.985816, f1:  0.989324
epoch:15, step:24, loss:  0.019304, precision:  0.972603, f1:  0.979310
epoch:15, step:25, loss:  0.011468, precision:  0.980519, f1:  0.993421
epoch:15, step:26, loss:  0.014872, precision:  0.986014, f1:  0.986014
epoch:15, step:27, loss:  0.019077, precision:  0.986755, f1:  0.983498
epoch:15, step:28, loss:  0.029957, precision:  0.972414, f1:  0.969072
epoch:15, step:29, loss:  0.024090, precision:  0.971631, f1:  0.982079
epoch:15, step:30, loss:  0.016970, precision:  0.967480, f1:  0.979424
epoch:15, step:31, loss:  0.030475, precision:  0.973510, f1:  0.973510
epoch:15, step:32, loss:  0.011182, precision:  0.985915, f1:  0.992908
epoch:15, step:33, loss:  0.016429, precision:  0.972603, f1:  0.986111
epoch:15, step:34, loss:  0.009053, precision:  0.993421, f1:  0.996700
epoch:15, step:35, loss:  0.015109, precision:  0.993289, f1:  0.993289
epoch:15, step:36, loss:  0.017365, precision:  0.951389, f1:  0.971631
epoch:15, step:37, loss:  0.011901, precision:  0.992126, f1:  0.992126
epoch:15, step:38, loss:  0.025275, precision:  0.972222, f1:  0.982456
epoch:15, step:39, loss:  0.008490, precision:  0.992593, f1:  0.992593
epoch:15, step:40, loss:  0.039358, precision:  0.977273, f1:  0.969925
epoch:15, step:41, loss:  0.027792, precision:  0.973333, f1:  0.983165
epoch:15, step:42, loss:  0.027070, precision:  0.968553, f1:  0.974684
epoch:15, step:43, loss:  0.022124, precision:  0.967742, f1:  0.977199
epoch:15, step:44, loss:  0.022823, precision:  0.986111, f1:  0.989547
epoch:15, step:45, loss:  0.017190, precision:  0.972028, f1:  0.982332
epoch:15, step:46, loss:  0.019076, precision:  0.985714, f1:  0.989247
epoch:15, step:47, loss:  0.013906, precision:  0.968750, f1:  0.987261
epoch:15, step:48, loss:  0.018133, precision:  0.986842, f1:  0.990099
epoch:15, step:49, loss:  0.009935, precision:  0.984127, f1:  0.992000
epoch:15, step:50, loss:  0.020652, precision:  0.970238, f1:  0.984894
epoch:15, step:51, loss:  0.013567, precision:  0.993671, f1:  0.987421
epoch:15, step:52, loss:  0.013188, precision:  0.991870, f1:  0.991870
epoch:15, step:53, loss:  0.026519, precision:  0.978261, f1:  0.981818
epoch:15, step:54, loss:  0.027764, precision:  0.979452, f1:  0.986207
epoch:15, step:55, loss:  0.035610, precision:  0.965035, f1:  0.971831
epoch:15, step:56, loss:  0.019340, precision:  0.975806, f1:  0.987755
epoch:15, step:57, loss:  0.013985, precision:  0.977444, f1:  0.988593
epoch:15, step:58, loss:  0.014136, precision:  0.986577, f1:  0.989899
epoch:15, step:59, loss:  0.032130, precision:  0.967105, f1:  0.970297
epoch:15, step:60, loss:  0.036846, precision:  0.959184, f1:  0.975779
epoch:15, step:61, loss:  0.014041, precision:  0.979167, f1:  0.992958
epoch:15, step:62, loss:  0.032153, precision:  0.953020, f1:  0.965986
epoch:15, step:63, loss:  0.014563, precision:  0.979452, f1:  0.986207
epoch:15, step:64, loss:  0.005835, precision:  0.992908, f1:  1.000000
epoch:15, step:65, loss:  0.023708, precision:  0.986014, f1:  0.982578
epoch:15, step:66, loss:  0.008394, precision:  0.985507, f1:  0.996337
epoch:15, step:67, loss:  0.005953, precision:  0.993333, f1:  1.000000
epoch:15, step:68, loss:  0.038123, precision:  0.964029, f1:  0.971014
epoch:15, step:69, loss:  0.017922, precision:  0.985915, f1:  0.992908
epoch:15, step:70, loss:  0.016297, precision:  0.986395, f1:  0.989761
epoch:15, step:71, loss:  0.022822, precision:  0.984733, f1:  0.992308
epoch:15, step:72, loss:  0.052488, precision:  0.916667, f1:  0.945312
epoch:15, step:73, loss:  0.034566, precision:  0.955224, f1:  0.962406
epoch:15, step:74, loss:  0.016650, precision:  0.985507, f1:  0.992701
epoch:15, step:75, loss:  0.038694, precision:  0.977444, f1:  0.977444
epoch:15, step:76, loss:  0.012066, precision:  0.992126, f1:  0.992126
epoch:15, step:77, loss:  0.031207, precision:  0.972789, f1:  0.976109
epoch:15, step:78, loss:  0.008772, precision:  0.992857, f1:  0.992857
epoch:15, step:79, loss:  0.038468, precision:  0.953333, f1:  0.976109
epoch:15, step:80, loss:  0.026189, precision:  0.965517, f1:  0.975610
epoch:15, step:81, loss:  0.033474, precision:  0.972414, f1:  0.972414
epoch:15, step:82, loss:  0.015229, precision:  0.978261, f1:  0.989011
epoch:15, step:83, loss:  0.039746, precision:  0.956522, f1:  0.956522
epoch:15, step:84, loss:  0.018316, precision:  0.986755, f1:  0.990033
epoch:15, step:85, loss:  0.017138, precision:  0.969231, f1:  0.984375
epoch:15, step:86, loss:  0.035637, precision:  0.977612, f1:  0.977612
epoch:15, step:87, loss:  0.008283, precision:  0.985075, f1:  0.996226
epoch:15, step:88, loss:  0.043561, precision:  0.968553, f1:  0.965517
epoch:15, step:89, loss:  0.008305, precision:  0.992958, f1:  1.000000
epoch:15, step:90, loss:  0.019346, precision:  0.992701, f1:  0.992701
epoch:15, step:91, loss:  0.019665, precision:  0.961240, f1:  0.980237
epoch:15, step:92, loss:  0.028057, precision:  0.968254, f1:  0.972112
epoch:15, step:93, loss:  0.022470, precision:  0.969231, f1:  0.976744
epoch:15, step:94, loss:  0.013228, precision:  0.985816, f1:  0.992857
epoch:15, step:95, loss:  0.023649, precision:  0.967105, f1:  0.976744
epoch:15, step:96, loss:  0.029831, precision:  0.976190, f1:  0.972332
epoch:15, step:97, loss:  0.027046, precision:  0.966443, f1:  0.982935
epoch:15, step:98, loss:  0.043994, precision:  0.953642, f1:  0.969697
epoch:15, step:99, loss:  0.023795, precision:  0.979310, f1:  0.986111
epoch:15, step:100, loss:  0.017131, precision:  0.987342, f1:  0.987342
Validating:   0%|          | 0/21 [00:00<?, ?it/s]Validating:   5%|▍         | 1/21 [00:00<00:07,  2.77it/s]Validating:  10%|▉         | 2/21 [00:00<00:07,  2.59it/s]Validating:  14%|█▍        | 3/21 [00:01<00:07,  2.43it/s]Validating:  19%|█▉        | 4/21 [00:01<00:07,  2.33it/s]Validating:  24%|██▍       | 5/21 [00:02<00:06,  2.34it/s]Validating:  29%|██▊       | 6/21 [00:02<00:06,  2.40it/s]Validating:  33%|███▎      | 7/21 [00:02<00:05,  2.38it/s]Validating:  38%|███▊      | 8/21 [00:03<00:05,  2.38it/s]Validating:  43%|████▎     | 9/21 [00:03<00:05,  2.33it/s]Validating:  48%|████▊     | 10/21 [00:04<00:04,  2.27it/s]Validating:  52%|█████▏    | 11/21 [00:04<00:04,  2.33it/s]Validating:  57%|█████▋    | 12/21 [00:05<00:03,  2.31it/s]Validating:  62%|██████▏   | 13/21 [00:05<00:03,  2.42it/s]Validating:  67%|██████▋   | 14/21 [00:05<00:02,  2.39it/s]Validating:  71%|███████▏  | 15/21 [00:06<00:02,  2.41it/s]Validating:  76%|███████▌  | 16/21 [00:06<00:01,  2.56it/s]Validating:  81%|████████  | 17/21 [00:07<00:01,  2.44it/s]Validating:  86%|████████▌ | 18/21 [00:07<00:01,  2.42it/s]Validating:  90%|█████████ | 19/21 [00:08<00:00,  2.30it/s]Validating:  95%|█████████▌| 20/21 [00:08<00:00,  2.32it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.47it/s]Validating: 100%|██████████| 21/21 [00:08<00:00,  2.38it/s]
epoch:15, step:101, loss:  0.016537, precision:  0.986395, f1:  0.983051
epoch:15, step:102, loss:  0.011570, precision:  0.987013, f1:  0.993464
epoch:15, step:103, loss:  0.031982, precision:  0.986207, f1:  0.972789
epoch:15, step:104, loss:  0.011080, precision:  0.992366, f1:  0.988593
epoch:15, step:105, loss:  0.026677, precision:  0.969466, f1:  0.973180
epoch:15, step:106, loss:  0.037167, precision:  0.979866, f1:  0.976589
epoch:15, step:107, loss:  0.019090, precision:  0.970588, f1:  0.977778
epoch:15, step:108, loss:  0.018504, precision:  0.966887, f1:  0.983165
epoch:15, step:109, loss:  0.008145, precision:  0.984733, f1:  0.996139
epoch:15, step:110, loss:  0.022799, precision:  0.967532, f1:  0.980263
epoch:15, step:111, loss:  0.024423, precision:  0.969231, f1:  0.972973
epoch:15, step:112, loss:  0.009124, precision:  0.987500, f1:  0.996845
epoch:15, step:113, loss:  0.039538, precision:  0.981013, f1:  0.971787
epoch:15, step:114, loss:  0.023295, precision:  0.965278, f1:  0.978873
epoch:15, step:115, loss:  0.014381, precision:  0.980645, f1:  0.990228
epoch:15, step:116, loss:  0.019834, precision:  0.981013, f1:  0.990415
epoch:15, step:117, loss:  0.009773, precision:  0.985816, f1:  0.992857
epoch:15, step:118, loss:  0.035236, precision:  0.981013, f1:  0.977918
epoch:15, step:119, loss:  0.015025, precision:  0.986207, f1:  0.986207
epoch:15, step:120, loss:  0.008585, precision:  0.985401, f1:  0.996310
epoch:15, step:121, loss:  0.009415, precision:  0.987179, f1:  0.996764
epoch:15, step:122, loss:  0.014357, precision:  0.986486, f1:  0.989830
epoch:15, step:123, loss:  0.025847, precision:  0.960526, f1:  0.973333
epoch:15, step:124, loss:  0.022272, precision:  0.964539, f1:  0.978417
epoch:15, step:125, loss:  0.018726, precision:  0.984733, f1:  0.988506
epoch:15, step:126, loss:  0.028751, precision:  0.974359, f1:  0.974359
epoch:15, step:127, loss:  0.022031, precision:  0.978102, f1:  0.985294
epoch:15, step:128, loss:  0.039953, precision:  0.959732, f1:  0.972789
epoch:15, step:129, loss:  0.029889, precision:  0.956522, f1:  0.981413
epoch:15, step:130, loss:  0.016172, precision:  0.966443, f1:  0.982935
epoch:15, step:131, loss:  0.014007, precision:  0.978102, f1:  0.985294
epoch:15, step:132, loss:  0.013867, precision:  0.987097, f1:  0.990291
epoch:15, step:133, loss:  0.030237, precision:  0.975904, f1:  0.981818
epoch:15, step:134, loss:  0.017881, precision:  0.970588, f1:  0.981413
epoch:15, step:135, loss:  0.013848, precision:  0.986667, f1:  0.996633
epoch:15, step:136, loss:  0.048108, precision:  0.956790, f1:  0.959752
epoch:15, step:137, loss:  0.007542, precision:  0.991870, f1:  0.995918
epoch:15, step:138, loss:  0.025706, precision:  0.986014, f1:  0.982578
epoch:15, step:139, loss:  0.030133, precision:  0.966443, f1:  0.982935
epoch:15, step:140, loss:  0.007287, precision:  0.992857, f1:  1.000000
epoch:15, step:141, loss:  0.010566, precision:  0.978417, f1:  0.989091
epoch:15, step:142, loss:  0.039741, precision:  0.944444, f1:  0.961131
epoch:15, step:143, loss:  0.027348, precision:  0.957747, f1:  0.974910
epoch:15, step:144, loss:  0.033607, precision:  0.969231, f1:  0.980545
epoch:15, step:145, loss:  0.022856, precision:  0.980645, f1:  0.990228
epoch:15, step:146, loss:  0.030695, precision:  0.974684, f1:  0.977778
epoch:15, step:147, loss:  0.020280, precision:  0.969925, f1:  0.969925
epoch:15, step:148, loss:  0.025457, precision:  0.978102, f1:  0.974545
epoch:15, step:149, loss:  0.038122, precision:  0.950311, f1:  0.965300
epoch:15, step:150, loss:  0.016170, precision:  0.967105, f1:  0.980000
epoch:15, step:151, loss:  0.016169, precision:  0.980263, f1:  0.983498
epoch:15, step:152, loss:  0.014561, precision:  0.980132, f1:  0.989967
epoch:15, step:153, loss:  0.017369, precision:  0.971631, f1:  0.982079
epoch:15, step:154, loss:  0.033903, precision:  0.962687, f1:  0.973585
epoch:15, step:155, loss:  0.035006, precision:  0.961832, f1:  0.961832
epoch:15, step:156, loss:  0.029156, precision:  0.951724, f1:  0.971831
epoch:15, step:157, loss:  0.026479, precision:  0.960265, f1:  0.979730
epoch:15, step:158, loss:  0.017565, precision:  0.984615, f1:  0.988417
epoch:15, step:159, loss:  0.025850, precision:  0.984962, f1:  0.984962
epoch:15, step:160, loss:  0.019196, precision:  0.985075, f1:  0.996226
epoch:15, step:161, loss:  0.020145, precision:  0.985294, f1:  0.985294
epoch:15, step:162, loss:  0.010984, precision:  0.985915, f1:  0.992908
epoch:15, step:163, loss:  0.039945, precision:  0.966667, f1:  0.969900
epoch:15, step:164, loss:  0.020502, precision:  0.965278, f1:  0.975439
epoch:15, step:165, loss:  0.018936, precision:  0.965517, f1:  0.982456
epoch:15, step:166, loss:  0.017773, precision:  0.977612, f1:  0.988679
epoch:15, step:167, loss:  0.026359, precision:  0.953947, f1:  0.973154
epoch:15, valid_f1:  0.785157, valid_precision:  0.779137, valid_recall:  0.791726
epoch:16, step:0, loss:  0.022037, precision:  0.977444, f1:  0.981132
epoch:16, step:1, loss:  0.030451, precision:  0.964286, f1:  0.967742
epoch:16, step:2, loss:  0.011200, precision:  0.991736, f1:  0.991736
epoch:16, step:3, loss:  0.017522, precision:  0.973333, f1:  0.983165
epoch:16, step:4, loss:  0.021957, precision:  0.977099, f1:  0.984615
epoch:16, step:5, loss:  0.016656, precision:  0.986667, f1:  0.983389
epoch:16, step:6, loss:  0.029139, precision:  0.993007, f1:  0.986111
epoch:16, step:7, loss:  0.017208, precision:  0.980132, f1:  0.986667
epoch:16, step:8, loss:  0.041293, precision:  0.990909, f1:  0.964602
epoch:16, step:9, loss:  0.017504, precision:  0.984252, f1:  0.988142
epoch:16, step:10, loss:  0.016659, precision:  0.976744, f1:  0.976744
epoch:16, step:11, loss:  0.023207, precision:  0.986111, f1:  0.986111
epoch:16, step:12, loss:  0.030648, precision:  0.938776, f1:  0.968421
epoch:16, step:13, loss:  0.013104, precision:  0.971831, f1:  0.985714
epoch:16, step:14, loss:  0.030234, precision:  0.959184, f1:  0.975779
epoch:16, step:15, loss:  0.039490, precision:  0.960000, f1:  0.979592
epoch:16, step:16, loss:  0.048610, precision:  0.945205, f1:  0.965035
epoch:16, step:17, loss:  0.034989, precision:  0.952055, f1:  0.975439
epoch:16, step:18, loss:  0.032312, precision:  0.958333, f1:  0.961672
epoch:16, step:19, loss:  0.021039, precision:  0.985294, f1:  0.985294
epoch:16, step:20, loss:  0.036925, precision:  0.980519, f1:  0.967949
epoch:16, step:21, loss:  0.010874, precision:  0.992806, f1:  0.992806
epoch:16, step:22, loss:  0.018720, precision:  0.985816, f1:  0.985816
epoch:16, step:23, loss:  0.038243, precision:  0.993590, f1:  0.984127
epoch:16, step:24, loss:  0.024830, precision:  0.973154, f1:  0.983051
epoch:16, step:25, loss:  0.019215, precision:  0.993333, f1:  0.990033
epoch:16, step:26, loss:  0.010201, precision:  0.984962, f1:  0.988679
epoch:16, step:27, loss:  0.026536, precision:  0.979452, f1:  0.989619
epoch:16, step:28, loss:  0.025005, precision:  0.973856, f1:  0.983498
epoch:16, step:29, loss:  0.018423, precision:  0.981707, f1:  0.993827
epoch:16, step:30, loss:  0.022253, precision:  0.971429, f1:  0.985507
epoch:16, step:31, loss:  0.008764, precision:  0.985915, f1:  0.996441
epoch:16, step:32, loss:  0.024080, precision:  0.977778, f1:  0.985075
epoch:16, step:33, loss:  0.036652, precision:  0.968750, f1:  0.977918
epoch:16, step:34, loss:  0.029136, precision:  0.956204, f1:  0.981273
epoch:16, step:35, loss:  0.023063, precision:  0.992308, f1:  0.977273
epoch:16, step:36, loss:  0.007566, precision:  0.993243, f1:  0.996610
epoch:16, step:37, loss:  0.012650, precision:  0.993548, f1:  0.996764
epoch:16, step:38, loss:  0.036447, precision:  0.977778, f1:  0.985075
epoch:16, step:39, loss:  0.016055, precision:  0.992248, f1:  0.988417
epoch:16, step:40, loss:  0.023351, precision:  0.978102, f1:  0.981685
epoch:16, step:41, loss:  0.022089, precision:  0.981366, f1:  0.990596
epoch:16, step:42, loss:  0.028904, precision:  0.987179, f1:  0.984026
epoch:16, step:43, loss:  0.007491, precision:  0.983051, f1:  0.995708
epoch:16, step:44, loss:  0.014136, precision:  0.980519, f1:  0.993421